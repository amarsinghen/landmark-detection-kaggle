Group 4:

for layer in Inception_ResNetV2_MODEL.layers:
    layer.trainable=False
	
model=tf.keras.models.Sequential([
                                  Inception_ResNetV2_MODEL,
                                  tf.keras.layers.GlobalAveragePooling2D(),
                                  tf.keras.layers.Flatten(),
                                  tf.keras.layers.Dense(2048, activation='relu'),
                                  tf.keras.layers.Dropout(0.3, name='Dropout_Regularization1'),
                                  tf.keras.layers.Dense(5844, activation='softmax')
])
model.summary()

optimizer = tf.keras.optimizers.Adam(lr=0.0001)
batch_size = 256
model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['acc'])
train_data_dir = '../datasets/group4_set_128/set_128/train/'
valid_data_dir = '../datasets/group4_set_128/set_128/valid/'

train_datagen = ImageDataGenerator(
    rescale=1/255,
    rotation_range=45,
    width_shift_range=0.1,
    height_shift_range=0.1,
    shear_range=0.2,
    zoom_range=0.1,
    horizontal_flip=True,
    fill_mode='nearest')

WARNING:tensorflow:From <ipython-input-16-aaad9bd815d4>:7: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
Please use Model.fit, which supports generators.
Epoch 1/50
1254/1254 [==============================] - 851s 678ms/step - loss: 7.8519 - acc: 0.0160 - val_loss: 7.1001 - val_acc: 0.0373
Epoch 2/50
1254/1254 [==============================] - 790s 630ms/step - loss: 6.8420 - acc: 0.0522 - val_loss: 6.6818 - val_acc: 0.0585
Epoch 3/50
1254/1254 [==============================] - 790s 630ms/step - loss: 6.4462 - acc: 0.0741 - val_loss: 6.4705 - val_acc: 0.0743
Epoch 4/50
1254/1254 [==============================] - 788s 628ms/step - loss: 6.1839 - acc: 0.0919 - val_loss: 6.3075 - val_acc: 0.0860
Epoch 5/50
1254/1254 [==============================] - 787s 628ms/step - loss: 5.9759 - acc: 0.1068 - val_loss: 6.1931 - val_acc: 0.0948
Epoch 6/50
1254/1254 [==============================] - 787s 628ms/step - loss: 5.8040 - acc: 0.1208 - val_loss: 6.1003 - val_acc: 0.1047
Epoch 7/50
1254/1254 [==============================] - 787s 628ms/step - loss: 5.6509 - acc: 0.1333 - val_loss: 6.0152 - val_acc: 0.1112
Epoch 8/50
1254/1254 [==============================] - 787s 628ms/step - loss: 5.5217 - acc: 0.1441 - val_loss: 5.9458 - val_acc: 0.1174
Epoch 9/50
1254/1254 [==============================] - 787s 628ms/step - loss: 5.4021 - acc: 0.1538 - val_loss: 5.8897 - val_acc: 0.1219
Epoch 10/50
 667/1254 [==============>...............] - ETA: 5:56 - loss: 5.2859 - acc: 0.1633
 

**********************************************************************************************************************

for layer in Inception_ResNetV2_MODEL.layers:
    layer.trainable=False
	
model=tf.keras.models.Sequential([
                                  Inception_ResNetV2_MODEL,
                                  tf.keras.layers.GlobalAveragePooling2D(),
                                  tf.keras.layers.Flatten(),
                                  tf.keras.layers.Dense(8192, activation='relu'),
                                  tf.keras.layers.Dropout(0.5, name='Dropout_Regularization1'),
                                  tf.keras.layers.Dense(5844, activation='softmax')
])
model.summary()

optimizer = tf.keras.optimizers.Adam(lr=0.0001)
batch_size = 256
model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['acc'])
train_data_dir = '../datasets/group4_set_128/set_128/train/'
valid_data_dir = '../datasets/group4_set_128/set_128/valid/'

train_datagen = ImageDataGenerator(
    rescale=1/255,
    rotation_range=45,
    width_shift_range=0.1,
    height_shift_range=0.1,
    shear_range=0.2,
    zoom_range=0.1,
    horizontal_flip=True,
    fill_mode='nearest')

WARNING:tensorflow:From <ipython-input-13-aaad9bd815d4>:7: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
Please use Model.fit, which supports generators.
Epoch 1/50
1254/1254 [==============================] - 793s 633ms/step - loss: 7.8163 - acc: 0.0168 - val_loss: 7.0147 - val_acc: 0.0400
Epoch 2/50
1254/1254 [==============================] - 791s 631ms/step - loss: 6.8245 - acc: 0.0501 - val_loss: 6.6262 - val_acc: 0.0606
Epoch 3/50
1254/1254 [==============================] - 792s 632ms/step - loss: 6.4587 - acc: 0.0713 - val_loss: 6.4116 - val_acc: 0.0756
Epoch 4/50
1254/1254 [==============================] - 792s 631ms/step - loss: 6.1965 - acc: 0.0880 - val_loss: 6.2663 - val_acc: 0.0870
Epoch 5/50
1254/1254 [==============================] - 789s 630ms/step - loss: 5.9881 - acc: 0.1031 - val_loss: 6.1378 - val_acc: 0.0969
Epoch 6/50
1254/1254 [==============================] - 791s 631ms/step - loss: 5.8133 - acc: 0.1158 - val_loss: 6.0476 - val_acc: 0.1046
Epoch 7/50
1254/1254 [==============================] - 790s 630ms/step - loss: 5.6543 - acc: 0.1284 - val_loss: 5.9632 - val_acc: 0.1125
Epoch 8/50
1254/1254 [==============================] - 788s 628ms/step - loss: 5.5133 - acc: 0.1385 - val_loss: 5.8987 - val_acc: 0.1190
Epoch 9/50
1254/1254 [==============================] - 790s 630ms/step - loss: 5.3858 - acc: 0.1505 - val_loss: 5.8383 - val_acc: 0.1279
Epoch 10/50
1254/1254 [==============================] - 790s 630ms/step - loss: 5.2659 - acc: 0.1597 - val_loss: 5.7841 - val_acc: 0.1306
Epoch 11/50
1254/1254 [==============================] - 789s 629ms/step - loss: 5.1612 - acc: 0.1696 - val_loss: 5.7479 - val_acc: 0.1371
Epoch 12/50
1254/1254 [==============================] - 786s 627ms/step - loss: 5.0537 - acc: 0.1788 - val_loss: 5.7051 - val_acc: 0.1420
Epoch 13/50
1254/1254 [==============================] - 786s 626ms/step - loss: 4.9624 - acc: 0.1864 - val_loss: 5.6774 - val_acc: 0.1471
Epoch 14/50
1254/1254 [==============================] - 786s 627ms/step - loss: 4.8724 - acc: 0.1947 - val_loss: 5.6501 - val_acc: 0.1503
Epoch 15/50
1254/1254 [==============================] - 785s 626ms/step - loss: 4.7887 - acc: 0.2049 - val_loss: 5.6123 - val_acc: 0.1532
Epoch 16/50
1254/1254 [==============================] - 786s 627ms/step - loss: 4.7097 - acc: 0.2119 - val_loss: 5.5960 - val_acc: 0.1555
Epoch 17/50
1254/1254 [==============================] - 785s 626ms/step - loss: 4.6309 - acc: 0.2183 - val_loss: 5.5767 - val_acc: 0.1595
Epoch 18/50
1254/1254 [==============================] - 789s 629ms/step - loss: 4.5594 - acc: 0.2258 - val_loss: 5.5527 - val_acc: 0.1627
Epoch 19/50
1254/1254 [==============================] - 790s 630ms/step - loss: 4.4926 - acc: 0.2332 - val_loss: 5.5446 - val_acc: 0.1642
Epoch 20/50
1254/1254 [==============================] - 788s 628ms/step - loss: 4.4233 - acc: 0.2399 - val_loss: 5.5196 - val_acc: 0.1668
Epoch 21/50
1254/1254 [==============================] - 784s 625ms/step - loss: 4.3638 - acc: 0.2463 - val_loss: 5.5164 - val_acc: 0.1688
Epoch 22/50
1254/1254 [==============================] - 784s 625ms/step - loss: 4.3035 - acc: 0.2524 - val_loss: 5.4987 - val_acc: 0.1701
Epoch 23/50
1254/1254 [==============================] - 784s 625ms/step - loss: 4.2468 - acc: 0.2582 - val_loss: 5.4875 - val_acc: 0.1742
Epoch 24/50
1254/1254 [==============================] - 784s 625ms/step - loss: 4.1838 - acc: 0.2645 - val_loss: 5.4869 - val_acc: 0.1761
Epoch 25/50
1254/1254 [==============================] - 788s 629ms/step - loss: 4.1381 - acc: 0.2710 - val_loss: 5.4840 - val_acc: 0.1786
Epoch 26/50
1254/1254 [==============================] - 789s 629ms/step - loss: 4.0853 - acc: 0.2770 - val_loss: 5.4728 - val_acc: 0.1792
Epoch 27/50
1254/1254 [==============================] - 786s 627ms/step - loss: 4.0309 - acc: 0.2809 - val_loss: 5.4658 - val_acc: 0.1817
Epoch 28/50
1254/1254 [==============================] - 784s 626ms/step - loss: 3.9895 - acc: 0.2879 - val_loss: 5.4559 - val_acc: 0.1811
Epoch 29/50
1254/1254 [==============================] - 784s 625ms/step - loss: 3.9450 - acc: 0.2928 - val_loss: 5.4569 - val_acc: 0.1857
Epoch 30/50
1254/1254 [==============================] - 785s 626ms/step - loss: 3.9012 - acc: 0.2962 - val_loss: 5.4513 - val_acc: 0.1843
Epoch 31/50
  22/1254 [..............................] - ETA: 12:03 - loss: 3.9272 - acc: 0.2903
  
 **********************************************************************************************************************

for layer in Inception_ResNetV2_MODEL.layers[:107]:
    layer.trainable=False
	
model=tf.keras.models.Sequential([
                                  Inception_ResNetV2_MODEL,
                                  tf.keras.layers.GlobalAveragePooling2D(),
                                  tf.keras.layers.Flatten(),
                                  tf.keras.layers.Dense(4096, activation='relu'),
                                  tf.keras.layers.Dense(5844, activation='softmax')
])
model.summary()

optimizer = tf.keras.optimizers.Adam(lr=0.0001)
batch_size = 256
model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['acc'])
train_data_dir = '../datasets/group4_set_128/set_128/train/'
valid_data_dir = '../datasets/group4_set_128/set_128/valid/'

train_datagen = ImageDataGenerator(
    rescale=1/255,
    rotation_range=45,
    width_shift_range=0.1,
    height_shift_range=0.1,
    shear_range=0.2,
    zoom_range=0.1,
    horizontal_flip=True,
    fill_mode='nearest') 
  
WARNING:tensorflow:From <ipython-input-13-aaad9bd815d4>:7: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
Please use Model.fit, which supports generators.
Epoch 1/50
1254/1254 [==============================] - 801s 639ms/step - loss: 6.7683 - acc: 0.0633 - val_loss: 5.0945 - val_acc: 0.1674
Epoch 2/50
1254/1254 [==============================] - 798s 636ms/step - loss: 4.2287 - acc: 0.2635 - val_loss: 4.1128 - val_acc: 0.2890
Epoch 3/50
1254/1254 [==============================] - 798s 636ms/step - loss: 3.2387 - acc: 0.3937 - val_loss: 3.6536 - val_acc: 0.3535
Epoch 4/50
1254/1254 [==============================] - 796s 635ms/step - loss: 2.5947 - acc: 0.4874 - val_loss: 3.5089 - val_acc: 0.3787
Epoch 5/50
1254/1254 [==============================] - 799s 637ms/step - loss: 2.1016 - acc: 0.5642 - val_loss: 3.4195 - val_acc: 0.3998
Epoch 6/50
1254/1254 [==============================] - 799s 637ms/step - loss: 1.6996 - acc: 0.6323 - val_loss: 3.3215 - val_acc: 0.4195
Epoch 7/50
1254/1254 [==============================] - 800s 638ms/step - loss: 1.3638 - acc: 0.6920 - val_loss: 3.3100 - val_acc: 0.4319
Epoch 8/50
1254/1254 [==============================] - 800s 638ms/step - loss: 1.0794 - acc: 0.7463 - val_loss: 3.3919 - val_acc: 0.4367
Epoch 9/50
1254/1254 [==============================] - 799s 637ms/step - loss: 0.8492 - acc: 0.7933 - val_loss: 3.5993 - val_acc: 0.4203
Epoch 10/50
1254/1254 [==============================] - 799s 637ms/step - loss: 0.6661 - acc: 0.8324 - val_loss: 3.4634 - val_acc: 0.4546
Epoch 11/50
1254/1254 [==============================] - 799s 637ms/step - loss: 0.5251 - acc: 0.8648 - val_loss: 3.7090 - val_acc: 0.4418
Epoch 12/50
1254/1254 [==============================] - 799s 637ms/step - loss: 0.4166 - acc: 0.8905 - val_loss: 3.7513 - val_acc: 0.4452
Epoch 13/50
1254/1254 [==============================] - 800s 638ms/step - loss: 0.3438 - acc: 0.9091 - val_loss: 3.8306 - val_acc: 0.4451
Epoch 14/50
 739/1254 [================>.............] - ETA: 5:17 - loss: 0.2588 - acc: 0.9315
 
*****************************************************************************************************************************
INCEPTION NETWORK - Training all layers

InceptionV3_MODEL=tf.keras.applications.InceptionV3(input_shape=(128,128,3),
                                               include_top=False,
                                               weights='imagenet')
											   
model=tf.keras.models.Sequential([
                                  InceptionV3_MODEL,
                                  tf.keras.layers.GlobalAveragePooling2D(),
                                  tf.keras.layers.Flatten(),
                                  tf.keras.layers.Dropout(0.5, name='Dropout_Regularization1'),
                                  tf.keras.layers.Dense(4096, activation='relu'),
                                  tf.keras.layers.Dense(5844, activation='softmax')
])
model.summary()

optimizer = tf.keras.optimizers.Adam(lr=0.0001)
batch_size = 256
model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['acc'])
train_data_dir = '../datasets/group4_set_128/set_128/train/'
valid_data_dir = '../datasets/group4_set_128/set_128/valid/

train_datagen = ImageDataGenerator(
    rescale=1/255,
    width_shift_range=0.1,
    height_shift_range=0.1,
    shear_range=0.2,
    zoom_range=0.1,
    fill_mode='nearest')

valid_datagen = ImageDataGenerator(rescale=1/255)

Please use Model.fit, which supports generators.
Epoch 1/50
1254/1254 [==============================] - 781s 623ms/step - loss: 7.8215 - acc: 0.0126 - val_loss: 6.3617 - val_acc: 0.0515
Epoch 2/50
1254/1254 [==============================] - 779s 621ms/step - loss: 5.5489 - acc: 0.1090 - val_loss: 5.0385 - val_acc: 0.1619
Epoch 3/50
1254/1254 [==============================] - 780s 622ms/step - loss: 4.4714 - acc: 0.2144 - val_loss: 4.4515 - val_acc: 0.2340
Epoch 4/50
1254/1254 [==============================] - 779s 621ms/step - loss: 3.8035 - acc: 0.2950 - val_loss: 4.1249 - val_acc: 0.2798
Epoch 5/50
1254/1254 [==============================] - 779s 621ms/step - loss: 3.3049 - acc: 0.3613 - val_loss: 3.9296 - val_acc: 0.3122
Epoch 6/50
1254/1254 [==============================] - 781s 623ms/step - loss: 2.9012 - acc: 0.4181 - val_loss: 3.7415 - val_acc: 0.3396
Epoch 7/50
1254/1254 [==============================] - 780s 622ms/step - loss: 2.5628 - acc: 0.4683 - val_loss: 3.6780 - val_acc: 0.3551
Epoch 8/50
1254/1254 [==============================] - 778s 620ms/step - loss: 2.2706 - acc: 0.5140 - val_loss: 3.5790 - val_acc: 0.3765
Epoch 9/50
1254/1254 [==============================] - 777s 619ms/step - loss: 2.0152 - acc: 0.5554 - val_loss: 3.5608 - val_acc: 0.3836
Epoch 10/50
1254/1254 [==============================] - 777s 619ms/step - loss: 1.7796 - acc: 0.5954 - val_loss: 3.6939 - val_acc: 0.3798
Epoch 11/50
1254/1254 [==============================] - 778s 620ms/step - loss: 1.5823 - acc: 0.6299 - val_loss: 3.6266 - val_acc: 0.3918
Epoch 12/50
1254/1254 [==============================] - 780s 622ms/step - loss: 1.3991 - acc: 0.6629 - val_loss: 3.6795 - val_acc: 0.3984
Epoch 13/50
1254/1254 [==============================] - 780s 622ms/step - loss: 1.2363 - acc: 0.6945 - val_loss: 3.6079 - val_acc: 0.4163
Epoch 14/50
1254/1254 [==============================] - 778s 620ms/step - loss: 1.1003 - acc: 0.7218 - val_loss: 3.6925 - val_acc: 0.4186
Epoch 15/50
1254/1254 [==============================] - 780s 622ms/step - loss: 0.9748 - acc: 0.7486 - val_loss: 3.6707 - val_acc: 0.4296
Epoch 16/50
1254/1254 [==============================] - 780s 622ms/step - loss: 0.8701 - acc: 0.7701 - val_loss: 3.7479 - val_acc: 0.4264
Epoch 17/50
1254/1254 [==============================] - 779s 622ms/step - loss: 0.7779 - acc: 0.7916 - val_loss: 3.8437 - val_acc: 0.4287
Epoch 18/50
1254/1254 [==============================] - 779s 621ms/step - loss: 0.6974 - acc: 0.8095 - val_loss: 3.9835 - val_acc: 0.4209
Epoch 19/50
1254/1254 [==============================] - 779s 622ms/step - loss: 0.6297 - acc: 0.8255 - val_loss: 3.9676 - val_acc: 0.4354
Epoch 20/50
 173/1254 [===>..........................] - ETA: 10:49 - loss: 0.5160 - acc: 0.8569
 
 
 *********************************************************************************************************************************

InceptionV3_MODEL=tf.keras.applications.InceptionV3(input_shape=(128,128,3),
                                               include_top=False,
                                               weights='imagenet')
											   
model=tf.keras.models.Sequential([
                                  InceptionV3_MODEL,
                                  tf.keras.layers.GlobalAveragePooling2D(),
                                  tf.keras.layers.Flatten(),
#                                   tf.keras.layers.Dropout(0.5, name='Dropout_Regularization1'),
                                  tf.keras.layers.Dense(4096, activation='relu'),
                                  tf.keras.layers.Dense(5844, activation='softmax')
])
model.summary()

optimizer = tf.keras.optimizers.Adam(lr=0.0001)
batch_size = 256
model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['acc'])
train_data_dir = '../datasets/group4_set_128/set_128/train/'
valid_data_dir = '../datasets/group4_set_128/set_128/valid/'

train_datagen = ImageDataGenerator(
    rescale=1/255,
    rotation_range=45,
    width_shift_range=0.3,
    height_shift_range=0.3,
    shear_range=0.3,
    zoom_range=0.3,
    horizontal_flip=True,
    fill_mode='nearest')

valid_datagen = ImageDataGenerator(rescale=1/255)

 Please use Model.fit, which supports generators.
Epoch 1/150
1254/1254 [==============================] - 442s 353ms/step - loss: 7.4702 - acc: 0.0216 - val_loss: 6.1699 - val_acc: 0.0628
Epoch 2/150
1254/1254 [==============================] - 413s 330ms/step - loss: 5.4964 - acc: 0.1190 - val_loss: 5.0680 - val_acc: 0.1611
Epoch 3/150
1254/1254 [==============================] - 412s 329ms/step - loss: 4.6121 - acc: 0.2065 - val_loss: 4.5435 - val_acc: 0.2266
Epoch 4/150
1254/1254 [==============================] - 413s 330ms/step - loss: 4.0116 - acc: 0.2763 - val_loss: 4.2500 - val_acc: 0.2702
Epoch 5/150
1254/1254 [==============================] - 413s 330ms/step - loss: 3.5497 - acc: 0.3356 - val_loss: 4.0664 - val_acc: 0.2960
Epoch 6/150
1254/1254 [==============================] - 412s 328ms/step - loss: 3.1714 - acc: 0.3875 - val_loss: 3.7966 - val_acc: 0.3391
Epoch 7/150
1254/1254 [==============================] - 413s 330ms/step - loss: 2.8470 - acc: 0.4342 - val_loss: 3.7161 - val_acc: 0.3527
Epoch 8/150
1254/1254 [==============================] - 413s 329ms/step - loss: 2.5503 - acc: 0.4788 - val_loss: 3.6419 - val_acc: 0.3705
Epoch 9/150
1254/1254 [==============================] - 413s 330ms/step - loss: 2.2889 - acc: 0.5172 - val_loss: 3.6230 - val_acc: 0.3834
Epoch 10/150
1254/1254 [==============================] - 413s 330ms/step - loss: 2.0519 - acc: 0.5558 - val_loss: 3.5951 - val_acc: 0.3914
Epoch 11/150
1254/1254 [==============================] - 413s 329ms/step - loss: 1.8349 - acc: 0.5941 - val_loss: 3.6852 - val_acc: 0.3853
Epoch 12/150
1254/1254 [==============================] - 414s 330ms/step - loss: 1.6412 - acc: 0.6278 - val_loss: 3.5996 - val_acc: 0.4102
Epoch 13/150
1254/1254 [==============================] - 414s 330ms/step - loss: 1.4574 - acc: 0.6630 - val_loss: 3.6369 - val_acc: 0.4137
Epoch 14/150
1254/1254 [==============================] - 414s 330ms/step - loss: 1.3019 - acc: 0.6934 - val_loss: 3.8414 - val_acc: 0.3964
Epoch 15/150
1254/1254 [==============================] - 414s 330ms/step - loss: 1.1587 - acc: 0.7219 - val_loss: 3.7428 - val_acc: 0.4122
Epoch 16/150
1254/1254 [==============================] - 413s 330ms/step - loss: 1.0283 - acc: 0.7504 - val_loss: 3.8004 - val_acc: 0.4209
Epoch 17/150
1254/1254 [==============================] - 414s 331ms/step - loss: 0.9179 - acc: 0.7736 - val_loss: 3.7998 - val_acc: 0.4255
Epoch 18/150
1254/1254 [==============================] - 415s 331ms/step - loss: 0.8194 - acc: 0.7976 - val_loss: 3.8850 - val_acc: 0.4222
Epoch 19/150
1254/1254 [==============================] - 415s 331ms/step - loss: 0.7383 - acc: 0.8158 - val_loss: 4.1258 - val_acc: 0.4019
Epoch 20/150
1254/1254 [==============================] - 414s 331ms/step - loss: 0.6609 - acc: 0.8343 - val_loss: 4.0333 - val_acc: 0.4216
Epoch 21/150
1254/1254 [==============================] - 415s 331ms/step - loss: 0.6004 - acc: 0.8490 - val_loss: 3.9166 - val_acc: 0.4354
Epoch 22/150
1254/1254 [==============================] - 414s 330ms/step - loss: 0.5510 - acc: 0.8612 - val_loss: 4.1546 - val_acc: 0.4139
Epoch 23/150
1254/1254 [==============================] - 414s 330ms/step - loss: 0.5068 - acc: 0.8717 - val_loss: 4.0292 - val_acc: 0.4295
Epoch 24/150
1254/1254 [==============================] - 414s 330ms/step - loss: 0.4713 - acc: 0.8807 - val_loss: 4.0898 - val_acc: 0.4338
Epoch 25/150
1254/1254 [==============================] - 415s 331ms/step - loss: 0.4364 - acc: 0.8886 - val_loss: 4.0565 - val_acc: 0.4401
Epoch 26/150
1254/1254 [==============================] - 414s 330ms/step - loss: 0.4091 - acc: 0.8963 - val_loss: 4.2556 - val_acc: 0.4234
Epoch 27/150
1254/1254 [==============================] - 414s 330ms/step - loss: 0.3831 - acc: 0.9026 - val_loss: 4.0524 - val_acc: 0.4481
Epoch 28/150
1254/1254 [==============================] - 414s 330ms/step - loss: 0.3611 - acc: 0.9073 - val_loss: 4.4531 - val_acc: 0.4170
Epoch 29/150
1254/1254 [==============================] - 414s 331ms/step - loss: 0.3436 - acc: 0.9120 - val_loss: 4.3399 - val_acc: 0.4238
Epoch 30/150
1254/1254 [==============================] - 415s 331ms/step - loss: 0.3215 - acc: 0.9175 - val_loss: 4.4093 - val_acc: 0.4181
Epoch 31/150
1254/1254 [==============================] - 415s 331ms/step - loss: 0.3076 - acc: 0.9210 - val_loss: 4.2581 - val_acc: 0.4373
Epoch 32/150
1254/1254 [==============================] - 414s 330ms/step - loss: 0.2914 - acc: 0.9250 - val_loss: 4.4041 - val_acc: 0.4337
Epoch 33/150
1254/1254 [==============================] - 415s 331ms/step - loss: 0.2808 - acc: 0.9274 - val_loss: 4.3183 - val_acc: 0.4353
Epoch 34/150
1254/1254 [==============================] - 414s 330ms/step - loss: 0.2675 - acc: 0.9309 - val_loss: 4.3350 - val_acc: 0.4386
Epoch 35/150
1254/1254 [==============================] - 416s 331ms/step - loss: 0.2550 - acc: 0.9338 - val_loss: 4.4637 - val_acc: 0.4316
Epoch 36/150
1254/1254 [==============================] - 415s 331ms/step - loss: 0.2462 - acc: 0.9363 - val_loss: 4.3214 - val_acc: 0.4497
Epoch 37/150
1254/1254 [==============================] - 415s 331ms/step - loss: 0.2385 - acc: 0.9376 - val_loss: 4.4701 - val_acc: 0.4433
Epoch 38/150
1254/1254 [==============================] - 416s 331ms/step - loss: 0.2250 - acc: 0.9410 - val_loss: 4.3834 - val_acc: 0.4423
Epoch 39/150
1254/1254 [==============================] - 416s 332ms/step - loss: 0.2218 - acc: 0.9419 - val_loss: 4.4879 - val_acc: 0.4471
Epoch 40/150
1254/1254 [==============================] - 416s 332ms/step - loss: 0.2142 - acc: 0.9444 - val_loss: 4.6365 - val_acc: 0.4256
Epoch 41/150
1254/1254 [==============================] - 415s 331ms/step - loss: 0.2055 - acc: 0.9460 - val_loss: 4.7867 - val_acc: 0.4132
Epoch 42/150
1254/1254 [==============================] - 416s 331ms/step - loss: 0.2015 - acc: 0.9469 - val_loss: 4.5850 - val_acc: 0.4381
Epoch 43/150
1254/1254 [==============================] - 416s 331ms/step - loss: 0.1939 - acc: 0.9487 - val_loss: 4.5842 - val_acc: 0.4447
Epoch 44/150
1254/1254 [==============================] - 416s 332ms/step - loss: 0.1887 - acc: 0.9502 - val_loss: 4.6893 - val_acc: 0.4298
Epoch 45/150
1254/1254 [==============================] - 416s 332ms/step - loss: 0.1834 - acc: 0.9519 - val_loss: 4.8140 - val_acc: 0.4236
Epoch 46/150
1254/1254 [==============================] - 417s 332ms/step - loss: 0.1770 - acc: 0.9532 - val_loss: 4.8031 - val_acc: 0.4202
Epoch 47/150
1195/1254 [===========================>..] - ETA: 18s - loss: 0.1708 - acc: 0.9549


**********************************************************************************************************************************
InceptionV3_MODEL=tf.keras.applications.InceptionV3(input_shape=(128,128,3),
                                               include_top=False,
                                               weights='imagenet')
											   
for layer in InceptionV3_MODEL.layers[:101]:
    layer.trainable=False
	
model=tf.keras.models.Sequential([
                                  InceptionV3_MODEL,
                                  tf.keras.layers.GlobalAveragePooling2D(),
                                  tf.keras.layers.Flatten(),
                                  tf.keras.layers.Dropout(0.5, name='Dropout_Regularization1'),
                                  tf.keras.layers.Dense(4096, activation='relu'),
                                  tf.keras.layers.Dropout(0.5, name='Dropout_Regularization2'),
                                  tf.keras.layers.Dense(5844, activation='softmax')
])
model.summary()

optimizer = tf.keras.optimizers.Adam(lr=0.0001)
batch_size = 256
model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['acc'])
train_data_dir = '../datasets/group4_set_128/set_128/train/'
valid_data_dir = '../datasets/group4_set_128/set_128/valid/'

train_datagen = ImageDataGenerator(
    rescale=1/255,
#     rotation_range=45,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True,
    fill_mode='nearest')

history = model.fit_generator(
    generator = train_generator,
    steps_per_epoch = train_generator.n // batch_size,
    validation_data = valid_generator,
    validation_steps = valid_generator.n // batch_size,
    epochs = 100,
    workers = 2,
    verbose=1
)

Please use Model.fit, which supports generators.
Epoch 1/100
1254/1254 [==============================] - 452s 361ms/step - loss: 8.3263 - acc: 0.0025 - val_loss: 7.1874 - val_acc: 0.0188
Epoch 2/100
1254/1254 [==============================] - 419s 334ms/step - loss: 6.6525 - acc: 0.0347 - val_loss: 5.8243 - val_acc: 0.0904
Epoch 3/100
1254/1254 [==============================] - 402s 320ms/step - loss: 5.7641 - acc: 0.0864 - val_loss: 5.1905 - val_acc: 0.1502
Epoch 4/100
1254/1254 [==============================] - 403s 321ms/step - loss: 5.2067 - acc: 0.1348 - val_loss: 4.9305 - val_acc: 0.1766
Epoch 5/100
1254/1254 [==============================] - 403s 321ms/step - loss: 4.7893 - acc: 0.1767 - val_loss: 4.5260 - val_acc: 0.2264
Epoch 6/100
1254/1254 [==============================] - 404s 322ms/step - loss: 4.4602 - acc: 0.2137 - val_loss: 4.3369 - val_acc: 0.2537
Epoch 7/100
1254/1254 [==============================] - 404s 322ms/step - loss: 4.1760 - acc: 0.2480 - val_loss: 4.1384 - val_acc: 0.2795
Epoch 8/100
1254/1254 [==============================] - 404s 322ms/step - loss: 3.9401 - acc: 0.2762 - val_loss: 4.0125 - val_acc: 0.3008
Epoch 9/100
1254/1254 [==============================] - 405s 323ms/step - loss: 3.7200 - acc: 0.3041 - val_loss: 3.9115 - val_acc: 0.3168
Epoch 10/100
1254/1254 [==============================] - 403s 322ms/step - loss: 3.5298 - acc: 0.3287 - val_loss: 3.8429 - val_acc: 0.3259
Epoch 11/100
1254/1254 [==============================] - 403s 321ms/step - loss: 3.3546 - acc: 0.3522 - val_loss: 3.7575 - val_acc: 0.3404
Epoch 12/100
1254/1254 [==============================] - 404s 322ms/step - loss: 3.1919 - acc: 0.3749 - val_loss: 3.6775 - val_acc: 0.3557
Epoch 13/100
1254/1254 [==============================] - 405s 323ms/step - loss: 3.0513 - acc: 0.3935 - val_loss: 3.6505 - val_acc: 0.3628
Epoch 14/100
1254/1254 [==============================] - 405s 323ms/step - loss: 2.9132 - acc: 0.4128 - val_loss: 3.5795 - val_acc: 0.3726
Epoch 15/100
1254/1254 [==============================] - 404s 322ms/step - loss: 2.7812 - acc: 0.4322 - val_loss: 3.5208 - val_acc: 0.3865
Epoch 16/100
1254/1254 [==============================] - 406s 323ms/step - loss: 2.6638 - acc: 0.4469 - val_loss: 3.4750 - val_acc: 0.3908
Epoch 17/100
1254/1254 [==============================] - 404s 322ms/step - loss: 2.5549 - acc: 0.4655 - val_loss: 3.4871 - val_acc: 0.3949
Epoch 18/100
1254/1254 [==============================] - 405s 323ms/step - loss: 2.4479 - acc: 0.4809 - val_loss: 3.4933 - val_acc: 0.3943
Epoch 19/100
1254/1254 [==============================] - 404s 322ms/step - loss: 2.3516 - acc: 0.4963 - val_loss: 3.4963 - val_acc: 0.3970
Epoch 20/100
1254/1254 [==============================] - 406s 324ms/step - loss: 2.2580 - acc: 0.5110 - val_loss: 3.4990 - val_acc: 0.4001
Epoch 21/100
1254/1254 [==============================] - 404s 322ms/step - loss: 2.1642 - acc: 0.5252 - val_loss: 3.5147 - val_acc: 0.4045
Epoch 22/100
1254/1254 [==============================] - 407s 324ms/step - loss: 2.0867 - acc: 0.5374 - val_loss: 3.4313 - val_acc: 0.4166
Epoch 23/100
1254/1254 [==============================] - 404s 322ms/step - loss: 2.0019 - acc: 0.5513 - val_loss: 3.4546 - val_acc: 0.4162
Epoch 24/100
1254/1254 [==============================] - 406s 324ms/step - loss: 1.9326 - acc: 0.5622 - val_loss: 3.5011 - val_acc: 0.4152
Epoch 25/100
1254/1254 [==============================] - 405s 323ms/step - loss: 1.8617 - acc: 0.5750 - val_loss: 3.4720 - val_acc: 0.4227
Epoch 26/100
1254/1254 [==============================] - 407s 324ms/step - loss: 1.7899 - acc: 0.5876 - val_loss: 3.5039 - val_acc: 0.4203
Epoch 27/100
1254/1254 [==============================] - 405s 323ms/step - loss: 1.7254 - acc: 0.5978 - val_loss: 3.5257 - val_acc: 0.4247
Epoch 28/100
1254/1254 [==============================] - 407s 324ms/step - loss: 1.6648 - acc: 0.6086 - val_loss: 3.4984 - val_acc: 0.4268
Epoch 29/100
1254/1254 [==============================] - 405s 323ms/step - loss: 1.6079 - acc: 0.6189 - val_loss: 3.4928 - val_acc: 0.4338
Epoch 30/100
1254/1254 [==============================] - 406s 324ms/step - loss: 1.5533 - acc: 0.6292 - val_loss: 3.5741 - val_acc: 0.4255
Epoch 31/100
1254/1254 [==============================] - 405s 323ms/step - loss: 1.5016 - acc: 0.6381 - val_loss: 3.4833 - val_acc: 0.4430
Epoch 32/100
1254/1254 [==============================] - 407s 325ms/step - loss: 1.4475 - acc: 0.6487 - val_loss: 3.6398 - val_acc: 0.4265
Epoch 33/100
1254/1254 [==============================] - 405s 323ms/step - loss: 1.4027 - acc: 0.6566 - val_loss: 3.5763 - val_acc: 0.4360
Epoch 34/100
1254/1254 [==============================] - 406s 324ms/step - loss: 1.3538 - acc: 0.6657 - val_loss: 3.6963 - val_acc: 0.4264
Epoch 35/100
1254/1254 [==============================] - 406s 323ms/step - loss: 1.3126 - acc: 0.6744 - val_loss: 3.6373 - val_acc: 0.4401
Epoch 36/100
1254/1254 [==============================] - 407s 325ms/step - loss: 1.2704 - acc: 0.6835 - val_loss: 3.6065 - val_acc: 0.4459
Epoch 37/100
1254/1254 [==============================] - 406s 323ms/step - loss: 1.2312 - acc: 0.6904 - val_loss: 3.6652 - val_acc: 0.4442
Epoch 38/100
1254/1254 [==============================] - 406s 324ms/step - loss: 1.1931 - acc: 0.6979 - val_loss: 3.6410 - val_acc: 0.4496
Epoch 39/100
1254/1254 [==============================] - 407s 324ms/step - loss: 1.1617 - acc: 0.7044 - val_loss: 3.7238 - val_acc: 0.4390
Epoch 40/100
1254/1254 [==============================] - 407s 325ms/step - loss: 1.1264 - acc: 0.7126 - val_loss: 3.6533 - val_acc: 0.4518
Epoch 41/100
1254/1254 [==============================] - 407s 324ms/step - loss: 1.0888 - acc: 0.7193 - val_loss: 3.7338 - val_acc: 0.4483
Epoch 42/100
1254/1254 [==============================] - 407s 325ms/step - loss: 1.0620 - acc: 0.7249 - val_loss: 3.7189 - val_acc: 0.4517
Epoch 43/100
1254/1254 [==============================] - 407s 324ms/step - loss: 1.0342 - acc: 0.7314 - val_loss: 3.7597 - val_acc: 0.4504
Epoch 44/100
1254/1254 [==============================] - 408s 326ms/step - loss: 1.0048 - acc: 0.7371 - val_loss: 3.8591 - val_acc: 0.4431
Epoch 45/100
1254/1254 [==============================] - 406s 324ms/step - loss: 0.9843 - acc: 0.7421 - val_loss: 3.7748 - val_acc: 0.4521
Epoch 46/100
1254/1254 [==============================] - 408s 325ms/step - loss: 0.9572 - acc: 0.7482 - val_loss: 3.8806 - val_acc: 0.4479
Epoch 47/100
1254/1254 [==============================] - 408s 325ms/step - loss: 0.9300 - acc: 0.7539 - val_loss: 3.8230 - val_acc: 0.4516
Epoch 48/100
 561/1254 [============>.................] - ETA: 3:34 - loss: 0.8835 - acc: 0.7651
 
 
****************************************************************************************************************************
VGG16 Model

VGG16_MODEL=tf.keras.applications.VGG16(input_shape=(128,128,3),
                                               include_top=False,
                                               weights='imagenet')

for layer in VGG16_MODEL.layers:
    layer.trainable=False

batch_size = 256
l1_factor = 0.0001
l2_factor = 0.0001
dropout = 0.5

model=tf.keras.models.Sequential([
                                  VGG16_MODEL,
                                  tf.keras.layers.GlobalAveragePooling2D(),
                                  tf.keras.layers.Flatten(),
                                  tf.keras.layers.Dropout(dropout, name='Dropout_Regularization1'),
                                  tf.keras.layers.Dense(4096, activation='relu', kernel_regularizer=tf.keras.regularizers.l1_l2(l1=l1_factor, l2=l2_factor)),
                                  tf.keras.layers.Dropout(dropout, name='Dropout_Regularization2'),
#                                   tf.keras.layers.Dense(4096, activation='relu', kernel_regularizer=tf.keras.regularizers.l1_l2(l1=l1_factor, l2=l2_factor)),
#                                   tf.keras.layers.Dropout(dropout, name='Dropout_Regularization3'),
                                  tf.keras.layers.Dense(5844, activation='softmax')
])
model.summary()

optimizer = tf.keras.optimizers.Adam(lr=0.0001)
model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['acc'])
train_data_dir = '../datasets/group4_set_128/set_128/train/'
valid_data_dir = '../datasets/group4_set_128/set_128/valid/'

train_datagen = ImageDataGenerator(
    rescale=1./255,
    rotation_range=45,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True,
    fill_mode='nearest')

valid_datagen = ImageDataGenerator(rescale=1./255)

Please use Model.fit, which supports generators.
Epoch 1/100
1254/1254 [==============================] - 320s 255ms/step - loss: 9.4922 - acc: 3.0839e-04 - val_loss: 8.7273 - val_acc: 6.8681e-04
Epoch 2/100
1254/1254 [==============================] - 323s 258ms/step - loss: 8.6118 - acc: 6.2953e-04 - val_loss: 8.5018 - val_acc: 0.0011
Epoch 3/100
1254/1254 [==============================] - 312s 249ms/step - loss: 8.4716 - acc: 0.0013 - val_loss: 8.3850 - val_acc: 0.0030
Epoch 4/100
1254/1254 [==============================] - 311s 248ms/step - loss: 8.3863 - acc: 0.0024 - val_loss: 8.3040 - val_acc: 0.0043
Epoch 5/100
1254/1254 [==============================] - 319s 254ms/step - loss: 8.3253 - acc: 0.0031 - val_loss: 8.2403 - val_acc: 0.0051
Epoch 6/100
1254/1254 [==============================] - 315s 251ms/step - loss: 8.2798 - acc: 0.0037 - val_loss: 8.1970 - val_acc: 0.0053
Epoch 7/100
1170/1254 [==========================>...] - ETA: 19s - loss: 8.2419 - acc: 0.0041

*************************************************************************************************************************************
RESNET50

for layer in ResNet50_MODEL.layers:
    layer.trainable=True
	
batch_size = 64
l1_factor = 0.0001
l2_factor = 0.0001
dropout = 0.5

model=tf.keras.models.Sequential([
                                  ResNet50_MODEL,
                                  tf.keras.layers.GlobalAveragePooling2D(),
                                  tf.keras.layers.Flatten(),
                                  tf.keras.layers.Dropout(dropout, name='Dropout_Regularization1'),
                                  tf.keras.layers.Dense(4096, activation='relu', kernel_regularizer=tf.keras.regularizers.l1_l2(l1=l1_factor, l2=l2_factor)),
                                  tf.keras.layers.Dropout(dropout, name='Dropout_Regularization2'),
#                                   tf.keras.layers.Dense(4096, activation='relu', kernel_regularizer=tf.keras.regularizers.l1_l2(l1=l1_factor, l2=l2_factor)),
#                                   tf.keras.layers.Dropout(dropout, name='Dropout_Regularization3'),
                                  tf.keras.layers.Dense(5844, activation='softmax')
])
model.summary()

optimizer = tf.keras.optimizers.Adam(lr=0.0002, decay=0.001)
model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['acc'])
train_data_dir = '../datasets/group4_set_128/set_128/train/'
valid_data_dir = '../datasets/group4_set_128/set_128/valid/'

train_datagen = ImageDataGenerator(
    rescale=1./255,
    rotation_range=45,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True,
    fill_mode='nearest')

valid_datagen = ImageDataGenerator(rescale=1./255)

Please use Model.fit, which supports generators.
Epoch 1/100
5017/5017 [==============================] - 569s 113ms/step - loss: 9.6287 - acc: 0.0022 - val_loss: 7.4315 - val_acc: 0.0127
Epoch 2/100
 827/5017 [===>..........................] - ETA: 7:33 - loss: 7.4673 - acc: 0.0114
 
 
*************************************************************************************************************************************
RESNET50

for layer in ResNet50_MODEL.layers:
    layer.trainable=True
	
batch_size = 64
l1_factor = 0.0001
l2_factor = 0.0001
dropout = 0.5

model=tf.keras.models.Sequential([
                                  ResNet50_MODEL,
                                  tf.keras.layers.GlobalAveragePooling2D(),
                                  tf.keras.layers.Flatten(),
#                                   tf.keras.layers.Dropout(dropout, name='Dropout_Regularization1'),
#                                   tf.keras.layers.Dense(4096, activation='relu', kernel_regularizer=tf.keras.regularizers.l1_l2(l1=l1_factor, l2=l2_factor)),
#                                   tf.keras.layers.Dropout(dropout, name='Dropout_Regularization2')
                                  tf.keras.layers.Dense(5844, activation='softmax')
])
model.summary()

optimizer = tf.keras.optimizers.Adam(lr=0.0002, decay=0.001)
model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['acc'])
train_data_dir = '../datasets/group4_set_128/set_128/train/'
valid_data_dir = '../datasets/group4_set_128/set_128/valid/'

train_datagen = ImageDataGenerator(
    rescale=1./255,
    rotation_range=45,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True,
    fill_mode='nearest')

valid_datagen = ImageDataGenerator(rescale=1./255)


Please use Model.fit, which supports generators.
Epoch 1/100
5017/5017 [==============================] - 551s 110ms/step - loss: 6.8727 - acc: 0.0553 - val_loss: 5.3175 - val_acc: 0.1483
Epoch 2/100
5017/5017 [==============================] - 553s 110ms/step - loss: 4.5194 - acc: 0.2407 - val_loss: 4.4327 - val_acc: 0.2599
Epoch 3/100
5017/5017 [==============================] - 554s 110ms/step - loss: 3.6952 - acc: 0.3428 - val_loss: 4.0813 - val_acc: 0.3093
Epoch 4/100
5017/5017 [==============================] - 556s 111ms/step - loss: 3.2828 - acc: 0.4012 - val_loss: 3.8635 - val_acc: 0.3398
Epoch 5/100
5017/5017 [==============================] - 555s 111ms/step - loss: 3.0234 - acc: 0.4386 - val_loss: 3.7386 - val_acc: 0.3598
Epoch 6/100
5017/5017 [==============================] - 556s 111ms/step - loss: 2.8384 - acc: 0.4673 - val_loss: 3.6662 - val_acc: 0.3732
Epoch 7/100
5017/5017 [==============================] - 555s 111ms/step - loss: 2.6992 - acc: 0.4882 - val_loss: 3.6033 - val_acc: 0.3811
Epoch 8/100
5017/5017 [==============================] - 551s 110ms/step - loss: 2.5871 - acc: 0.5064 - val_loss: 3.5687 - val_acc: 0.3874
Epoch 9/100
5017/5017 [==============================] - 555s 111ms/step - loss: 2.4915 - acc: 0.5213 - val_loss: 3.5271 - val_acc: 0.3938
Epoch 10/100
5017/5017 [==============================] - 556s 111ms/step - loss: 2.4113 - acc: 0.5343 - val_loss: 3.4699 - val_acc: 0.4019
Epoch 11/100
 618/5017 [==>...........................] - ETA: 7:43 - loss: 2.3526 - acc: 0.5451
 
*********************************************************************************************************************************'
ResNet50_MODEL=tf.keras.applications.ResNet50(input_shape=(128,128,3),
                                               include_top=False,
                                               weights='imagenet')
											   
for layer in ResNet50_MODEL.layers:
    layer.trainable=True
	
batch_size = 64
l1_factor = 0.0001
l2_factor = 0.0001
dropout = 0.5

model=tf.keras.models.Sequential([
                                  ResNet50_MODEL,
                                  tf.keras.layers.GlobalAveragePooling2D(),
#                                   tf.keras.layers.Flatten(),
                                  tf.keras.layers.Dropout(dropout, name='Dropout_Regularization1'),
#                                   tf.keras.layers.Dense(4096, activation='relu', kernel_regularizer=tf.keras.regularizers.l1_l2(l1=l1_factor, l2=l2_factor)),
#                                   tf.keras.layers.Dropout(dropout, name='Dropout_Regularization2')
                                  tf.keras.layers.Dense(5844, activation='softmax')
])
model.summary()

optimizer = tf.keras.optimizers.Adam(lr=0.0001)
model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['acc'])
train_data_dir = '../datasets/group4_set_128/set_128/train/'
valid_data_dir = '../datasets/group4_set_128/set_128/valid/'

train_datagen = ImageDataGenerator(
    rescale=1./255,
    rotation_range=45,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True,
    fill_mode='nearest')

valid_datagen = ImageDataGenerator(rescale=1./255)

Please use Model.fit, which supports generators.
Epoch 1/100
5017/5017 [==============================] - 555s 111ms/step - loss: 7.0451 - acc: 0.0489 - val_loss: 5.2922 - val_acc: 0.1614
Epoch 2/100
5017/5017 [==============================] - 557s 111ms/step - loss: 4.8129 - acc: 0.2059 - val_loss: 4.4625 - val_acc: 0.2593
Epoch 3/100
5017/5017 [==============================] - 556s 111ms/step - loss: 3.9807 - acc: 0.3036 - val_loss: 3.8392 - val_acc: 0.3452
Epoch 4/100
5017/5017 [==============================] - 558s 111ms/step - loss: 3.4593 - acc: 0.3717 - val_loss: 3.5939 - val_acc: 0.3838
Epoch 5/100
5017/5017 [==============================] - 558s 111ms/step - loss: 3.0700 - acc: 0.4236 - val_loss: 3.4525 - val_acc: 0.4053
Epoch 6/100
5017/5017 [==============================] - 557s 111ms/step - loss: 2.7645 - acc: 0.4671 - val_loss: 3.3268 - val_acc: 0.4218
Epoch 7/100
5017/5017 [==============================] - 557s 111ms/step - loss: 2.5102 - acc: 0.5043 - val_loss: 3.2137 - val_acc: 0.4428
Epoch 8/100
5017/5017 [==============================] - 558s 111ms/step - loss: 2.2974 - acc: 0.5363 - val_loss: 3.2227 - val_acc: 0.4439
Epoch 9/100
5017/5017 [==============================] - 557s 111ms/step - loss: 2.1137 - acc: 0.5643 - val_loss: 3.2707 - val_acc: 0.4447
Epoch 10/100
5017/5017 [==============================] - 557s 111ms/step - loss: 1.9506 - acc: 0.5899 - val_loss: 2.9742 - val_acc: 0.4880
Epoch 11/100
5017/5017 [==============================] - 557s 111ms/step - loss: 1.8001 - acc: 0.6150 - val_loss: 3.1208 - val_acc: 0.4726
Epoch 12/100
5017/5017 [==============================] - 557s 111ms/step - loss: 1.6746 - acc: 0.6340 - val_loss: 2.9747 - val_acc: 0.4947
Epoch 13/100
5017/5017 [==============================] - 557s 111ms/step - loss: 1.5553 - acc: 0.6544 - val_loss: 2.9366 - val_acc: 0.5088
Epoch 14/100
5017/5017 [==============================] - 554s 110ms/step - loss: 1.4492 - acc: 0.6719 - val_loss: 2.9399 - val_acc: 0.5154
Epoch 15/100
5017/5017 [==============================] - 551s 110ms/step - loss: 1.3517 - acc: 0.6893 - val_loss: 3.0415 - val_acc: 0.5108
Epoch 16/100
5017/5017 [==============================] - 551s 110ms/step - loss: 1.2668 - acc: 0.7037 - val_loss: 3.2739 - val_acc: 0.4864
Epoch 17/100
5017/5017 [==============================] - 551s 110ms/step - loss: 1.1807 - acc: 0.7197 - val_loss: 3.0753 - val_acc: 0.5122
Epoch 18/100
5017/5017 [==============================] - 550s 110ms/step - loss: 1.1098 - acc: 0.7328 - val_loss: 3.0088 - val_acc: 0.5315
Epoch 19/100
5017/5017 [==============================] - 551s 110ms/step - loss: 1.0403 - acc: 0.7458 - val_loss: 3.1441 - val_acc: 0.5157
Epoch 20/100
5017/5017 [==============================] - 551s 110ms/step - loss: 0.9794 - acc: 0.7563 - val_loss: 3.0266 - val_acc: 0.5380
Epoch 21/100
5017/5017 [==============================] - 551s 110ms/step - loss: 0.9226 - acc: 0.7680 - val_loss: 3.0570 - val_acc: 0.5323
Epoch 22/100
5017/5017 [==============================] - 550s 110ms/step - loss: 0.8703 - acc: 0.7775 - val_loss: 3.1167 - val_acc: 0.5322
Epoch 23/100
5017/5017 [==============================] - 550s 110ms/step - loss: 0.8186 - acc: 0.7886 - val_loss: 3.2829 - val_acc: 0.5139
Epoch 24/100
5017/5017 [==============================] - 551s 110ms/step - loss: 0.7774 - acc: 0.7978 - val_loss: 3.4166 - val_acc: 0.5059
Epoch 25/100
5017/5017 [==============================] - 551s 110ms/step - loss: 0.7366 - acc: 0.8061 - val_loss: 3.3319 - val_acc: 0.5189
Epoch 26/100
5017/5017 [==============================] - 551s 110ms/step - loss: 0.6968 - acc: 0.8149 - val_loss: 3.2021 - val_acc: 0.5397
Epoch 27/100
5017/5017 [==============================] - 551s 110ms/step - loss: 0.6653 - acc: 0.8220 - val_loss: 3.2952 - val_acc: 0.5195
Epoch 28/100
5017/5017 [==============================] - 551s 110ms/step - loss: 0.6325 - acc: 0.8297 - val_loss: 3.2678 - val_acc: 0.5341
Epoch 29/100
5017/5017 [==============================] - 552s 110ms/step - loss: 0.6007 - acc: 0.8373 - val_loss: 3.1930 - val_acc: 0.5508
Epoch 30/100
5017/5017 [==============================] - 551s 110ms/step - loss: 0.5760 - acc: 0.8427 - val_loss: 3.4604 - val_acc: 0.5367
Epoch 31/100
5017/5017 [==============================] - 551s 110ms/step - loss: 0.5521 - acc: 0.8484 - val_loss: 3.1974 - val_acc: 0.5545
Epoch 32/100
5017/5017 [==============================] - 551s 110ms/step - loss: 0.5253 - acc: 0.8539 - val_loss: 3.2298 - val_acc: 0.5468
Epoch 33/100
5017/5017 [==============================] - 552s 110ms/step - loss: 0.5086 - acc: 0.8583 - val_loss: 3.2278 - val_acc: 0.5539
Epoch 34/100
5017/5017 [==============================] - 552s 110ms/step - loss: 0.4853 - acc: 0.8643 - val_loss: 3.5554 - val_acc: 0.5231
Epoch 35/100
5017/5017 [==============================] - 552s 110ms/step - loss: 0.4666 - acc: 0.8693 - val_loss: 3.5427 - val_acc: 0.5451
Epoch 36/100
5017/5017 [==============================] - 552s 110ms/step - loss: 0.4485 - acc: 0.8731 - val_loss: 3.5782 - val_acc: 0.5304
Epoch 37/100
5017/5017 [==============================] - 552s 110ms/step - loss: 0.4318 - acc: 0.8788 - val_loss: 3.5604 - val_acc: 0.5368
Epoch 38/100
5017/5017 [==============================] - 552s 110ms/step - loss: 0.4170 - acc: 0.8815 - val_loss: 3.5192 - val_acc: 0.5484
Epoch 39/100
5017/5017 [==============================] - 552s 110ms/step - loss: 0.4057 - acc: 0.8840 - val_loss: 3.4781 - val_acc: 0.5478
Epoch 40/100
5017/5017 [==============================] - 552s 110ms/step - loss: 0.3938 - acc: 0.8876 - val_loss: 3.4788 - val_acc: 0.5570
Epoch 41/100
5017/5017 [==============================] - 553s 110ms/step - loss: 0.3799 - acc: 0.8914 - val_loss: 3.5324 - val_acc: 0.5585
Epoch 42/100
5017/5017 [==============================] - 551s 110ms/step - loss: 0.3659 - acc: 0.8949 - val_loss: 3.7449 - val_acc: 0.5439
Epoch 43/100
5017/5017 [==============================] - 552s 110ms/step - loss: 0.3572 - acc: 0.8969 - val_loss: 3.7555 - val_acc: 0.5341
Epoch 44/100
5017/5017 [==============================] - 553s 110ms/step - loss: 0.3481 - acc: 0.8998 - val_loss: 3.4769 - val_acc: 0.5572
Epoch 45/100
5017/5017 [==============================] - 552s 110ms/step - loss: 0.3399 - acc: 0.9015 - val_loss: 3.6699 - val_acc: 0.5436
Epoch 46/100
5017/5017 [==============================] - 552s 110ms/step - loss: 0.3315 - acc: 0.9042 - val_loss: 3.8874 - val_acc: 0.5375
Epoch 47/100
5017/5017 [==============================] - 553s 110ms/step - loss: 0.3209 - acc: 0.9073 - val_loss: 3.8653 - val_acc: 0.5346
Epoch 48/100
5017/5017 [==============================] - 554s 110ms/step - loss: 0.3125 - acc: 0.9089 - val_loss: 3.6259 - val_acc: 0.5564
Epoch 49/100
5017/5017 [==============================] - 553s 110ms/step - loss: 0.3055 - acc: 0.9111 - val_loss: 3.5266 - val_acc: 0.5682
Epoch 50/100
5017/5017 [==============================] - 553s 110ms/step - loss: 0.2975 - acc: 0.9134 - val_loss: 3.6487 - val_acc: 0.5652
Epoch 51/100
5017/5017 [==============================] - 553s 110ms/step - loss: 0.2906 - acc: 0.9151 - val_loss: 3.7145 - val_acc: 0.5657
Epoch 52/100
5017/5017 [==============================] - 553s 110ms/step - loss: 0.2834 - acc: 0.9170 - val_loss: 3.5039 - val_acc: 0.5712
Epoch 53/100
5017/5017 [==============================] - 553s 110ms/step - loss: 0.2791 - acc: 0.9182 - val_loss: 3.5516 - val_acc: 0.5743
Epoch 54/100
5017/5017 [==============================] - 553s 110ms/step - loss: 0.2703 - acc: 0.9209 - val_loss: 3.8173 - val_acc: 0.5479
Epoch 55/100
5017/5017 [==============================] - 553s 110ms/step - loss: 0.2676 - acc: 0.9218 - val_loss: 4.1328 - val_acc: 0.5288
Epoch 56/100
5017/5017 [==============================] - 553s 110ms/step - loss: 0.2629 - acc: 0.9233 - val_loss: 3.9316 - val_acc: 0.5477
Epoch 57/100
5017/5017 [==============================] - 552s 110ms/step - loss: 0.2555 - acc: 0.9249 - val_loss: 4.0797 - val_acc: 0.5344
Epoch 58/100
5017/5017 [==============================] - 552s 110ms/step - loss: 0.2509 - acc: 0.9260 - val_loss: 3.8782 - val_acc: 0.5426
Epoch 59/100
5017/5017 [==============================] - 555s 111ms/step - loss: 0.2456 - acc: 0.9273 - val_loss: 4.1037 - val_acc: 0.5352
Epoch 60/100
5017/5017 [==============================] - 558s 111ms/step - loss: 0.2410 - acc: 0.9296 - val_loss: 3.9331 - val_acc: 0.5408
Epoch 61/100
5017/5017 [==============================] - 558s 111ms/step - loss: 0.2376 - acc: 0.9300 - val_loss: 3.7589 - val_acc: 0.5695
Epoch 62/100
5017/5017 [==============================] - 558s 111ms/step - loss: 0.2326 - acc: 0.9315 - val_loss: 3.7596 - val_acc: 0.5646
Epoch 63/100
5017/5017 [==============================] - 553s 110ms/step - loss: 0.2282 - acc: 0.9329 - val_loss: 3.8272 - val_acc: 0.5640
Epoch 64/100
5017/5017 [==============================] - 553s 110ms/step - loss: 0.2253 - acc: 0.9333 - val_loss: 3.9395 - val_acc: 0.5569
Epoch 65/100
5017/5017 [==============================] - 553s 110ms/step - loss: 0.2221 - acc: 0.9346 - val_loss: 3.8494 - val_acc: 0.5668
Epoch 66/100
5017/5017 [==============================] - 553s 110ms/step - loss: 0.2170 - acc: 0.9355 - val_loss: 3.8972 - val_acc: 0.5591
Epoch 67/100
5017/5017 [==============================] - 555s 111ms/step - loss: 0.2129 - acc: 0.9380 - val_loss: 3.9228 - val_acc: 0.5555
Epoch 68/100
5017/5017 [==============================] - 559s 111ms/step - loss: 0.2091 - acc: 0.9381 - val_loss: 4.0959 - val_acc: 0.5399
Epoch 69/100
5017/5017 [==============================] - 553s 110ms/step - loss: 0.2086 - acc: 0.9380 - val_loss: 4.0482 - val_acc: 0.5599
Epoch 70/100
5017/5017 [==============================] - 557s 111ms/step - loss: 0.2040 - acc: 0.9398 - val_loss: 3.8498 - val_acc: 0.5667
Epoch 71/100
5017/5017 [==============================] - 560s 112ms/step - loss: 0.2012 - acc: 0.9402 - val_loss: 3.9257 - val_acc: 0.5688
Epoch 72/100
5017/5017 [==============================] - 560s 112ms/step - loss: 0.1987 - acc: 0.9409 - val_loss: 4.3486 - val_acc: 0.5317
Epoch 73/100
5017/5017 [==============================] - 560s 112ms/step - loss: 0.1940 - acc: 0.9420 - val_loss: 3.8383 - val_acc: 0.5679
Epoch 74/100
5017/5017 [==============================] - 560s 112ms/step - loss: 0.1914 - acc: 0.9432 - val_loss: 3.9453 - val_acc: 0.5702
Epoch 75/100
5017/5017 [==============================] - 560s 112ms/step - loss: 0.1910 - acc: 0.9428 - val_loss: 4.0244 - val_acc: 0.5470
Epoch 76/100
5017/5017 [==============================] - 560s 112ms/step - loss: 0.1877 - acc: 0.9438 - val_loss: 4.4890 - val_acc: 0.5259
Epoch 77/100
5017/5017 [==============================] - 558s 111ms/step - loss: 0.1835 - acc: 0.9454 - val_loss: 4.1471 - val_acc: 0.5475
Epoch 78/100
5017/5017 [==============================] - 554s 111ms/step - loss: 0.1790 - acc: 0.9465 - val_loss: 4.2389 - val_acc: 0.5489
Epoch 79/100
5017/5017 [==============================] - 555s 111ms/step - loss: 0.1793 - acc: 0.9463 - val_loss: 4.0659 - val_acc: 0.5521
Epoch 80/100
5017/5017 [==============================] - 555s 111ms/step - loss: 0.1767 - acc: 0.9475 - val_loss: 3.9103 - val_acc: 0.5716
Epoch 81/100
5017/5017 [==============================] - 555s 111ms/step - loss: 0.1747 - acc: 0.9475 - val_loss: 4.2604 - val_acc: 0.5466
Epoch 82/100
5017/5017 [==============================] - 561s 112ms/step - loss: 0.1750 - acc: 0.9477 - val_loss: 4.1674 - val_acc: 0.5702
Epoch 83/100
5017/5017 [==============================] - 561s 112ms/step - loss: 0.1712 - acc: 0.9489 - val_loss: 3.9909 - val_acc: 0.5703
Epoch 84/100
5017/5017 [==============================] - 561s 112ms/step - loss: 0.1691 - acc: 0.9498 - val_loss: 4.1288 - val_acc: 0.5620
Epoch 85/100
5017/5017 [==============================] - 560s 112ms/step - loss: 0.1667 - acc: 0.9505 - val_loss: 4.2944 - val_acc: 0.5502
Epoch 86/100
5017/5017 [==============================] - 558s 111ms/step - loss: 0.1634 - acc: 0.9512 - val_loss: 4.1451 - val_acc: 0.5615
Epoch 87/100
5017/5017 [==============================] - 561s 112ms/step - loss: 0.1601 - acc: 0.9521 - val_loss: 4.1522 - val_acc: 0.5562
Epoch 88/100
5017/5017 [==============================] - 561s 112ms/step - loss: 0.1610 - acc: 0.9517 - val_loss: 4.0095 - val_acc: 0.5676
Epoch 89/100
5017/5017 [==============================] - 561s 112ms/step - loss: 0.1586 - acc: 0.9527 - val_loss: 4.6416 - val_acc: 0.5194
Epoch 90/100
5017/5017 [==============================] - 560s 112ms/step - loss: 0.1573 - acc: 0.9530 - val_loss: 4.2799 - val_acc: 0.5631
Epoch 91/100
5017/5017 [==============================] - 555s 111ms/step - loss: 0.1556 - acc: 0.9535 - val_loss: 4.1222 - val_acc: 0.5608
Epoch 92/100
5017/5017 [==============================] - 555s 111ms/step - loss: 0.1541 - acc: 0.9540 - val_loss: 4.0996 - val_acc: 0.5734
Epoch 93/100
5017/5017 [==============================] - 556s 111ms/step - loss: 0.1517 - acc: 0.9545 - val_loss: 4.0906 - val_acc: 0.5667
Epoch 94/100
5017/5017 [==============================] - 561s 112ms/step - loss: 0.1494 - acc: 0.9550 - val_loss: 4.2266 - val_acc: 0.5584
Epoch 95/100
5017/5017 [==============================] - 560s 112ms/step - loss: 0.1486 - acc: 0.9554 - val_loss: 4.4209 - val_acc: 0.5606
Epoch 96/100
5017/5017 [==============================] - 561s 112ms/step - loss: 0.1475 - acc: 0.9557 - val_loss: 4.2916 - val_acc: 0.5515
Epoch 97/100
5017/5017 [==============================] - 562s 112ms/step - loss: 0.1447 - acc: 0.9568 - val_loss: 4.3724 - val_acc: 0.5527
Epoch 98/100
5017/5017 [==============================] - 562s 112ms/step - loss: 0.1433 - acc: 0.9570 - val_loss: 4.3620 - val_acc: 0.5483
Epoch 99/100
5017/5017 [==============================] - 562s 112ms/step - loss: 0.1427 - acc: 0.9569 - val_loss: 4.0089 - val_acc: 0.5700
Epoch 100/100
5017/5017 [==============================] - 561s 112ms/step - loss: 0.1426 - acc: 0.9570 - val_loss: 4.2678 - val_acc: 0.5689


*************************************************************************************************************************************
ResNet50_MODEL=tf.keras.applications.ResNet50(input_shape=(224,224,3),
                                               include_top=False,
                                               weights='imagenet')
											   
for layer in ResNet50_MODEL.layers:
    layer.trainable=True
	
batch_size = 64
l1_factor = 0.0001
l2_factor = 0.0001
dropout = 0.5

model=tf.keras.models.Sequential([
                                  ResNet50_MODEL,
                                  tf.keras.layers.GlobalAveragePooling2D(),
                                  tf.keras.layers.Dropout(dropout, name='Dropout_Regularization1'),
                                  tf.keras.layers.Dense(5844, activation='softmax')
])
model.summary()

optimizer = tf.keras.optimizers.Adam(lr=0.0001)
model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['acc'])
train_data_dir = '../datasets/group4_set_256/set_256/train/'
valid_data_dir = '../datasets/group4_set_256/set_256/valid/'

train_datagen = ImageDataGenerator(
    rescale=1./255,
    rotation_range=45,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True,
    fill_mode='nearest')

valid_datagen = ImageDataGenerator(rescale=1./255)

Instructions for updating:
Please use Model.fit, which supports generators.
Epoch 1/100
4652/4652 [==============================] - 1796s 386ms/step - loss: 6.8055 - acc: 0.0649 - val_loss: 4.6291 - val_acc: 0.2285
Epoch 2/100
4652/4652 [==============================] - 1799s 387ms/step - loss: 4.0480 - acc: 0.2925 - val_loss: 3.6338 - val_acc: 0.3635
Epoch 3/100
4652/4652 [==============================] - 1807s 388ms/step - loss: 3.1302 - acc: 0.4169 - val_loss: 3.2762 - val_acc: 0.4223
Epoch 4/100
4652/4652 [==============================] - 1794s 386ms/step - loss: 2.6023 - acc: 0.4940 - val_loss: 3.0023 - val_acc: 0.4620
Epoch 5/100
4652/4652 [==============================] - 1808s 389ms/step - loss: 2.2325 - acc: 0.5512 - val_loss: 2.7810 - val_acc: 0.5028
Epoch 6/100
4652/4652 [==============================] - 1804s 388ms/step - loss: 1.9521 - acc: 0.5959 - val_loss: 2.9348 - val_acc: 0.4872
Epoch 7/100
4652/4652 [==============================] - 1805s 388ms/step - loss: 1.7233 - acc: 0.6345 - val_loss: 2.9540 - val_acc: 0.4780
Epoch 8/100
4652/4652 [==============================] - 1806s 388ms/step - loss: 1.5389 - acc: 0.6659 - val_loss: 2.5075 - val_acc: 0.5587
Epoch 9/100
4652/4652 [==============================] - 1800s 387ms/step - loss: 1.3800 - acc: 0.6937 - val_loss: 2.5218 - val_acc: 0.5537
Epoch 10/100
4652/4652 [==============================] - 1794s 386ms/step - loss: 1.2444 - acc: 0.7172 - val_loss: 3.0675 - val_acc: 0.4951
Epoch 11/100
4652/4652 [==============================] - 1807s 388ms/step - loss: 1.1292 - acc: 0.7381 - val_loss: 2.5899 - val_acc: 0.5607
Epoch 12/100
4652/4652 [==============================] - 1813s 390ms/step - loss: 1.0249 - acc: 0.7578 - val_loss: 2.5540 - val_acc: 0.5743
Epoch 13/100
4652/4652 [==============================] - 1813s 390ms/step - loss: 0.9371 - acc: 0.7753 - val_loss: 2.6705 - val_acc: 0.5519
Epoch 14/100
4652/4652 [==============================] - 1815s 390ms/step - loss: 0.8595 - acc: 0.7892 - val_loss: 2.7260 - val_acc: 0.5557
Epoch 15/100
4652/4652 [==============================] - 1802s 387ms/step - loss: 0.7849 - acc: 0.8047 - val_loss: 2.6088 - val_acc: 0.5789
Epoch 16/100
4652/4652 [==============================] - 1806s 388ms/step - loss: 0.7239 - acc: 0.8166 - val_loss: 2.6695 - val_acc: 0.5738
Epoch 17/100
4652/4652 [==============================] - 1800s 387ms/step - loss: 0.6716 - acc: 0.8278 - val_loss: 3.3994 - val_acc: 0.5038
Epoch 18/100
4652/4652 [==============================] - 1806s 388ms/step - loss: 0.6188 - acc: 0.8385 - val_loss: 2.8032 - val_acc: 0.5724
Epoch 19/100
4652/4652 [==============================] - 1803s 388ms/step - loss: 0.5772 - acc: 0.8479 - val_loss: 2.7336 - val_acc: 0.5812
Epoch 20/100
4652/4652 [==============================] - 1801s 387ms/step - loss: 0.5334 - acc: 0.8573 - val_loss: 2.9707 - val_acc: 0.5603
Epoch 21/100
4652/4652 [==============================] - 1792s 385ms/step - loss: 0.4976 - acc: 0.8660 - val_loss: 2.7128 - val_acc: 0.6000
Epoch 22/100
4652/4652 [==============================] - 1793s 385ms/step - loss: 0.4715 - acc: 0.8721 - val_loss: 2.8982 - val_acc: 0.5856
Epoch 23/100
4652/4652 [==============================] - 1793s 385ms/step - loss: 0.4372 - acc: 0.8801 - val_loss: 2.9010 - val_acc: 0.5903
Epoch 24/100
4652/4652 [==============================] - 1793s 385ms/step - loss: 0.4115 - acc: 0.8858 - val_loss: 3.2249 - val_acc: 0.5623
Epoch 25/100
4652/4652 [==============================] - 1793s 385ms/step - loss: 0.3864 - acc: 0.8921 - val_loss: 2.8430 - val_acc: 0.5997
Epoch 26/100
4652/4652 [==============================] - 1794s 386ms/step - loss: 0.3691 - acc: 0.8961 - val_loss: 3.3796 - val_acc: 0.5396
Epoch 27/100
4652/4652 [==============================] - 1795s 386ms/step - loss: 0.3470 - acc: 0.9026 - val_loss: 2.9803 - val_acc: 0.5844
Epoch 28/100
4652/4652 [==============================] - 1792s 385ms/step - loss: 0.3316 - acc: 0.9064 - val_loss: 3.0242 - val_acc: 0.5845
Epoch 29/100
4652/4652 [==============================] - 1794s 386ms/step - loss: 0.3137 - acc: 0.9106 - val_loss: 3.0191 - val_acc: 0.5843
Epoch 30/100
4652/4652 [==============================] - 1795s 386ms/step - loss: 0.3003 - acc: 0.9146 - val_loss: 2.9752 - val_acc: 0.6025
Epoch 31/100
4652/4652 [==============================] - 1792s 385ms/step - loss: 0.2867 - acc: 0.9185 - val_loss: 3.2057 - val_acc: 0.5766
Epoch 32/100
4652/4652 [==============================] - 1792s 385ms/step - loss: 0.2759 - acc: 0.9209 - val_loss: 3.1362 - val_acc: 0.5806
Epoch 33/100
4652/4652 [==============================] - 1795s 386ms/step - loss: 0.2654 - acc: 0.9239 - val_loss: 3.0975 - val_acc: 0.5946
Epoch 34/100
4652/4652 [==============================] - 1802s 387ms/step - loss: 0.2538 - acc: 0.9270 - val_loss: 3.3088 - val_acc: 0.5678
Epoch 35/100
4652/4652 [==============================] - 1802s 387ms/step - loss: 0.2433 - acc: 0.9299 - val_loss: 3.5818 - val_acc: 0.5441
Epoch 36/100
4652/4652 [==============================] - 1800s 387ms/step - loss: 0.2356 - acc: 0.9326 - val_loss: 3.1077 - val_acc: 0.6009
Epoch 37/100
4652/4652 [==============================] - 1804s 388ms/step - loss: 0.2264 - acc: 0.9346 - val_loss: 3.4007 - val_acc: 0.5624
Epoch 38/100
4652/4652 [==============================] - 1795s 386ms/step - loss: 0.2205 - acc: 0.9361 - val_loss: 3.0789 - val_acc: 0.6111
Epoch 39/100
4652/4652 [==============================] - 1794s 386ms/step - loss: 0.2128 - acc: 0.9380 - val_loss: 3.5060 - val_acc: 0.5706
Epoch 40/100
4652/4652 [==============================] - 1792s 385ms/step - loss: 0.2066 - acc: 0.9402 - val_loss: 3.2643 - val_acc: 0.5897
Epoch 41/100
4652/4652 [==============================] - 1797s 386ms/step - loss: 0.2004 - acc: 0.9420 - val_loss: 3.1942 - val_acc: 0.6112
Epoch 42/100
4652/4652 [==============================] - 1794s 386ms/step - loss: 0.1934 - acc: 0.9438 - val_loss: 3.0965 - val_acc: 0.6141
Epoch 43/100
4652/4652 [==============================] - 1793s 386ms/step - loss: 0.1882 - acc: 0.9449 - val_loss: 2.7853 - val_acc: 0.6419
Epoch 44/100
4652/4652 [==============================] - 1793s 385ms/step - loss: 0.1840 - acc: 0.9461 - val_loss: 3.5945 - val_acc: 0.5730
Epoch 45/100
4652/4652 [==============================] - 1793s 385ms/step - loss: 0.1785 - acc: 0.9479 - val_loss: 3.6100 - val_acc: 0.5621
Epoch 46/100
4652/4652 [==============================] - 1793s 385ms/step - loss: 0.1728 - acc: 0.9494 - val_loss: 3.4420 - val_acc: 0.5933
Epoch 47/100
4652/4652 [==============================] - 1793s 385ms/step - loss: 0.1709 - acc: 0.9497 - val_loss: 4.0696 - val_acc: 0.5168
Epoch 48/100
4652/4652 [==============================] - 1793s 385ms/step - loss: 0.1655 - acc: 0.9517 - val_loss: 3.3111 - val_acc: 0.6030
Epoch 49/100
4652/4652 [==============================] - 1799s 387ms/step - loss: 0.1607 - acc: 0.9530 - val_loss: 3.1268 - val_acc: 0.6180
Epoch 50/100
4652/4652 [==============================] - 1793s 385ms/step - loss: 0.1583 - acc: 0.9535 - val_loss: 3.2191 - val_acc: 0.6092
Epoch 51/100
4652/4652 [==============================] - 1793s 385ms/step - loss: 0.1558 - acc: 0.9544 - val_loss: 3.6686 - val_acc: 0.5742
Epoch 52/100
4652/4652 [==============================] - 1794s 386ms/step - loss: 0.1494 - acc: 0.9564 - val_loss: 3.0140 - val_acc: 0.6263
Epoch 53/100
4652/4652 [==============================] - 1793s 385ms/step - loss: 0.1471 - acc: 0.9569 - val_loss: 3.5178 - val_acc: 0.5863
Epoch 54/100
4652/4652 [==============================] - 1793s 386ms/step - loss: 0.1443 - acc: 0.9576 - val_loss: 3.4381 - val_acc: 0.5951
Epoch 55/100
4652/4652 [==============================] - 1792s 385ms/step - loss: 0.1409 - acc: 0.9588 - val_loss: 3.5195 - val_acc: 0.5973
Epoch 56/100
4652/4652 [==============================] - 1796s 386ms/step - loss: 0.1383 - acc: 0.9590 - val_loss: 3.0810 - val_acc: 0.6272
Epoch 57/100
4652/4652 [==============================] - 1802s 387ms/step - loss: 0.1347 - acc: 0.9605 - val_loss: 3.2496 - val_acc: 0.6178
Epoch 58/100
4652/4652 [==============================] - 1805s 388ms/step - loss: 0.1333 - acc: 0.9611 - val_loss: 4.3817 - val_acc: 0.5156
Epoch 59/100
4652/4652 [==============================] - 1800s 387ms/step - loss: 0.1293 - acc: 0.9619 - val_loss: 3.8238 - val_acc: 0.5661
Epoch 60/100
4652/4652 [==============================] - 1802s 387ms/step - loss: 0.1286 - acc: 0.9618 - val_loss: 4.2806 - val_acc: 0.5368
Epoch 61/100
4652/4652 [==============================] - 1792s 385ms/step - loss: 0.1247 - acc: 0.9634 - val_loss: 3.5474 - val_acc: 0.5907
Epoch 62/100
4652/4652 [==============================] - 1795s 386ms/step - loss: 0.1236 - acc: 0.9632 - val_loss: 3.6433 - val_acc: 0.5965
Epoch 63/100
4652/4652 [==============================] - 1791s 385ms/step - loss: 0.1209 - acc: 0.9642 - val_loss: 4.5028 - val_acc: 0.5192
Epoch 64/100
4652/4652 [==============================] - 1788s 384ms/step - loss: 0.1183 - acc: 0.9649 - val_loss: 3.3954 - val_acc: 0.6096
Epoch 65/100
4652/4652 [==============================] - 1791s 385ms/step - loss: 0.1165 - acc: 0.9656 - val_loss: 4.2467 - val_acc: 0.5462
Epoch 66/100
4652/4652 [==============================] - 1788s 384ms/step - loss: 0.1148 - acc: 0.9662 - val_loss: 3.2622 - val_acc: 0.6306
Epoch 67/100
4652/4652 [==============================] - 1787s 384ms/step - loss: 0.1124 - acc: 0.9666 - val_loss: 3.4956 - val_acc: 0.6012
Epoch 68/100
4652/4652 [==============================] - 1788s 384ms/step - loss: 0.1111 - acc: 0.9673 - val_loss: 3.5022 - val_acc: 0.6122
Epoch 69/100
4652/4652 [==============================] - 1787s 384ms/step - loss: 0.1102 - acc: 0.9675 - val_loss: 3.7062 - val_acc: 0.5971
Epoch 70/100
4652/4652 [==============================] - 1786s 384ms/step - loss: 0.1072 - acc: 0.9680 - val_loss: 3.8513 - val_acc: 0.5844
Epoch 71/100
4652/4652 [==============================] - 1787s 384ms/step - loss: 0.1063 - acc: 0.9686 - val_loss: 4.5849 - val_acc: 0.5300
Epoch 72/100
4652/4652 [==============================] - 1788s 384ms/step - loss: 0.1046 - acc: 0.9690 - val_loss: 3.7155 - val_acc: 0.5940
Epoch 73/100
4652/4652 [==============================] - 1789s 385ms/step - loss: 0.1033 - acc: 0.9693 - val_loss: 3.2494 - val_acc: 0.6284
Epoch 74/100
4652/4652 [==============================] - 1791s 385ms/step - loss: 0.1018 - acc: 0.9699 - val_loss: 3.4531 - val_acc: 0.6057
Epoch 75/100
4652/4652 [==============================] - 1793s 385ms/step - loss: 0.1004 - acc: 0.9705 - val_loss: 3.3854 - val_acc: 0.6213
Epoch 76/100
4652/4652 [==============================] - 1795s 386ms/step - loss: 0.0990 - acc: 0.9708 - val_loss: 4.3607 - val_acc: 0.5556
Epoch 77/100
4652/4652 [==============================] - 1796s 386ms/step - loss: 0.0975 - acc: 0.9711 - val_loss: 3.3776 - val_acc: 0.6262
Epoch 78/100
4652/4652 [==============================] - 1795s 386ms/step - loss: 0.0960 - acc: 0.9716 - val_loss: 4.0612 - val_acc: 0.5836
Epoch 79/100
4652/4652 [==============================] - 1796s 386ms/step - loss: 0.0955 - acc: 0.9714 - val_loss: 3.4231 - val_acc: 0.6298
Epoch 80/100
4652/4652 [==============================] - 1799s 387ms/step - loss: 0.0933 - acc: 0.9722 - val_loss: 4.0341 - val_acc: 0.5681
Epoch 81/100
4652/4652 [==============================] - 1801s 387ms/step - loss: 0.0929 - acc: 0.9725 - val_loss: 3.5138 - val_acc: 0.6218
Epoch 82/100
4652/4652 [==============================] - 1799s 387ms/step - loss: 0.0912 - acc: 0.9731 - val_loss: 3.5904 - val_acc: 0.6224
Epoch 83/100
4652/4652 [==============================] - 1816s 390ms/step - loss: 0.0898 - acc: 0.9734 - val_loss: 5.3657 - val_acc: 0.4803
Epoch 84/100
4652/4652 [==============================] - 1832s 394ms/step - loss: 0.0905 - acc: 0.9729 - val_loss: 3.6476 - val_acc: 0.6227
Epoch 85/100
4652/4652 [==============================] - 1847s 397ms/step - loss: 0.0877 - acc: 0.9739 - val_loss: 3.6999 - val_acc: 0.6063
Epoch 86/100
4652/4652 [==============================] - 1843s 396ms/step - loss: 0.0856 - acc: 0.9744 - val_loss: 4.1616 - val_acc: 0.5806
Epoch 87/100
 595/4652 [==>...........................] - ETA: 24:24 - loss: 0.0827 - acc: 0.9751
 