{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image, ImageOps\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "import matplotlib.image as mpimg\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'),\n",
       " PhysicalDevice(name='/physical_device:XLA_CPU:0', device_type='XLA_CPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'),\n",
       " PhysicalDevice(name='/physical_device:XLA_GPU:0', device_type='XLA_GPU')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ResNet50_MODEL=tf.keras.applications.ResNet50(input_shape=(224,224,3),\n",
    "                                               include_top=False,\n",
    "                                               weights=\"imagenet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "175"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ResNet50_MODEL.layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'conv2_block1_0_bn'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ResNet50_MODEL.layers[15].name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in ResNet50_MODEL.layers:\n",
    "    layer.trainable=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"resnet50\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 230, 230, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1_conv (Conv2D)             (None, 112, 112, 64) 9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1_bn (BatchNormalization)   (None, 112, 112, 64) 256         conv1_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1_relu (Activation)         (None, 112, 112, 64) 0           conv1_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 114, 114, 64) 0           conv1_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pool (MaxPooling2D)       (None, 56, 56, 64)   0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_conv (Conv2D)    (None, 56, 56, 64)   4160        pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_relu (Activation (None, 56, 56, 64)   0           conv2_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_relu (Activation (None, 56, 56, 64)   0           conv2_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_conv (Conv2D)    (None, 56, 56, 256)  16640       pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_add (Add)          (None, 56, 56, 256)  0           conv2_block1_0_bn[0][0]          \n",
      "                                                                 conv2_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_out (Activation)   (None, 56, 56, 256)  0           conv2_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_conv (Conv2D)    (None, 56, 56, 64)   16448       conv2_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_relu (Activation (None, 56, 56, 64)   0           conv2_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_relu (Activation (None, 56, 56, 64)   0           conv2_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_add (Add)          (None, 56, 56, 256)  0           conv2_block1_out[0][0]           \n",
      "                                                                 conv2_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_out (Activation)   (None, 56, 56, 256)  0           conv2_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_conv (Conv2D)    (None, 56, 56, 64)   16448       conv2_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_relu (Activation (None, 56, 56, 64)   0           conv2_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_relu (Activation (None, 56, 56, 64)   0           conv2_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_add (Add)          (None, 56, 56, 256)  0           conv2_block2_out[0][0]           \n",
      "                                                                 conv2_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_out (Activation)   (None, 56, 56, 256)  0           conv2_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_conv (Conv2D)    (None, 28, 28, 128)  32896       conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_relu (Activation (None, 28, 28, 128)  0           conv3_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_relu (Activation (None, 28, 28, 128)  0           conv3_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_conv (Conv2D)    (None, 28, 28, 512)  131584      conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_add (Add)          (None, 28, 28, 512)  0           conv3_block1_0_bn[0][0]          \n",
      "                                                                 conv3_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_out (Activation)   (None, 28, 28, 512)  0           conv3_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_relu (Activation (None, 28, 28, 128)  0           conv3_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_relu (Activation (None, 28, 28, 128)  0           conv3_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_add (Add)          (None, 28, 28, 512)  0           conv3_block1_out[0][0]           \n",
      "                                                                 conv3_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_out (Activation)   (None, 28, 28, 512)  0           conv3_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_relu (Activation (None, 28, 28, 128)  0           conv3_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_relu (Activation (None, 28, 28, 128)  0           conv3_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_add (Add)          (None, 28, 28, 512)  0           conv3_block2_out[0][0]           \n",
      "                                                                 conv3_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_out (Activation)   (None, 28, 28, 512)  0           conv3_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_relu (Activation (None, 28, 28, 128)  0           conv3_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_relu (Activation (None, 28, 28, 128)  0           conv3_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_add (Add)          (None, 28, 28, 512)  0           conv3_block3_out[0][0]           \n",
      "                                                                 conv3_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_out (Activation)   (None, 28, 28, 512)  0           conv3_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_conv (Conv2D)    (None, 14, 14, 256)  131328      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_relu (Activation (None, 14, 14, 256)  0           conv4_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_relu (Activation (None, 14, 14, 256)  0           conv4_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_conv (Conv2D)    (None, 14, 14, 1024) 525312      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_add (Add)          (None, 14, 14, 1024) 0           conv4_block1_0_bn[0][0]          \n",
      "                                                                 conv4_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_out (Activation)   (None, 14, 14, 1024) 0           conv4_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_relu (Activation (None, 14, 14, 256)  0           conv4_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_relu (Activation (None, 14, 14, 256)  0           conv4_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_add (Add)          (None, 14, 14, 1024) 0           conv4_block1_out[0][0]           \n",
      "                                                                 conv4_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_out (Activation)   (None, 14, 14, 1024) 0           conv4_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_relu (Activation (None, 14, 14, 256)  0           conv4_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_relu (Activation (None, 14, 14, 256)  0           conv4_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_add (Add)          (None, 14, 14, 1024) 0           conv4_block2_out[0][0]           \n",
      "                                                                 conv4_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_out (Activation)   (None, 14, 14, 1024) 0           conv4_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_relu (Activation (None, 14, 14, 256)  0           conv4_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_relu (Activation (None, 14, 14, 256)  0           conv4_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_add (Add)          (None, 14, 14, 1024) 0           conv4_block3_out[0][0]           \n",
      "                                                                 conv4_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_out (Activation)   (None, 14, 14, 1024) 0           conv4_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_relu (Activation (None, 14, 14, 256)  0           conv4_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_relu (Activation (None, 14, 14, 256)  0           conv4_block5_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block5_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block5_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_add (Add)          (None, 14, 14, 1024) 0           conv4_block4_out[0][0]           \n",
      "                                                                 conv4_block5_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_out (Activation)   (None, 14, 14, 1024) 0           conv4_block5_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block5_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_relu (Activation (None, 14, 14, 256)  0           conv4_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_relu (Activation (None, 14, 14, 256)  0           conv4_block6_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block6_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block6_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_add (Add)          (None, 14, 14, 1024) 0           conv4_block5_out[0][0]           \n",
      "                                                                 conv4_block6_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_out (Activation)   (None, 14, 14, 1024) 0           conv4_block6_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_conv (Conv2D)    (None, 7, 7, 512)    524800      conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_relu (Activation (None, 7, 7, 512)    0           conv5_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_relu (Activation (None, 7, 7, 512)    0           conv5_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_conv (Conv2D)    (None, 7, 7, 2048)   2099200     conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_add (Add)          (None, 7, 7, 2048)   0           conv5_block1_0_bn[0][0]          \n",
      "                                                                 conv5_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_out (Activation)   (None, 7, 7, 2048)   0           conv5_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_conv (Conv2D)    (None, 7, 7, 512)    1049088     conv5_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_relu (Activation (None, 7, 7, 512)    0           conv5_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_relu (Activation (None, 7, 7, 512)    0           conv5_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_add (Add)          (None, 7, 7, 2048)   0           conv5_block1_out[0][0]           \n",
      "                                                                 conv5_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_out (Activation)   (None, 7, 7, 2048)   0           conv5_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_conv (Conv2D)    (None, 7, 7, 512)    1049088     conv5_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_relu (Activation (None, 7, 7, 512)    0           conv5_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_relu (Activation (None, 7, 7, 512)    0           conv5_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_add (Add)          (None, 7, 7, 2048)   0           conv5_block2_out[0][0]           \n",
      "                                                                 conv5_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_out (Activation)   (None, 7, 7, 2048)   0           conv5_block3_add[0][0]           \n",
      "==================================================================================================\n",
      "Total params: 23,587,712\n",
      "Trainable params: 23,534,592\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "ResNet50_MODEL.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "l1_factor = 0.0001\n",
    "l2_factor = 0.001\n",
    "dropout = 0.5\n",
    "learning_rate = 0.0001\n",
    "target_size_image_shape = (224, 224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "resnet50 (Model)             (None, 7, 7, 2048)        23587712  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "Dropout_Regularization1 (Dro (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 3145)              6444105   \n",
      "=================================================================\n",
      "Total params: 30,031,817\n",
      "Trainable params: 29,978,697\n",
      "Non-trainable params: 53,120\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model=tf.keras.models.Sequential([\n",
    "                                  ResNet50_MODEL,\n",
    "                                  tf.keras.layers.GlobalAveragePooling2D(),\n",
    "                                  tf.keras.layers.Dropout(dropout, name='Dropout_Regularization1'),\n",
    "                                  tf.keras.layers.Dense(3145, activation='softmax')\n",
    "])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(lr=learning_rate)\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['acc'])\n",
    "train_data_dir = '../datasets/group9_set_224/set_224/train/'\n",
    "valid_data_dir = '../datasets/group9_set_224/set_224/valid/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1.0/255,\n",
    "    rotation_range=45,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    zoom_range=0.25,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    fill_mode='nearest')\n",
    "\n",
    "valid_datagen = ImageDataGenerator(rescale=1.0/255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 168612 images belonging to 3145 classes.\n"
     ]
    }
   ],
   "source": [
    "#flow training images\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=target_size_image_shape,\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 50320 images belonging to 3145 classes.\n"
     ]
    }
   ],
   "source": [
    "valid_generator = valid_datagen.flow_from_directory(\n",
    "    valid_data_dir,\n",
    "    target_size=target_size_image_shape,\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3145\n",
      "{0: '100051', 1: '100167', 2: '100191', 3: '100280', 4: '100338', 5: '100363', 6: '100485', 7: '100490', 8: '100569', 9: '100634', 10: '100682', 11: '100793', 12: '100908', 13: '101166', 14: '101212', 15: '101263', 16: '101460', 17: '101502', 18: '101633', 19: '101660', 20: '101666', 21: '101722', 22: '101728', 23: '10173', 24: '101760', 25: '101834', 26: '101875', 27: '101896', 28: '10196', 29: '101968', 30: '101998', 31: '102008', 32: '102089', 33: '102114', 34: '10221', 35: '102289', 36: '102447', 37: '102534', 38: '102568', 39: '10262', 40: '102643', 41: '102759', 42: '102840', 43: '103034', 44: '103068', 45: '103076', 46: '103099', 47: '103104', 48: '103130', 49: '103198', 50: '103407', 51: '103617', 52: '103692', 53: '103710', 54: '103729', 55: '103752', 56: '103774', 57: '103833', 58: '103847', 59: '103894', 60: '104038', 61: '104039', 62: '104111', 63: '104131', 64: '104141', 65: '104175', 66: '104235', 67: '104322', 68: '104431', 69: '104456', 70: '104503', 71: '104577', 72: '104632', 73: '104772', 74: '104774', 75: '104825', 76: '104846', 77: '104880', 78: '104938', 79: '105018', 80: '105162', 81: '105185', 82: '105233', 83: '105322', 84: '105340', 85: '105357', 86: '10539', 87: '105472', 88: '105494', 89: '105533', 90: '105665', 91: '105744', 92: '10575', 93: '10583', 94: '105870', 95: '106151', 96: '106230', 97: '106246', 98: '106286', 99: '10649', 100: '106546', 101: '106651', 102: '106665', 103: '106676', 104: '106681', 105: '106883', 106: '10691', 107: '107039', 108: '107145', 109: '107374', 110: '107474', 111: '107495', 112: '107600', 113: '107611', 114: '107642', 115: '107649', 116: '107689', 117: '107722', 118: '107747', 119: '10775', 120: '107754', 121: '107904', 122: '10809', 123: '108201', 124: '10825', 125: '108253', 126: '108281', 127: '108357', 128: '10839', 129: '108404', 130: '108449', 131: '108495', 132: '1085', 133: '10851', 134: '108757', 135: '108813', 136: '108853', 137: '108921', 138: '108936', 139: '108991', 140: '109014', 141: '109170', 142: '109205', 143: '109237', 144: '109256', 145: '109392', 146: '10940', 147: '109425', 148: '109434', 149: '109578', 150: '10959', 151: '10961', 152: '109632', 153: '10968', 154: '109750', 155: '109808', 156: '109908', 157: '109968', 158: '110048', 159: '110198', 160: '110224', 161: '110229', 162: '110239', 163: '110246', 164: '110321', 165: '110363', 166: '110385', 167: '110416', 168: '11043', 169: '110469', 170: '110510', 171: '11054', 172: '11059', 173: '110633', 174: '110640', 175: '110702', 176: '110739', 177: '110863', 178: '110946', 179: '110950', 180: '110960', 181: '111020', 182: '111157', 183: '111166', 184: '111239', 185: '111376', 186: '111468', 187: '111470', 188: '111492', 189: '111867', 190: '111896', 191: '111926', 192: '112024', 193: '112063', 194: '112115', 195: '112161', 196: '112168', 197: '112193', 198: '112201', 199: '112290', 200: '112356', 201: '112461', 202: '11256', 203: '112592', 204: '112621', 205: '112733', 206: '112785', 207: '112868', 208: '112888', 209: '112944', 210: '112960', 211: '113050', 212: '113128', 213: '113134', 214: '113146', 215: '113238', 216: '113318', 217: '113370', 218: '113433', 219: '113504', 220: '113539', 221: '11356', 222: '113611', 223: '113654', 224: '113698', 225: '113756', 226: '113955', 227: '1140', 228: '11400', 229: '11408', 230: '114168', 231: '114199', 232: '114208', 233: '114224', 234: '114390', 235: '114404', 236: '114408', 237: '114460', 238: '114491', 239: '114582', 240: '114595', 241: '114609', 242: '114846', 243: '114894', 244: '114986', 245: '114999', 246: '115038', 247: '11511', 248: '115196', 249: '115272', 250: '115305', 251: '115529', 252: '115927', 253: '11603', 254: '11606', 255: '11609', 256: '116117', 257: '116211', 258: '116214', 259: '116226', 260: '116312', 261: '116497', 262: '116554', 263: '116563', 264: '11663', 265: '116637', 266: '116689', 267: '116702', 268: '116745', 269: '116761', 270: '116772', 271: '116911', 272: '116954', 273: '11703', 274: '117051', 275: '117058', 276: '117061', 277: '117128', 278: '117249', 279: '117308', 280: '117317', 281: '117347', 282: '117350', 283: '117376', 284: '117379', 285: '117429', 286: '117487', 287: '117528', 288: '117623', 289: '117640', 290: '117685', 291: '117688', 292: '117697', 293: '117816', 294: '117819', 295: '117834', 296: '117862', 297: '117865', 298: '117927', 299: '11794', 300: '118074', 301: '118111', 302: '118182', 303: '118232', 304: '118450', 305: '118470', 306: '118579', 307: '118611', 308: '118663', 309: '118691', 310: '118766', 311: '118787', 312: '11879', 313: '118794', 314: '118862', 315: '11889', 316: '118948', 317: '118950', 318: '118979', 319: '119022', 320: '119296', 321: '119302', 322: '119369', 323: '119492', 324: '119521', 325: '119595', 326: '119660', 327: '119668', 328: '119683', 329: '119745', 330: '119784', 331: '11989', 332: '119931', 333: '11994', 334: '120180', 335: '120207', 336: '120270', 337: '12030', 338: '120304', 339: '120343', 340: '120351', 341: '120462', 342: '12049', 343: '120581', 344: '120687', 345: '120722', 346: '120793', 347: '121095', 348: '121132', 349: '12118', 350: '121314', 351: '121367', 352: '121385', 353: '121445', 354: '121462', 355: '121501', 356: '121548', 357: '121570', 358: '121647', 359: '121919', 360: '121931', 361: '12205', 362: '122075', 363: '122126', 364: '122139', 365: '122153', 366: '122171', 367: '122258', 368: '122265', 369: '122304', 370: '122516', 371: '12252', 372: '122529', 373: '122644', 374: '122665', 375: '122803', 376: '122831', 377: '122833', 378: '12287', 379: '122956', 380: '123131', 381: '123142', 382: '123147', 383: '123165', 384: '123166', 385: '123241', 386: '123313', 387: '123359', 388: '123479', 389: '123503', 390: '123517', 391: '123562', 392: '123650', 393: '123659', 394: '123662', 395: '123689', 396: '123697', 397: '123738', 398: '12375', 399: '123838', 400: '123875', 401: '123914', 402: '123923', 403: '123951', 404: '123976', 405: '123988', 406: '124078', 407: '124149', 408: '124200', 409: '124259', 410: '124309', 411: '124353', 412: '124358', 413: '12436', 414: '124408', 415: '124421', 416: '124461', 417: '124516', 418: '124524', 419: '12464', 420: '124643', 421: '124680', 422: '124718', 423: '12477', 424: '124835', 425: '124907', 426: '124953', 427: '125015', 428: '125017', 429: '125169', 430: '125181', 431: '125222', 432: '125478', 433: '125568', 434: '125589', 435: '125613', 436: '125729', 437: '125787', 438: '125802', 439: '125845', 440: '125858', 441: '125884', 442: '125886', 443: '125897', 444: '125929', 445: '125954', 446: '125992', 447: '12606', 448: '126133', 449: '126188', 450: '126199', 451: '126244', 452: '126255', 453: '126452', 454: '12647', 455: '126547', 456: '126598', 457: '126630', 458: '126672', 459: '126875', 460: '12691', 461: '127012', 462: '127072', 463: '127077', 464: '127084', 465: '12711', 466: '127186', 467: '12724', 468: '127290', 469: '12734', 470: '127445', 471: '127535', 472: '127549', 473: '127626', 474: '127638', 475: '127668', 476: '127739', 477: '127896', 478: '127900', 479: '128073', 480: '128126', 481: '128321', 482: '128360', 483: '12844', 484: '128544', 485: '128606', 486: '128627', 487: '128643', 488: '128649', 489: '128666', 490: '128680', 491: '128709', 492: '128730', 493: '128926', 494: '128933', 495: '128958', 496: '129016', 497: '129115', 498: '129134', 499: '12915', 500: '12923', 501: '129236', 502: '129366', 503: '12944', 504: '129553', 505: '129634', 506: '12965', 507: '129724', 508: '129732', 509: '129914', 510: '130025', 511: '13007', 512: '130087', 513: '130314', 514: '130331', 515: '130368', 516: '130432', 517: '130520', 518: '130568', 519: '130584', 520: '130596', 521: '130632', 522: '130714', 523: '130828', 524: '130843', 525: '13085', 526: '130864', 527: '130899', 528: '130940', 529: '130954', 530: '131042', 531: '131052', 532: '131162', 533: '131381', 534: '131411', 535: '131677', 536: '131782', 537: '131955', 538: '132288', 539: '132301', 540: '132336', 541: '132356', 542: '13236', 543: '132378', 544: '132465', 545: '132468', 546: '132610', 547: '132672', 548: '132715', 549: '132718', 550: '13272', 551: '132884', 552: '13297', 553: '133119', 554: '133152', 555: '133307', 556: '133334', 557: '133396', 558: '133425', 559: '133429', 560: '133457', 561: '133459', 562: '133466', 563: '133470', 564: '133479', 565: '133508', 566: '133515', 567: '133632', 568: '133633', 569: '133647', 570: '133653', 571: '133666', 572: '133679', 573: '133728', 574: '133878', 575: '133880', 576: '133898', 577: '134066', 578: '13416', 579: '134160', 580: '134165', 581: '134187', 582: '134293', 583: '134494', 584: '134575', 585: '134657', 586: '134706', 587: '134714', 588: '134793', 589: '134851', 590: '134872', 591: '134939', 592: '134951', 593: '13497', 594: '135143', 595: '135274', 596: '135323', 597: '135328', 598: '135374', 599: '135481', 600: '13560', 601: '135638', 602: '135645', 603: '135700', 604: '135776', 605: '135822', 606: '135836', 607: '135956', 608: '136050', 609: '136062', 610: '136128', 611: '136150', 612: '136166', 613: '136188', 614: '136303', 615: '136336', 616: '136354', 617: '136463', 618: '136511', 619: '136569', 620: '136684', 621: '136712', 622: '136735', 623: '136868', 624: '136899', 625: '136944', 626: '136964', 627: '137025', 628: '137058', 629: '137113', 630: '137149', 631: '137152', 632: '137167', 633: '137361', 634: '137391', 635: '137424', 636: '137508', 637: '13761', 638: '137662', 639: '137680', 640: '137702', 641: '137821', 642: '13787', 643: '137932', 644: '137952', 645: '13798', 646: '138082', 647: '138169', 648: '138178', 649: '138233', 650: '138360', 651: '138383', 652: '138460', 653: '138473', 654: '138483', 655: '138598', 656: '138692', 657: '13879', 658: '138795', 659: '138831', 660: '138857', 661: '138886', 662: '138906', 663: '138957', 664: '139', 665: '139201', 666: '139210', 667: '139297', 668: '139316', 669: '139344', 670: '139362', 671: '139370', 672: '139420', 673: '13950', 674: '139581', 675: '139600', 676: '139658', 677: '139663', 678: '139677', 679: '139705', 680: '13977', 681: '139776', 682: '139777', 683: '139792', 684: '139808', 685: '139893', 686: '139899', 687: '139924', 688: '139935', 689: '14009', 690: '140207', 691: '140213', 692: '140282', 693: '140311', 694: '140487', 695: '140556', 696: '140564', 697: '140590', 698: '140616', 699: '140671', 700: '140830', 701: '140845', 702: '140964', 703: '141113', 704: '141226', 705: '141241', 706: '141253', 707: '141266', 708: '141303', 709: '141365', 710: '141410', 711: '141427', 712: '141500', 713: '141592', 714: '141721', 715: '141779', 716: '141893', 717: '141925', 718: '141927', 719: '14197', 720: '141978', 721: '142093', 722: '142101', 723: '142154', 724: '142170', 725: '142201', 726: '142354', 727: '142387', 728: '142465', 729: '142663', 730: '142810', 731: '142890', 732: '142946', 733: '143091', 734: '143146', 735: '143204', 736: '143225', 737: '143258', 738: '143299', 739: '143329', 740: '143361', 741: '143423', 742: '143461', 743: '143537', 744: '143583', 745: '143651', 746: '143862', 747: '143872', 748: '143886', 749: '144005', 750: '144012', 751: '144069', 752: '144144', 753: '144164', 754: '144435', 755: '144532', 756: '144558', 757: '144593', 758: '144674', 759: '144762', 760: '144924', 761: '144963', 762: '144999', 763: '145', 764: '145065', 765: '145206', 766: '14522', 767: '145234', 768: '145237', 769: '145258', 770: '145259', 771: '145298', 772: '145345', 773: '145351', 774: '145398', 775: '14549', 776: '145534', 777: '145842', 778: '145877', 779: '145884', 780: '145897', 781: '145925', 782: '145970', 783: '145997', 784: '14612', 785: '146145', 786: '146162', 787: '146178', 788: '146243', 789: '146393', 790: '146416', 791: '146468', 792: '146480', 793: '146535', 794: '146545', 795: '146564', 796: '146570', 797: '146578', 798: '146666', 799: '146709', 800: '14671', 801: '146717', 802: '146776', 803: '146801', 804: '146839', 805: '146847', 806: '146894', 807: '1469', 808: '146968', 809: '147057', 810: '147125', 811: '147187', 812: '147296', 813: '147312', 814: '147365', 815: '147383', 816: '14739', 817: '147555', 818: '147588', 819: '147722', 820: '147765', 821: '147775', 822: '147835', 823: '147922', 824: '147944', 825: '148071', 826: '148214', 827: '148255', 828: '148348', 829: '14836', 830: '148392', 831: '148579', 832: '14862', 833: '148742', 834: '148798', 835: '148802', 836: '148811', 837: '148886', 838: '148967', 839: '148968', 840: '149000', 841: '149049', 842: '149054', 843: '149109', 844: '149142', 845: '149260', 846: '149285', 847: '149302', 848: '149346', 849: '149350', 850: '149380', 851: '149479', 852: '149518', 853: '149570', 854: '149696', 855: '149806', 856: '149815', 857: '149829', 858: '150012', 859: '150117', 860: '150175', 861: '150190', 862: '150201', 863: '15021', 864: '150302', 865: '150324', 866: '150397', 867: '150503', 868: '150524', 869: '150527', 870: '150579', 871: '15059', 872: '150612', 873: '150643', 874: '150843', 875: '150918', 876: '150977', 877: '15098', 878: '150984', 879: '151156', 880: '151220', 881: '15142', 882: '15146', 883: '151471', 884: '151535', 885: '151555', 886: '151652', 887: '151841', 888: '151966', 889: '151982', 890: '151999', 891: '1520', 892: '152053', 893: '152073', 894: '152082', 895: '152278', 896: '152315', 897: '152334', 898: '152341', 899: '152424', 900: '152490', 901: '152557', 902: '152596', 903: '152640', 904: '152728', 905: '152749', 906: '152754', 907: '152846', 908: '152896', 909: '152935', 910: '153014', 911: '153031', 912: '153227', 913: '153329', 914: '153423', 915: '153429', 916: '153708', 917: '153760', 918: '153821', 919: '154024', 920: '154122', 921: '154162', 922: '154251', 923: '154295', 924: '154306', 925: '154448', 926: '154492', 927: '154498', 928: '154534', 929: '154764', 930: '154798', 931: '154970', 932: '155119', 933: '15518', 934: '155224', 935: '155286', 936: '155329', 937: '155334', 938: '155377', 939: '15548', 940: '155526', 941: '155670', 942: '155802', 943: '155819', 944: '155860', 945: '15588', 946: '155886', 947: '155966', 948: '155995', 949: '156015', 950: '156135', 951: '15615', 952: '156176', 953: '156342', 954: '156481', 955: '156556', 956: '156600', 957: '156657', 958: '156658', 959: '156675', 960: '156682', 961: '156713', 962: '156741', 963: '156796', 964: '156817', 965: '156824', 966: '156864', 967: '156916', 968: '156931', 969: '156969', 970: '157033', 971: '15705', 972: '157052', 973: '157070', 974: '157122', 975: '157170', 976: '157185', 977: '157231', 978: '157276', 979: '1574', 980: '157455', 981: '157481', 982: '157652', 983: '157715', 984: '157753', 985: '158081', 986: '158085', 987: '158118', 988: '158171', 989: '158246', 990: '15833', 991: '158435', 992: '158448', 993: '158544', 994: '15859', 995: '158660', 996: '158685', 997: '158712', 998: '15876', 999: '158766', 1000: '15880', 1001: '158852', 1002: '159124', 1003: '159127', 1004: '159237', 1005: '159392', 1006: '159656', 1007: '159753', 1008: '159768', 1009: '159814', 1010: '159854', 1011: '15996', 1012: '16001', 1013: '160013', 1014: '160041', 1015: '160426', 1016: '160503', 1017: '160609', 1018: '16061', 1019: '160627', 1020: '16067', 1021: '160768', 1022: '160874', 1023: '16089', 1024: '160978', 1025: '161013', 1026: '161082', 1027: '161242', 1028: '161294', 1029: '161326', 1030: '16146', 1031: '161523', 1032: '161617', 1033: '161672', 1034: '161713', 1035: '161718', 1036: '161719', 1037: '161722', 1038: '161738', 1039: '161784', 1040: '161878', 1041: '161908', 1042: '161931', 1043: '161932', 1044: '162003', 1045: '162045', 1046: '162143', 1047: '162290', 1048: '162436', 1049: '162469', 1050: '162612', 1051: '16281', 1052: '162907', 1053: '162974', 1054: '162975', 1055: '163005', 1056: '163104', 1057: '163108', 1058: '16314', 1059: '163153', 1060: '163378', 1061: '163406', 1062: '163477', 1063: '163540', 1064: '16356', 1065: '16361', 1066: '163678', 1067: '163749', 1068: '163769', 1069: '16379', 1070: '163795', 1071: '163843', 1072: '163958', 1073: '163968', 1074: '164029', 1075: '164061', 1076: '164063', 1077: '164121', 1078: '164179', 1079: '164187', 1080: '16427', 1081: '164351', 1082: '164456', 1083: '164482', 1084: '164485', 1085: '164623', 1086: '164803', 1087: '164804', 1088: '164883', 1089: '165048', 1090: '165053', 1091: '165160', 1092: '165179', 1093: '16519', 1094: '165192', 1095: '165294', 1096: '165295', 1097: '165508', 1098: '165524', 1099: '165689', 1100: '165691', 1101: '165692', 1102: '165751', 1103: '166031', 1104: '166163', 1105: '166188', 1106: '16623', 1107: '166247', 1108: '166258', 1109: '166284', 1110: '16631', 1111: '166315', 1112: '166392', 1113: '166495', 1114: '166514', 1115: '166554', 1116: '166563', 1117: '166661', 1118: '166737', 1119: '166801', 1120: '166831', 1121: '166835', 1122: '166908', 1123: '166952', 1124: '16711', 1125: '167188', 1126: '167310', 1127: '167398', 1128: '167435', 1129: '167506', 1130: '167559', 1131: '167619', 1132: '167683', 1133: '16769', 1134: '167764', 1135: '167845', 1136: '167911', 1137: '167918', 1138: '167986', 1139: '167998', 1140: '168032', 1141: '168059', 1142: '168074', 1143: '168137', 1144: '168180', 1145: '168203', 1146: '168222', 1147: '168263', 1148: '168282', 1149: '16832', 1150: '168342', 1151: '168355', 1152: '168376', 1153: '16840', 1154: '168431', 1155: '168493', 1156: '168503', 1157: '168556', 1158: '168570', 1159: '168590', 1160: '168594', 1161: '168733', 1162: '168761', 1163: '168772', 1164: '16878', 1165: '168914', 1166: '168921', 1167: '16912', 1168: '169132', 1169: '169165', 1170: '169179', 1171: '169272', 1172: '169289', 1173: '16936', 1174: '169465', 1175: '169468', 1176: '169604', 1177: '16975', 1178: '169804', 1179: '169889', 1180: '169894', 1181: '16992', 1182: '169921', 1183: '169965', 1184: '170004', 1185: '170152', 1186: '170156', 1187: '170370', 1188: '170447', 1189: '170488', 1190: '170612', 1191: '170711', 1192: '170757', 1193: '170774', 1194: '170814', 1195: '170900', 1196: '170944', 1197: '170955', 1198: '171051', 1199: '171061', 1200: '171111', 1201: '171117', 1202: '171153', 1203: '171168', 1204: '171194', 1205: '171268', 1206: '171277', 1207: '171308', 1208: '17132', 1209: '171492', 1210: '17160', 1211: '171626', 1212: '171646', 1213: '171903', 1214: '171951', 1215: '172', 1216: '172008', 1217: '172040', 1218: '17212', 1219: '172124', 1220: '172163', 1221: '172176', 1222: '172214', 1223: '172336', 1224: '172412', 1225: '172438', 1226: '172463', 1227: '17279', 1228: '172835', 1229: '172881', 1230: '172891', 1231: '172941', 1232: '172957', 1233: '173151', 1234: '173224', 1235: '173229', 1236: '17326', 1237: '173291', 1238: '173311', 1239: '173336', 1240: '173462', 1241: '173513', 1242: '173522', 1243: '173556', 1244: '173576', 1245: '173609', 1246: '173850', 1247: '173882', 1248: '173948', 1249: '174011', 1250: '174046', 1251: '174106', 1252: '174130', 1253: '174155', 1254: '174193', 1255: '174205', 1256: '174215', 1257: '174226', 1258: '174305', 1259: '174421', 1260: '174523', 1261: '174547', 1262: '174563', 1263: '174579', 1264: '174654', 1265: '174672', 1266: '174696', 1267: '174748', 1268: '17476', 1269: '174763', 1270: '174926', 1271: '174957', 1272: '175087', 1273: '175189', 1274: '175201', 1275: '175219', 1276: '175237', 1277: '175469', 1278: '175527', 1279: '175815', 1280: '175842', 1281: '17586', 1282: '175880', 1283: '175906', 1284: '175919', 1285: '175950', 1286: '175982', 1287: '176078', 1288: '176087', 1289: '176155', 1290: '176312', 1291: '176357', 1292: '176484', 1293: '17657', 1294: '176646', 1295: '176653', 1296: '176707', 1297: '176834', 1298: '176878', 1299: '176891', 1300: '177025', 1301: '177093', 1302: '177199', 1303: '177219', 1304: '177253', 1305: '177335', 1306: '177350', 1307: '177440', 1308: '177530', 1309: '177626', 1310: '177677', 1311: '177682', 1312: '177687', 1313: '177690', 1314: '177724', 1315: '177731', 1316: '177761', 1317: '177774', 1318: '177871', 1319: '177968', 1320: '178027', 1321: '178111', 1322: '178127', 1323: '178128', 1324: '178286', 1325: '178300', 1326: '178312', 1327: '178366', 1328: '178472', 1329: '178514', 1330: '178544', 1331: '178698', 1332: '17872', 1333: '178721', 1334: '178793', 1335: '178809', 1336: '178931', 1337: '17905', 1338: '179113', 1339: '179194', 1340: '179230', 1341: '179247', 1342: '179348', 1343: '179369', 1344: '179382', 1345: '17949', 1346: '17960', 1347: '179602', 1348: '179648', 1349: '179650', 1350: '17991', 1351: '179986', 1352: '180008', 1353: '180085', 1354: '180111', 1355: '180158', 1356: '180256', 1357: '180257', 1358: '180360', 1359: '180361', 1360: '180462', 1361: '18048', 1362: '180676', 1363: '180802', 1364: '180986', 1365: '181042', 1366: '181075', 1367: '181082', 1368: '181083', 1369: '181130', 1370: '181239', 1371: '181267', 1372: '181281', 1373: '181362', 1374: '181526', 1375: '181535', 1376: '181539', 1377: '18159', 1378: '181639', 1379: '18165', 1380: '181659', 1381: '181701', 1382: '181739', 1383: '181743', 1384: '181786', 1385: '181947', 1386: '182052', 1387: '182069', 1388: '182162', 1389: '182220', 1390: '182262', 1391: '182317', 1392: '182583', 1393: '182604', 1394: '182654', 1395: '182668', 1396: '182683', 1397: '182693', 1398: '182737', 1399: '182775', 1400: '18282', 1401: '182942', 1402: '182971', 1403: '182990', 1404: '183071', 1405: '183093', 1406: '183236', 1407: '183241', 1408: '183252', 1409: '183322', 1410: '183397', 1411: '183405', 1412: '183447', 1413: '183767', 1414: '183804', 1415: '183838', 1416: '183843', 1417: '183883', 1418: '183901', 1419: '184038', 1420: '184122', 1421: '184160', 1422: '18418', 1423: '184309', 1424: '184330', 1425: '184371', 1426: '184388', 1427: '184470', 1428: '184484', 1429: '184758', 1430: '184767', 1431: '184835', 1432: '184959', 1433: '184962', 1434: '184976', 1435: '185012', 1436: '185094', 1437: '185101', 1438: '185116', 1439: '185158', 1440: '185168', 1441: '185182', 1442: '185193', 1443: '185319', 1444: '185324', 1445: '185392', 1446: '185420', 1447: '185510', 1448: '185559', 1449: '185735', 1450: '185775', 1451: '185829', 1452: '18598', 1453: '186043', 1454: '186070', 1455: '186171', 1456: '186221', 1457: '186365', 1458: '186374', 1459: '186438', 1460: '186439', 1461: '186607', 1462: '186645', 1463: '186743', 1464: '186803', 1465: '186860', 1466: '186954', 1467: '18700', 1468: '187106', 1469: '187123', 1470: '187191', 1471: '187205', 1472: '187215', 1473: '187288', 1474: '18739', 1475: '187423', 1476: '18746', 1477: '18751', 1478: '187537', 1479: '187565', 1480: '187594', 1481: '187628', 1482: '187643', 1483: '18767', 1484: '187670', 1485: '187672', 1486: '187685', 1487: '187717', 1488: '187737', 1489: '187851', 1490: '187861', 1491: '187882', 1492: '188055', 1493: '188070', 1494: '188108', 1495: '188119', 1496: '18837', 1497: '188473', 1498: '188550', 1499: '188553', 1500: '188599', 1501: '188647', 1502: '188650', 1503: '188778', 1504: '18881', 1505: '188817', 1506: '188952', 1507: '18901', 1508: '189010', 1509: '189016', 1510: '189136', 1511: '189218', 1512: '18932', 1513: '189349', 1514: '189414', 1515: '18942', 1516: '189620', 1517: '189715', 1518: '189788', 1519: '189808', 1520: '189913', 1521: '189945', 1522: '190074', 1523: '190106', 1524: '190173', 1525: '190191', 1526: '190241', 1527: '190334', 1528: '190374', 1529: '190400', 1530: '190433', 1531: '190466', 1532: '190515', 1533: '19053', 1534: '190573', 1535: '190577', 1536: '190595', 1537: '190613', 1538: '190632', 1539: '190708', 1540: '190711', 1541: '190717', 1542: '190740', 1543: '190781', 1544: '190842', 1545: '190953', 1546: '19096', 1547: '191050', 1548: '191062', 1549: '19121', 1550: '191293', 1551: '191338', 1552: '191362', 1553: '191493', 1554: '191568', 1555: '191603', 1556: '191650', 1557: '191756', 1558: '191774', 1559: '191892', 1560: '191898', 1561: '19191', 1562: '191978', 1563: '192047', 1564: '192056', 1565: '19218', 1566: '192292', 1567: '192334', 1568: '192468', 1569: '192505', 1570: '192524', 1571: '192584', 1572: '192614', 1573: '192637', 1574: '192794', 1575: '192925', 1576: '193026', 1577: '193082', 1578: '193154', 1579: '193258', 1580: '193292', 1581: '1933', 1582: '193343', 1583: '193358', 1584: '193381', 1585: '193383', 1586: '193419', 1587: '193482', 1588: '193486', 1589: '193560', 1590: '193631', 1591: '19368', 1592: '193738', 1593: '193745', 1594: '193746', 1595: '193954', 1596: '193978', 1597: '194071', 1598: '194094', 1599: '194101', 1600: '194189', 1601: '194286', 1602: '194297', 1603: '19430', 1604: '194340', 1605: '194407', 1606: '194427', 1607: '194449', 1608: '194475', 1609: '194505', 1610: '194523', 1611: '194613', 1612: '194818', 1613: '194827', 1614: '194872', 1615: '195021', 1616: '195090', 1617: '195263', 1618: '195335', 1619: '195358', 1620: '195363', 1621: '19545', 1622: '195513', 1623: '195542', 1624: '195619', 1625: '195749', 1626: '195909', 1627: '195921', 1628: '195930', 1629: '19601', 1630: '19611', 1631: '196149', 1632: '196216', 1633: '19653', 1634: '196834', 1635: '196838', 1636: '196948', 1637: '196961', 1638: '197014', 1639: '197070', 1640: '197083', 1641: '197087', 1642: '197244', 1643: '19733', 1644: '197429', 1645: '197433', 1646: '19747', 1647: '197487', 1648: '197510', 1649: '197747', 1650: '198014', 1651: '198053', 1652: '198144', 1653: '198184', 1654: '198267', 1655: '198384', 1656: '198416', 1657: '198417', 1658: '198489', 1659: '198519', 1660: '198527', 1661: '198570', 1662: '19859', 1663: '198594', 1664: '198614', 1665: '198643', 1666: '198647', 1667: '198702', 1668: '198713', 1669: '198821', 1670: '198885', 1671: '198895', 1672: '198951', 1673: '198970', 1674: '19899', 1675: '199', 1676: '199210', 1677: '199265', 1678: '199333', 1679: '199344', 1680: '19943', 1681: '199448', 1682: '199456', 1683: '199597', 1684: '199710', 1685: '19977', 1686: '199787', 1687: '199807', 1688: '199908', 1689: '199923', 1690: '199960', 1691: '199988', 1692: '200080', 1693: '200097', 1694: '200219', 1695: '200245', 1696: '200288', 1697: '200475', 1698: '200477', 1699: '20048', 1700: '200512', 1701: '200552', 1702: '200564', 1703: '200711', 1704: '200761', 1705: '200785', 1706: '200793', 1707: '200839', 1708: '200983', 1709: '201001', 1710: '201130', 1711: '201150', 1712: '201181', 1713: '201343', 1714: '201346', 1715: '201378', 1716: '201509', 1717: '201526', 1718: '20155', 1719: '201559', 1720: '201664', 1721: '201698', 1722: '201778', 1723: '201857', 1724: '201864', 1725: '201898', 1726: '202068', 1727: '202184', 1728: '202277', 1729: '202289', 1730: '20238', 1731: '202399', 1732: '202412', 1733: '202433', 1734: '202445', 1735: '202463', 1736: '202555', 1737: '202577', 1738: '202749', 1739: '202766', 1740: '202773', 1741: '20279', 1742: '202898', 1743: '202910', 1744: '202913', 1745: '202935', 1746: '202971', 1747: '202990', 1748: '203006', 1749: '203026', 1750: '20369', 1751: '20389', 1752: '20402', 1753: '20406', 1754: '20408', 1755: '20431', 1756: '2052', 1757: '20532', 1758: '20615', 1759: '20732', 1760: '20755', 1761: '20837', 1762: '20952', 1763: '21088', 1764: '21143', 1765: '21192', 1766: '21294', 1767: '21315', 1768: '21327', 1769: '21419', 1770: '2147', 1771: '21476', 1772: '21659', 1773: '21692', 1774: '21736', 1775: '2184', 1776: '21867', 1777: '21941', 1778: '22011', 1779: '22074', 1780: '22083', 1781: '22134', 1782: '22173', 1783: '22236', 1784: '22276', 1785: '22288', 1786: '22291', 1787: '22292', 1788: '22363', 1789: '22459', 1790: '2246', 1791: '22667', 1792: '22761', 1793: '22779', 1794: '22815', 1795: '22874', 1796: '2297', 1797: '23036', 1798: '23055', 1799: '23087', 1800: '2310', 1801: '23165', 1802: '23166', 1803: '23234', 1804: '23282', 1805: '2343', 1806: '23462', 1807: '2349', 1808: '23630', 1809: '23683', 1810: '23698', 1811: '23825', 1812: '23826', 1813: '23867', 1814: '23974', 1815: '24036', 1816: '24128', 1817: '2417', 1818: '24219', 1819: '24224', 1820: '2430', 1821: '24311', 1822: '2434', 1823: '2451', 1824: '24683', 1825: '24717', 1826: '24726', 1827: '24873', 1828: '24952', 1829: '24968', 1830: '25126', 1831: '25152', 1832: '25186', 1833: '25192', 1834: '25193', 1835: '25229', 1836: '2528', 1837: '25307', 1838: '25340', 1839: '25355', 1840: '25392', 1841: '25434', 1842: '25456', 1843: '25458', 1844: '25507', 1845: '25571', 1846: '2559', 1847: '25593', 1848: '25622', 1849: '25662', 1850: '25759', 1851: '25942', 1852: '25956', 1853: '25993', 1854: '2604', 1855: '26082', 1856: '26105', 1857: '26106', 1858: '2616', 1859: '26173', 1860: '26184', 1861: '26195', 1862: '26202', 1863: '26204', 1864: '26218', 1865: '26305', 1866: '2640', 1867: '26403', 1868: '26435', 1869: '26459', 1870: '26516', 1871: '26527', 1872: '26546', 1873: '26558', 1874: '26717', 1875: '26753', 1876: '26774', 1877: '26804', 1878: '26841', 1879: '26850', 1880: '26915', 1881: '27002', 1882: '27040', 1883: '27197', 1884: '27213', 1885: '2724', 1886: '27248', 1887: '27404', 1888: '27418', 1889: '27453', 1890: '27532', 1891: '27579', 1892: '27584', 1893: '27782', 1894: '27791', 1895: '278', 1896: '27881', 1897: '27914', 1898: '27945', 1899: '28140', 1900: '28193', 1901: '28220', 1902: '2840', 1903: '28429', 1904: '28444', 1905: '28482', 1906: '28540', 1907: '28652', 1908: '28768', 1909: '2887', 1910: '28982', 1911: '29102', 1912: '29124', 1913: '29225', 1914: '29226', 1915: '29300', 1916: '29349', 1917: '29450', 1918: '29515', 1919: '29556', 1920: '29562', 1921: '29603', 1922: '2963', 1923: '29754', 1924: '29767', 1925: '29776', 1926: '29970', 1927: '30012', 1928: '30019', 1929: '3003', 1930: '30112', 1931: '30268', 1932: '30301', 1933: '30302', 1934: '30358', 1935: '30373', 1936: '30532', 1937: '30588', 1938: '30609', 1939: '31008', 1940: '31045', 1941: '31075', 1942: '31163', 1943: '31195', 1944: '31269', 1945: '31334', 1946: '31437', 1947: '31542', 1948: '31601', 1949: '31678', 1950: '31730', 1951: '31793', 1952: '31820', 1953: '31841', 1954: '31889', 1955: '31980', 1956: '32219', 1957: '32231', 1958: '3228', 1959: '32335', 1960: '32347', 1961: '32348', 1962: '324', 1963: '32421', 1964: '32482', 1965: '32738', 1966: '32807', 1967: '32968', 1968: '33051', 1969: '33096', 1970: '33120', 1971: '33136', 1972: '33197', 1973: '33210', 1974: '3331', 1975: '33370', 1976: '33414', 1977: '33483', 1978: '33554', 1979: '33603', 1980: '33645', 1981: '33651', 1982: '33664', 1983: '33793', 1984: '3380', 1985: '33907', 1986: '33966', 1987: '34028', 1988: '34266', 1989: '34347', 1990: '34506', 1991: '34531', 1992: '34807', 1993: '34812', 1994: '34814', 1995: '34828', 1996: '34846', 1997: '3485', 1998: '34932', 1999: '34933', 2000: '34966', 2001: '35042', 2002: '35169', 2003: '35320', 2004: '35345', 2005: '354', 2006: '35508', 2007: '35510', 2008: '35533', 2009: '35536', 2010: '35683', 2011: '3574', 2012: '3578', 2013: '35783', 2014: '35843', 2015: '35864', 2016: '35918', 2017: '35946', 2018: '36015', 2019: '36080', 2020: '36088', 2021: '36158', 2022: '36160', 2023: '36216', 2024: '36275', 2025: '36308', 2026: '36320', 2027: '36345', 2028: '36359', 2029: '36419', 2030: '36511', 2031: '36542', 2032: '36675', 2033: '36737', 2034: '36861', 2035: '36868', 2036: '36882', 2037: '36928', 2038: '37046', 2039: '37063', 2040: '37087', 2041: '37154', 2042: '37267', 2043: '37356', 2044: '37366', 2045: '37374', 2046: '37381', 2047: '37518', 2048: '37589', 2049: '37844', 2050: '37907', 2051: '38055', 2052: '38099', 2053: '38152', 2054: '38168', 2055: '38236', 2056: '3825', 2057: '38275', 2058: '38292', 2059: '38296', 2060: '38302', 2061: '3835', 2062: '38508', 2063: '38596', 2064: '38784', 2065: '38986', 2066: '39021', 2067: '39090', 2068: '39151', 2069: '3923', 2070: '3927', 2071: '39361', 2072: '39384', 2073: '3951', 2074: '39521', 2075: '39547', 2076: '39572', 2077: '39592', 2078: '39599', 2079: '39799', 2080: '3981', 2081: '39833', 2082: '39942', 2083: '40002', 2084: '40010', 2085: '40074', 2086: '40092', 2087: '40136', 2088: '40205', 2089: '40309', 2090: '40367', 2091: '40409', 2092: '40582', 2093: '40652', 2094: '40676', 2095: '40712', 2096: '40715', 2097: '4073', 2098: '40733', 2099: '40741', 2100: '40953', 2101: '40979', 2102: '40981', 2103: '40990', 2104: '41128', 2105: '41161', 2106: '41217', 2107: '41291', 2108: '41372', 2109: '41392', 2110: '4153', 2111: '41547', 2112: '41583', 2113: '41654', 2114: '41720', 2115: '41768', 2116: '4177', 2117: '4180', 2118: '41828', 2119: '41840', 2120: '41870', 2121: '41874', 2122: '41936', 2123: '42099', 2124: '4212', 2125: '42157', 2126: '42183', 2127: '42243', 2128: '42452', 2129: '42462', 2130: '4253', 2131: '42548', 2132: '42614', 2133: '42755', 2134: '4283', 2135: '42881', 2136: '4293', 2137: '42945', 2138: '42950', 2139: '43095', 2140: '43155', 2141: '43175', 2142: '4321', 2143: '43212', 2144: '43323', 2145: '43403', 2146: '43487', 2147: '43728', 2148: '43799', 2149: '43884', 2150: '43898', 2151: '4390', 2152: '4391', 2153: '44023', 2154: '44119', 2155: '44158', 2156: '4417', 2157: '4418', 2158: '44253', 2159: '44444', 2160: '44476', 2161: '44479', 2162: '4450', 2163: '44509', 2164: '4455', 2165: '44609', 2166: '44615', 2167: '44700', 2168: '44785', 2169: '44824', 2170: '45000', 2171: '45012', 2172: '45051', 2173: '45173', 2174: '45282', 2175: '453', 2176: '45303', 2177: '45334', 2178: '45341', 2179: '45366', 2180: '45919', 2181: '45929', 2182: '45982', 2183: '46004', 2184: '46121', 2185: '46250', 2186: '46269', 2187: '46278', 2188: '46331', 2189: '46340', 2190: '4644', 2191: '46479', 2192: '46602', 2193: '4675', 2194: '46774', 2195: '46876', 2196: '46898', 2197: '46908', 2198: '46915', 2199: '47063', 2200: '47087', 2201: '47147', 2202: '47239', 2203: '47333', 2204: '47340', 2205: '47380', 2206: '47385', 2207: '47406', 2208: '47484', 2209: '4753', 2210: '47622', 2211: '47688', 2212: '47718', 2213: '47768', 2214: '47945', 2215: '47961', 2216: '48015', 2217: '48098', 2218: '48112', 2219: '4822', 2220: '48241', 2221: '48251', 2222: '48339', 2223: '48423', 2224: '48520', 2225: '48566', 2226: '48604', 2227: '48614', 2228: '48684', 2229: '48700', 2230: '48701', 2231: '48714', 2232: '48735', 2233: '48812', 2234: '4882', 2235: '48953', 2236: '48954', 2237: '48983', 2238: '49040', 2239: '49079', 2240: '49125', 2241: '49207', 2242: '49240', 2243: '49243', 2244: '49248', 2245: '49272', 2246: '49343', 2247: '49426', 2248: '49450', 2249: '49459', 2250: '49488', 2251: '49523', 2252: '49572', 2253: '49628', 2254: '4982', 2255: '49931', 2256: '50054', 2257: '50056', 2258: '50131', 2259: '5014', 2260: '50149', 2261: '50183', 2262: '5023', 2263: '50268', 2264: '50321', 2265: '50407', 2266: '50436', 2267: '50446', 2268: '50492', 2269: '50559', 2270: '50706', 2271: '50746', 2272: '50786', 2273: '50800', 2274: '50838', 2275: '50851', 2276: '50878', 2277: '50924', 2278: '51018', 2279: '51021', 2280: '5108', 2281: '51159', 2282: '51192', 2283: '51198', 2284: '51221', 2285: '51234', 2286: '51242', 2287: '51246', 2288: '51265', 2289: '51266', 2290: '51300', 2291: '51333', 2292: '51339', 2293: '51418', 2294: '51464', 2295: '5155', 2296: '5156', 2297: '51639', 2298: '51691', 2299: '51744', 2300: '51761', 2301: '51784', 2302: '51862', 2303: '51970', 2304: '52020', 2305: '52027', 2306: '52029', 2307: '52176', 2308: '52422', 2309: '52461', 2310: '52551', 2311: '52640', 2312: '5268', 2313: '52686', 2314: '52725', 2315: '52765', 2316: '52799', 2317: '52853', 2318: '52871', 2319: '52938', 2320: '52948', 2321: '52954', 2322: '52956', 2323: '52986', 2324: '53001', 2325: '53015', 2326: '53163', 2327: '53236', 2328: '53521', 2329: '53566', 2330: '53764', 2331: '53820', 2332: '53903', 2333: '53907', 2334: '53909', 2335: '53929', 2336: '53983', 2337: '53986', 2338: '54093', 2339: '541', 2340: '54157', 2341: '54272', 2342: '54364', 2343: '54413', 2344: '54526', 2345: '54612', 2346: '54633', 2347: '54656', 2348: '54735', 2349: '55007', 2350: '5501', 2351: '55023', 2352: '55111', 2353: '55128', 2354: '5529', 2355: '55381', 2356: '5543', 2357: '55459', 2358: '5547', 2359: '55472', 2360: '55577', 2361: '55631', 2362: '55649', 2363: '55809', 2364: '55815', 2365: '55853', 2366: '55866', 2367: '55941', 2368: '56062', 2369: '56131', 2370: '56308', 2371: '56357', 2372: '56444', 2373: '56536', 2374: '56564', 2375: '56622', 2376: '56646', 2377: '56728', 2378: '56764', 2379: '56877', 2380: '56904', 2381: '56909', 2382: '56920', 2383: '57071', 2384: '5719', 2385: '57195', 2386: '57228', 2387: '57316', 2388: '57436', 2389: '57472', 2390: '5749', 2391: '57610', 2392: '57688', 2393: '57821', 2394: '57897', 2395: '5791', 2396: '57973', 2397: '58029', 2398: '58030', 2399: '58071', 2400: '581', 2401: '58128', 2402: '58319', 2403: '58333', 2404: '58371', 2405: '58386', 2406: '58443', 2407: '58454', 2408: '58495', 2409: '58497', 2410: '58533', 2411: '58585', 2412: '58609', 2413: '58646', 2414: '58725', 2415: '5905', 2416: '59068', 2417: '59113', 2418: '59114', 2419: '59175', 2420: '59231', 2421: '59330', 2422: '59392', 2423: '59400', 2424: '59404', 2425: '59549', 2426: '59634', 2427: '59652', 2428: '59700', 2429: '59702', 2430: '59723', 2431: '59756', 2432: '59842', 2433: '5989', 2434: '59912', 2435: '60028', 2436: '60045', 2437: '6005', 2438: '60059', 2439: '60129', 2440: '60154', 2441: '60190', 2442: '60228', 2443: '60328', 2444: '60398', 2445: '60417', 2446: '6049', 2447: '60664', 2448: '60704', 2449: '60722', 2450: '60725', 2451: '60808', 2452: '61009', 2453: '61026', 2454: '61029', 2455: '61054', 2456: '61059', 2457: '61093', 2458: '61181', 2459: '6120', 2460: '61342', 2461: '61357', 2462: '61367', 2463: '6142', 2464: '61450', 2465: '61552', 2466: '61864', 2467: '619', 2468: '61995', 2469: '62065', 2470: '62079', 2471: '62096', 2472: '62154', 2473: '62165', 2474: '62235', 2475: '62286', 2476: '62302', 2477: '62306', 2478: '62338', 2479: '62344', 2480: '62384', 2481: '62445', 2482: '62543', 2483: '62580', 2484: '62584', 2485: '62622', 2486: '62647', 2487: '6276', 2488: '62761', 2489: '62799', 2490: '62805', 2491: '62809', 2492: '62813', 2493: '62849', 2494: '6286', 2495: '62962', 2496: '6300', 2497: '63003', 2498: '63013', 2499: '63137', 2500: '6314', 2501: '63141', 2502: '63228', 2503: '63238', 2504: '63244', 2505: '63579', 2506: '63621', 2507: '63660', 2508: '63757', 2509: '63764', 2510: '63775', 2511: '63800', 2512: '63847', 2513: '64122', 2514: '64125', 2515: '64203', 2516: '64388', 2517: '64574', 2518: '64607', 2519: '6463', 2520: '64696', 2521: '64766', 2522: '64787', 2523: '64837', 2524: '6490', 2525: '65106', 2526: '65111', 2527: '65146', 2528: '6517', 2529: '65207', 2530: '65298', 2531: '65338', 2532: '65395', 2533: '65406', 2534: '65410', 2535: '65460', 2536: '65461', 2537: '65530', 2538: '656', 2539: '65699', 2540: '65708', 2541: '65754', 2542: '65758', 2543: '65843', 2544: '65852', 2545: '65924', 2546: '65986', 2547: '65995', 2548: '6601', 2549: '66024', 2550: '66047', 2551: '66292', 2552: '66402', 2553: '66438', 2554: '66473', 2555: '66540', 2556: '66594', 2557: '66613', 2558: '66614', 2559: '66615', 2560: '66640', 2561: '66662', 2562: '66848', 2563: '66912', 2564: '66943', 2565: '66971', 2566: '67085', 2567: '67125', 2568: '67218', 2569: '6725', 2570: '67265', 2571: '67272', 2572: '67307', 2573: '67401', 2574: '67407', 2575: '67455', 2576: '67538', 2577: '67543', 2578: '67557', 2579: '67558', 2580: '67663', 2581: '67686', 2582: '67691', 2583: '6772', 2584: '67722', 2585: '67737', 2586: '67767', 2587: '67853', 2588: '67925', 2589: '68096', 2590: '6812', 2591: '6818', 2592: '68368', 2593: '6846', 2594: '68549', 2595: '6871', 2596: '6886', 2597: '68875', 2598: '68910', 2599: '69059', 2600: '6906', 2601: '69089', 2602: '691', 2603: '69105', 2604: '69138', 2605: '69361', 2606: '69376', 2607: '6940', 2608: '69453', 2609: '69546', 2610: '69560', 2611: '69635', 2612: '69661', 2613: '69696', 2614: '69758', 2615: '69768', 2616: '69887', 2617: '69890', 2618: '70033', 2619: '70041', 2620: '70054', 2621: '70134', 2622: '7016', 2623: '70276', 2624: '70336', 2625: '7035', 2626: '7039', 2627: '7043', 2628: '70443', 2629: '70578', 2630: '70633', 2631: '70658', 2632: '70698', 2633: '70744', 2634: '70768', 2635: '70838', 2636: '70950', 2637: '71023', 2638: '71038', 2639: '71092', 2640: '71093', 2641: '71192', 2642: '71257', 2643: '71352', 2644: '71426', 2645: '71475', 2646: '71493', 2647: '71541', 2648: '71616', 2649: '71702', 2650: '71730', 2651: '71738', 2652: '71853', 2653: '72005', 2654: '72029', 2655: '72074', 2656: '72135', 2657: '72168', 2658: '72240', 2659: '7227', 2660: '72290', 2661: '72298', 2662: '72442', 2663: '72598', 2664: '72638', 2665: '72662', 2666: '72685', 2667: '72724', 2668: '72809', 2669: '7282', 2670: '7283', 2671: '7284', 2672: '72959', 2673: '72997', 2674: '7307', 2675: '73094', 2676: '73122', 2677: '73216', 2678: '73219', 2679: '73254', 2680: '73318', 2681: '73323', 2682: '73328', 2683: '73346', 2684: '73363', 2685: '73391', 2686: '73469', 2687: '73489', 2688: '73542', 2689: '73570', 2690: '73581', 2691: '73582', 2692: '73664', 2693: '73736', 2694: '73742', 2695: '73789', 2696: '73836', 2697: '73914', 2698: '74087', 2699: '7409', 2700: '74228', 2701: '74258', 2702: '74335', 2703: '74400', 2704: '74423', 2705: '74476', 2706: '74523', 2707: '74651', 2708: '74704', 2709: '74749', 2710: '74823', 2711: '74978', 2712: '7499', 2713: '75016', 2714: '75058', 2715: '75073', 2716: '75138', 2717: '75154', 2718: '7519', 2719: '75252', 2720: '75289', 2721: '75296', 2722: '75297', 2723: '75321', 2724: '75322', 2725: '75386', 2726: '75389', 2727: '75496', 2728: '75505', 2729: '75579', 2730: '75616', 2731: '75650', 2732: '75713', 2733: '75735', 2734: '7580', 2735: '75817', 2736: '75859', 2737: '75862', 2738: '75864', 2739: '75914', 2740: '75999', 2741: '76059', 2742: '76175', 2743: '7618', 2744: '76201', 2745: '76273', 2746: '76405', 2747: '76441', 2748: '76482', 2749: '76506', 2750: '76525', 2751: '7656', 2752: '76647', 2753: '76818', 2754: '76819', 2755: '76855', 2756: '76923', 2757: '76956', 2758: '77124', 2759: '77204', 2760: '77289', 2761: '77367', 2762: '77382', 2763: '77403', 2764: '77405', 2765: '77472', 2766: '7749', 2767: '77593', 2768: '77711', 2769: '77808', 2770: '77842', 2771: '77906', 2772: '77907', 2773: '77982', 2774: '7809', 2775: '78142', 2776: '78171', 2777: '782', 2778: '78291', 2779: '78301', 2780: '78512', 2781: '78544', 2782: '78557', 2783: '78558', 2784: '78590', 2785: '78650', 2786: '78660', 2787: '78679', 2788: '78724', 2789: '78875', 2790: '79071', 2791: '79111', 2792: '79125', 2793: '79287', 2794: '79324', 2795: '79518', 2796: '79639', 2797: '7964', 2798: '79718', 2799: '79744', 2800: '79831', 2801: '79857', 2802: '79892', 2803: '79905', 2804: '7997', 2805: '80063', 2806: '80126', 2807: '80148', 2808: '8016', 2809: '80212', 2810: '80213', 2811: '80274', 2812: '80286', 2813: '80342', 2814: '80371', 2815: '80714', 2816: '80748', 2817: '80851', 2818: '80909', 2819: '81132', 2820: '81155', 2821: '81234', 2822: '81438', 2823: '81539', 2824: '81550', 2825: '81581', 2826: '81616', 2827: '81716', 2828: '81888', 2829: '81891', 2830: '81945', 2831: '81956', 2832: '81994', 2833: '8213', 2834: '82137', 2835: '82207', 2836: '82265', 2837: '82272', 2838: '82364', 2839: '82471', 2840: '82538', 2841: '82635', 2842: '82683', 2843: '82718', 2844: '8276', 2845: '82889', 2846: '82998', 2847: '83048', 2848: '83152', 2849: '83204', 2850: '83211', 2851: '83219', 2852: '83226', 2853: '83247', 2854: '83259', 2855: '83390', 2856: '83409', 2857: '83423', 2858: '83597', 2859: '83630', 2860: '83775', 2861: '8380', 2862: '83801', 2863: '83857', 2864: '83859', 2865: '83880', 2866: '83910', 2867: '83925', 2868: '83966', 2869: '84096', 2870: '84121', 2871: '84174', 2872: '84175', 2873: '84184', 2874: '84247', 2875: '84412', 2876: '84414', 2877: '84483', 2878: '84509', 2879: '84553', 2880: '84575', 2881: '84577', 2882: '84628', 2883: '84637', 2884: '84844', 2885: '84871', 2886: '84966', 2887: '85001', 2888: '85064', 2889: '85139', 2890: '85142', 2891: '85143', 2892: '85208', 2893: '85238', 2894: '85306', 2895: '85317', 2896: '85423', 2897: '85512', 2898: '85606', 2899: '85820', 2900: '85910', 2901: '85923', 2902: '86125', 2903: '86165', 2904: '86195', 2905: '86227', 2906: '86304', 2907: '86330', 2908: '86391', 2909: '86454', 2910: '86490', 2911: '8652', 2912: '86582', 2913: '86609', 2914: '86615', 2915: '86732', 2916: '8690', 2917: '87005', 2918: '87083', 2919: '8714', 2920: '87250', 2921: '873', 2922: '87389', 2923: '87461', 2924: '87485', 2925: '8749', 2926: '87735', 2927: '87887', 2928: '87895', 2929: '87935', 2930: '87972', 2931: '87982', 2932: '88022', 2933: '88035', 2934: '881', 2935: '88228', 2936: '88231', 2937: '88311', 2938: '88338', 2939: '88356', 2940: '88399', 2941: '88431', 2942: '8844', 2943: '88454', 2944: '88534', 2945: '88564', 2946: '88651', 2947: '88658', 2948: '88691', 2949: '88764', 2950: '88770', 2951: '88803', 2952: '88862', 2953: '88900', 2954: '89104', 2955: '89129', 2956: '89244', 2957: '89259', 2958: '89260', 2959: '89306', 2960: '89312', 2961: '89331', 2962: '89355', 2963: '89437', 2964: '89440', 2965: '89443', 2966: '89467', 2967: '89494', 2968: '89520', 2969: '89622', 2970: '8973', 2971: '89891', 2972: '89936', 2973: '89974', 2974: '8998', 2975: '90009', 2976: '90011', 2977: '90029', 2978: '90051', 2979: '90085', 2980: '901', 2981: '90118', 2982: '90142', 2983: '90175', 2984: '90275', 2985: '90394', 2986: '90424', 2987: '90672', 2988: '90724', 2989: '90902', 2990: '91110', 2991: '91136', 2992: '91146', 2993: '9115', 2994: '91348', 2995: '91399', 2996: '91549', 2997: '91691', 2998: '91795', 2999: '9189', 3000: '91980', 3001: '91983', 3002: '92170', 3003: '9222', 3004: '92226', 3005: '92335', 3006: '92363', 3007: '92421', 3008: '92432', 3009: '92475', 3010: '92519', 3011: '92724', 3012: '92746', 3013: '92762', 3014: '9278', 3015: '92809', 3016: '92831', 3017: '92901', 3018: '92919', 3019: '92957', 3020: '93025', 3021: '93050', 3022: '93055', 3023: '93102', 3024: '93111', 3025: '93221', 3026: '93369', 3027: '93376', 3028: '93387', 3029: '93420', 3030: '93513', 3031: '93662', 3032: '93768', 3033: '93827', 3034: '93904', 3035: '93959', 3036: '9396', 3037: '93993', 3038: '94037', 3039: '94081', 3040: '94127', 3041: '94351', 3042: '9438', 3043: '9463', 3044: '94686', 3045: '94764', 3046: '94786', 3047: '94932', 3048: '95007', 3049: '95030', 3050: '95094', 3051: '95195', 3052: '95245', 3053: '95293', 3054: '95323', 3055: '95341', 3056: '95455', 3057: '95506', 3058: '95507', 3059: '95516', 3060: '95609', 3061: '95664', 3062: '95963', 3063: '9597', 3064: '95999', 3065: '96093', 3066: '96120', 3067: '96152', 3068: '96179', 3069: '96197', 3070: '96236', 3071: '96270', 3072: '96335', 3073: '96354', 3074: '96365', 3075: '9640', 3076: '96403', 3077: '96506', 3078: '9651', 3079: '96525', 3080: '96558', 3081: '9681', 3082: '96833', 3083: '96898', 3084: '96922', 3085: '96936', 3086: '96941', 3087: '96986', 3088: '96991', 3089: '97013', 3090: '97015', 3091: '97018', 3092: '97134', 3093: '97153', 3094: '97176', 3095: '97210', 3096: '97228', 3097: '97292', 3098: '97387', 3099: '97420', 3100: '97441', 3101: '9745', 3102: '97469', 3103: '9756', 3104: '97742', 3105: '9775', 3106: '97756', 3107: '97784', 3108: '97840', 3109: '97895', 3110: '97976', 3111: '98043', 3112: '98062', 3113: '98136', 3114: '98197', 3115: '98205', 3116: '98253', 3117: '98323', 3118: '98472', 3119: '98514', 3120: '98652', 3121: '98703', 3122: '98741', 3123: '98759', 3124: '98885', 3125: '99049', 3126: '99147', 3127: '9921', 3128: '99260', 3129: '99283', 3130: '99330', 3131: '99352', 3132: '99401', 3133: '99409', 3134: '99486', 3135: '99524', 3136: '99545', 3137: '99664', 3138: '9969', 3139: '99713', 3140: '99777', 3141: '99800', 3142: '99836', 3143: '99872', 3144: '99994'}\n"
     ]
    }
   ],
   "source": [
    "indices_to_class_labels_dict = {value : key for key, value in train_generator.class_indices.items()}\n",
    "print(len(indices_to_class_labels_dict))\n",
    "print(indices_to_class_labels_dict)\n",
    "with open(\"group9_indices_to_class_labels_dict.json\", \"wb\") as pickle_file:\n",
    "    pickle.dump(indices_to_class_labels_dict, pickle_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputFolder = 'checkpoints_group9'\n",
    "if not os.path.exists(outputFolder):\n",
    "    os.makedirs(outputFolder)\n",
    "checkpoint_filepath=outputFolder+\"/model-{epoch:02d}-{val_acc:.2f}.hdf5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath, monitor='val_acc', verbose=1, mode='max',\n",
    "    save_best_only=True, save_weights_only=True,\n",
    "    save_frequency='epoch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "logs_outputFolder = 'logs_group9'\n",
    "if not os.path.exists(logs_outputFolder):\n",
    "    os.makedirs(logs_outputFolder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(\n",
    "    log_dir=logs_outputFolder, histogram_freq=1, write_graph=False, write_images=False,\n",
    "    update_freq='epoch', profile_batch=5, embeddings_freq=1,\n",
    "    embeddings_metadata=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2634/2634 [==============================] - ETA: 0s - loss: 6.4782 - acc: 0.0649\n",
      "Epoch 00001: val_acc improved from -inf to 0.23394, saving model to checkpoints_group9/model-01-0.23.hdf5\n",
      "2634/2634 [==============================] - 840s 319ms/step - loss: 6.4782 - acc: 0.0649 - val_loss: 4.4421 - val_acc: 0.2339\n",
      "Epoch 2/100\n",
      "2634/2634 [==============================] - ETA: 0s - loss: 4.1439 - acc: 0.2632\n",
      "Epoch 00002: val_acc improved from 0.23394 to 0.37677, saving model to checkpoints_group9/model-02-0.38.hdf5\n",
      "2634/2634 [==============================] - 843s 320ms/step - loss: 4.1439 - acc: 0.2632 - val_loss: 3.4550 - val_acc: 0.3768\n",
      "Epoch 3/100\n",
      "2634/2634 [==============================] - ETA: 0s - loss: 3.3236 - acc: 0.3735\n",
      "Epoch 00003: val_acc improved from 0.37677 to 0.43768, saving model to checkpoints_group9/model-03-0.44.hdf5\n",
      "2634/2634 [==============================] - 844s 320ms/step - loss: 3.3236 - acc: 0.3735 - val_loss: 3.0843 - val_acc: 0.4377\n",
      "Epoch 4/100\n",
      "2634/2634 [==============================] - ETA: 0s - loss: 2.8346 - acc: 0.4470\n",
      "Epoch 00004: val_acc improved from 0.43768 to 0.47911, saving model to checkpoints_group9/model-04-0.48.hdf5\n",
      "2634/2634 [==============================] - 843s 320ms/step - loss: 2.8346 - acc: 0.4470 - val_loss: 2.7868 - val_acc: 0.4791\n",
      "Epoch 5/100\n",
      "2634/2634 [==============================] - ETA: 0s - loss: 2.4757 - acc: 0.5006\n",
      "Epoch 00005: val_acc improved from 0.47911 to 0.50545, saving model to checkpoints_group9/model-05-0.51.hdf5\n",
      "2634/2634 [==============================] - 842s 320ms/step - loss: 2.4757 - acc: 0.5006 - val_loss: 2.6780 - val_acc: 0.5055\n",
      "Epoch 6/100\n",
      "2634/2634 [==============================] - ETA: 0s - loss: 2.2038 - acc: 0.5449\n",
      "Epoch 00006: val_acc improved from 0.50545 to 0.53484, saving model to checkpoints_group9/model-06-0.53.hdf5\n",
      "2634/2634 [==============================] - 847s 322ms/step - loss: 2.2038 - acc: 0.5449 - val_loss: 2.5163 - val_acc: 0.5348\n",
      "Epoch 7/100\n",
      "2634/2634 [==============================] - ETA: 0s - loss: 1.9731 - acc: 0.5822\n",
      "Epoch 00007: val_acc improved from 0.53484 to 0.54238, saving model to checkpoints_group9/model-07-0.54.hdf5\n",
      "2634/2634 [==============================] - 847s 322ms/step - loss: 1.9731 - acc: 0.5822 - val_loss: 2.4930 - val_acc: 0.5424\n",
      "Epoch 8/100\n",
      "2634/2634 [==============================] - ETA: 0s - loss: 1.7788 - acc: 0.6148\n",
      "Epoch 00008: val_acc did not improve from 0.54238\n",
      "2634/2634 [==============================] - 840s 319ms/step - loss: 1.7788 - acc: 0.6148 - val_loss: 2.7336 - val_acc: 0.5221\n",
      "Epoch 9/100\n",
      "2634/2634 [==============================] - ETA: 0s - loss: 1.6186 - acc: 0.6426\n",
      "Epoch 00009: val_acc did not improve from 0.54238\n",
      "2634/2634 [==============================] - 840s 319ms/step - loss: 1.6186 - acc: 0.6426 - val_loss: 2.7609 - val_acc: 0.5131\n",
      "Epoch 10/100\n",
      "2634/2634 [==============================] - ETA: 0s - loss: 1.4739 - acc: 0.6668\n",
      "Epoch 00010: val_acc improved from 0.54238 to 0.57016, saving model to checkpoints_group9/model-10-0.57.hdf5\n",
      "2634/2634 [==============================] - 840s 319ms/step - loss: 1.4739 - acc: 0.6668 - val_loss: 2.4615 - val_acc: 0.5702\n",
      "Epoch 11/100\n",
      "2634/2634 [==============================] - ETA: 0s - loss: 1.3525 - acc: 0.6895\n",
      "Epoch 00011: val_acc improved from 0.57016 to 0.58761, saving model to checkpoints_group9/model-11-0.59.hdf5\n",
      "2634/2634 [==============================] - 840s 319ms/step - loss: 1.3525 - acc: 0.6895 - val_loss: 2.3969 - val_acc: 0.5876\n",
      "Epoch 12/100\n",
      "2634/2634 [==============================] - ETA: 0s - loss: 1.2374 - acc: 0.7112\n",
      "Epoch 00012: val_acc did not improve from 0.58761\n",
      "2634/2634 [==============================] - 839s 319ms/step - loss: 1.2374 - acc: 0.7112 - val_loss: 2.4234 - val_acc: 0.5810\n",
      "Epoch 13/100\n",
      "2634/2634 [==============================] - ETA: 0s - loss: 1.1411 - acc: 0.7295\n",
      "Epoch 00013: val_acc did not improve from 0.58761\n",
      "2634/2634 [==============================] - 840s 319ms/step - loss: 1.1411 - acc: 0.7295 - val_loss: 2.4493 - val_acc: 0.5805\n",
      "Epoch 14/100\n",
      "2634/2634 [==============================] - ETA: 0s - loss: 1.0481 - acc: 0.7465\n",
      "Epoch 00014: val_acc improved from 0.58761 to 0.60196, saving model to checkpoints_group9/model-14-0.60.hdf5\n",
      "2634/2634 [==============================] - 839s 319ms/step - loss: 1.0481 - acc: 0.7465 - val_loss: 2.3907 - val_acc: 0.6020\n",
      "Epoch 15/100\n",
      "2634/2634 [==============================] - ETA: 0s - loss: 0.9696 - acc: 0.7616\n",
      "Epoch 00015: val_acc improved from 0.60196 to 0.60445, saving model to checkpoints_group9/model-15-0.60.hdf5\n",
      "2634/2634 [==============================] - 839s 318ms/step - loss: 0.9696 - acc: 0.7616 - val_loss: 2.3663 - val_acc: 0.6044\n",
      "Epoch 16/100\n",
      "2634/2634 [==============================] - ETA: 0s - loss: 0.8995 - acc: 0.7761\n",
      "Epoch 00016: val_acc did not improve from 0.60445\n",
      "2634/2634 [==============================] - 838s 318ms/step - loss: 0.8995 - acc: 0.7761 - val_loss: 2.5597 - val_acc: 0.5745\n",
      "Epoch 17/100\n",
      "2634/2634 [==============================] - ETA: 0s - loss: 0.8335 - acc: 0.7895\n",
      "Epoch 00017: val_acc improved from 0.60445 to 0.60703, saving model to checkpoints_group9/model-17-0.61.hdf5\n",
      "2634/2634 [==============================] - 842s 320ms/step - loss: 0.8335 - acc: 0.7895 - val_loss: 2.4219 - val_acc: 0.6070\n",
      "Epoch 18/100\n",
      "2634/2634 [==============================] - ETA: 0s - loss: 0.7770 - acc: 0.8018\n",
      "Epoch 00018: val_acc improved from 0.60703 to 0.60747, saving model to checkpoints_group9/model-18-0.61.hdf5\n",
      "2634/2634 [==============================] - 841s 319ms/step - loss: 0.7770 - acc: 0.8018 - val_loss: 2.3799 - val_acc: 0.6075\n",
      "Epoch 19/100\n",
      "2634/2634 [==============================] - ETA: 0s - loss: 0.7181 - acc: 0.8150\n",
      "Epoch 00019: val_acc did not improve from 0.60747\n",
      "2634/2634 [==============================] - 842s 320ms/step - loss: 0.7181 - acc: 0.8150 - val_loss: 3.2411 - val_acc: 0.5147\n",
      "Epoch 20/100\n",
      "2634/2634 [==============================] - ETA: 0s - loss: 0.6659 - acc: 0.8264\n",
      "Epoch 00020: val_acc did not improve from 0.60747\n",
      "2634/2634 [==============================] - 850s 323ms/step - loss: 0.6659 - acc: 0.8264 - val_loss: 2.5483 - val_acc: 0.6066\n",
      "Epoch 21/100\n",
      "2634/2634 [==============================] - ETA: 0s - loss: 0.6250 - acc: 0.8346\n",
      "Epoch 00021: val_acc did not improve from 0.60747\n",
      "2634/2634 [==============================] - 840s 319ms/step - loss: 0.6250 - acc: 0.8346 - val_loss: 2.5519 - val_acc: 0.5999\n",
      "Epoch 22/100\n",
      "2634/2634 [==============================] - ETA: 0s - loss: 0.5916 - acc: 0.8434\n",
      "Epoch 00022: val_acc did not improve from 0.60747\n",
      "2634/2634 [==============================] - 836s 317ms/step - loss: 0.5916 - acc: 0.8434 - val_loss: 2.6674 - val_acc: 0.6033\n",
      "Epoch 23/100\n",
      "2634/2634 [==============================] - ETA: 0s - loss: 0.5499 - acc: 0.8530\n",
      "Epoch 00023: val_acc improved from 0.60747 to 0.62084, saving model to checkpoints_group9/model-23-0.62.hdf5\n",
      "2634/2634 [==============================] - 843s 320ms/step - loss: 0.5499 - acc: 0.8530 - val_loss: 2.5122 - val_acc: 0.6208\n",
      "Epoch 24/100\n",
      "2634/2634 [==============================] - ETA: 0s - loss: 0.5188 - acc: 0.8600\n",
      "Epoch 00024: val_acc did not improve from 0.62084\n",
      "2634/2634 [==============================] - 842s 320ms/step - loss: 0.5188 - acc: 0.8600 - val_loss: 2.5733 - val_acc: 0.6128\n",
      "Epoch 25/100\n",
      "2634/2634 [==============================] - ETA: 0s - loss: 0.4942 - acc: 0.8660\n",
      "Epoch 00025: val_acc did not improve from 0.62084\n",
      "2634/2634 [==============================] - 841s 319ms/step - loss: 0.4942 - acc: 0.8660 - val_loss: 3.0271 - val_acc: 0.5863\n",
      "Epoch 26/100\n",
      "2634/2634 [==============================] - ETA: 0s - loss: 0.4650 - acc: 0.8727\n",
      "Epoch 00026: val_acc did not improve from 0.62084\n",
      "2634/2634 [==============================] - 842s 320ms/step - loss: 0.4650 - acc: 0.8727 - val_loss: 2.8979 - val_acc: 0.5949\n",
      "Epoch 27/100\n",
      "2634/2634 [==============================] - ETA: 0s - loss: 0.4406 - acc: 0.8785\n",
      "Epoch 00027: val_acc did not improve from 0.62084\n",
      "2634/2634 [==============================] - 841s 319ms/step - loss: 0.4406 - acc: 0.8785 - val_loss: 2.9558 - val_acc: 0.5931\n",
      "Epoch 28/100\n",
      "2634/2634 [==============================] - ETA: 0s - loss: 0.4184 - acc: 0.8849\n",
      "Epoch 00028: val_acc improved from 0.62084 to 0.63574, saving model to checkpoints_group9/model-28-0.64.hdf5\n",
      "2634/2634 [==============================] - 839s 318ms/step - loss: 0.4184 - acc: 0.8849 - val_loss: 2.5434 - val_acc: 0.6357\n",
      "Epoch 29/100\n",
      "2634/2634 [==============================] - ETA: 0s - loss: 0.4019 - acc: 0.8889\n",
      "Epoch 00029: val_acc did not improve from 0.63574\n",
      "2634/2634 [==============================] - 834s 317ms/step - loss: 0.4019 - acc: 0.8889 - val_loss: 2.8749 - val_acc: 0.6103\n",
      "Epoch 30/100\n",
      "2634/2634 [==============================] - ETA: 0s - loss: 0.3787 - acc: 0.8947\n",
      "Epoch 00030: val_acc did not improve from 0.63574\n",
      "2634/2634 [==============================] - 835s 317ms/step - loss: 0.3787 - acc: 0.8947 - val_loss: 2.6727 - val_acc: 0.6217\n",
      "Epoch 31/100\n",
      "2634/2634 [==============================] - ETA: 0s - loss: 0.3642 - acc: 0.8982\n",
      "Epoch 00031: val_acc did not improve from 0.63574\n",
      "2634/2634 [==============================] - 838s 318ms/step - loss: 0.3642 - acc: 0.8982 - val_loss: 2.8432 - val_acc: 0.5999\n",
      "Epoch 32/100\n",
      "2634/2634 [==============================] - ETA: 0s - loss: 0.3443 - acc: 0.9049\n",
      "Epoch 00032: val_acc did not improve from 0.63574\n",
      "2634/2634 [==============================] - 840s 319ms/step - loss: 0.3443 - acc: 0.9049 - val_loss: 2.8756 - val_acc: 0.6207\n",
      "Epoch 33/100\n",
      "2634/2634 [==============================] - ETA: 0s - loss: 0.3331 - acc: 0.9063\n",
      "Epoch 00033: val_acc did not improve from 0.63574\n",
      "2634/2634 [==============================] - 839s 318ms/step - loss: 0.3331 - acc: 0.9063 - val_loss: 2.6346 - val_acc: 0.6334\n",
      "Epoch 34/100\n",
      "2634/2634 [==============================] - ETA: 0s - loss: 0.3256 - acc: 0.9083\n",
      "Epoch 00034: val_acc did not improve from 0.63574\n",
      "2634/2634 [==============================] - 838s 318ms/step - loss: 0.3256 - acc: 0.9083 - val_loss: 3.0504 - val_acc: 0.5883\n",
      "Epoch 35/100\n",
      "2634/2634 [==============================] - ETA: 0s - loss: 0.3115 - acc: 0.9124\n",
      "Epoch 00035: val_acc did not improve from 0.63574\n",
      "2634/2634 [==============================] - 835s 317ms/step - loss: 0.3115 - acc: 0.9124 - val_loss: 2.8670 - val_acc: 0.6284\n",
      "Epoch 36/100\n",
      "2634/2634 [==============================] - ETA: 0s - loss: 0.2941 - acc: 0.9173\n",
      "Epoch 00036: val_acc did not improve from 0.63574\n",
      "2634/2634 [==============================] - 835s 317ms/step - loss: 0.2941 - acc: 0.9173 - val_loss: 2.9080 - val_acc: 0.6213\n",
      "Epoch 37/100\n",
      "2634/2634 [==============================] - ETA: 0s - loss: 0.2899 - acc: 0.9180\n",
      "Epoch 00037: val_acc did not improve from 0.63574\n",
      "2634/2634 [==============================] - 835s 317ms/step - loss: 0.2899 - acc: 0.9180 - val_loss: 2.9818 - val_acc: 0.6114\n",
      "Epoch 38/100\n",
      "2634/2634 [==============================] - ETA: 0s - loss: 0.2792 - acc: 0.9208\n",
      "Epoch 00038: val_acc did not improve from 0.63574\n",
      "2634/2634 [==============================] - 836s 317ms/step - loss: 0.2792 - acc: 0.9208 - val_loss: 3.1405 - val_acc: 0.5988\n",
      "Epoch 39/100\n",
      "2634/2634 [==============================] - ETA: 0s - loss: 0.2704 - acc: 0.9239\n",
      "Epoch 00039: val_acc did not improve from 0.63574\n",
      "2634/2634 [==============================] - 836s 317ms/step - loss: 0.2704 - acc: 0.9239 - val_loss: 2.8501 - val_acc: 0.6290\n",
      "Epoch 40/100\n",
      "2634/2634 [==============================] - ETA: 0s - loss: 0.2568 - acc: 0.9280\n",
      "Epoch 00040: val_acc did not improve from 0.63574\n",
      "2634/2634 [==============================] - 836s 317ms/step - loss: 0.2568 - acc: 0.9280 - val_loss: 3.1660 - val_acc: 0.6190\n",
      "Epoch 41/100\n",
      "2634/2634 [==============================] - ETA: 0s - loss: 0.2536 - acc: 0.9276\n",
      "Epoch 00041: val_acc improved from 0.63574 to 0.63871, saving model to checkpoints_group9/model-41-0.64.hdf5\n",
      "2634/2634 [==============================] - 836s 317ms/step - loss: 0.2536 - acc: 0.9276 - val_loss: 3.0096 - val_acc: 0.6387\n",
      "Epoch 42/100\n",
      "2634/2634 [==============================] - ETA: 0s - loss: 0.2473 - acc: 0.9303\n",
      "Epoch 00042: val_acc did not improve from 0.63871\n",
      "2634/2634 [==============================] - 835s 317ms/step - loss: 0.2473 - acc: 0.9303 - val_loss: 2.9255 - val_acc: 0.6317\n",
      "Epoch 43/100\n",
      "2634/2634 [==============================] - ETA: 0s - loss: 0.2400 - acc: 0.9320\n",
      "Epoch 00043: val_acc did not improve from 0.63871\n",
      "2634/2634 [==============================] - 835s 317ms/step - loss: 0.2400 - acc: 0.9320 - val_loss: 3.2341 - val_acc: 0.6075\n",
      "Epoch 44/100\n",
      "2634/2634 [==============================] - ETA: 0s - loss: 0.2340 - acc: 0.9330\n",
      "Epoch 00044: val_acc did not improve from 0.63871\n",
      "2634/2634 [==============================] - 835s 317ms/step - loss: 0.2340 - acc: 0.9330 - val_loss: 3.4013 - val_acc: 0.5970\n",
      "Epoch 45/100\n",
      "2634/2634 [==============================] - ETA: 0s - loss: 0.2213 - acc: 0.9369\n",
      "Epoch 00045: val_acc did not improve from 0.63871\n",
      "2634/2634 [==============================] - 836s 317ms/step - loss: 0.2213 - acc: 0.9369 - val_loss: 3.3823 - val_acc: 0.5997\n",
      "Epoch 46/100\n",
      "2634/2634 [==============================] - ETA: 0s - loss: 0.2174 - acc: 0.9376\n",
      "Epoch 00046: val_acc did not improve from 0.63871\n",
      "2634/2634 [==============================] - 836s 317ms/step - loss: 0.2174 - acc: 0.9376 - val_loss: 3.2598 - val_acc: 0.6139\n",
      "Epoch 47/100\n",
      "2634/2634 [==============================] - ETA: 0s - loss: 0.2162 - acc: 0.9384\n",
      "Epoch 00047: val_acc did not improve from 0.63871\n",
      "2634/2634 [==============================] - 835s 317ms/step - loss: 0.2162 - acc: 0.9384 - val_loss: 3.1358 - val_acc: 0.6283\n",
      "Epoch 48/100\n",
      "2634/2634 [==============================] - ETA: 0s - loss: 0.2127 - acc: 0.9391\n",
      "Epoch 00048: val_acc did not improve from 0.63871\n",
      "2634/2634 [==============================] - 835s 317ms/step - loss: 0.2127 - acc: 0.9391 - val_loss: 3.1134 - val_acc: 0.6183\n",
      "Epoch 49/100\n",
      "2634/2634 [==============================] - ETA: 0s - loss: 0.2054 - acc: 0.9409\n",
      "Epoch 00049: val_acc did not improve from 0.63871\n",
      "2634/2634 [==============================] - 835s 317ms/step - loss: 0.2054 - acc: 0.9409 - val_loss: 3.1302 - val_acc: 0.6318\n",
      "Epoch 50/100\n",
      "2634/2634 [==============================] - ETA: 0s - loss: 0.1988 - acc: 0.9428\n",
      "Epoch 00050: val_acc did not improve from 0.63871\n",
      "2634/2634 [==============================] - 835s 317ms/step - loss: 0.1988 - acc: 0.9428 - val_loss: 3.3104 - val_acc: 0.6212\n",
      "Epoch 51/100\n",
      "2634/2634 [==============================] - ETA: 0s - loss: 0.1903 - acc: 0.9447\n",
      "Epoch 00051: val_acc did not improve from 0.63871\n",
      "2634/2634 [==============================] - 835s 317ms/step - loss: 0.1903 - acc: 0.9447 - val_loss: 3.1412 - val_acc: 0.6195\n",
      "Epoch 52/100\n",
      "2634/2634 [==============================] - ETA: 0s - loss: 0.1885 - acc: 0.9457\n",
      "Epoch 00052: val_acc did not improve from 0.63871\n",
      "2634/2634 [==============================] - 835s 317ms/step - loss: 0.1885 - acc: 0.9457 - val_loss: 3.4688 - val_acc: 0.5897\n",
      "Epoch 53/100\n",
      "2634/2634 [==============================] - ETA: 0s - loss: 0.1848 - acc: 0.9463\n",
      "Epoch 00053: val_acc did not improve from 0.63871\n",
      "2634/2634 [==============================] - 835s 317ms/step - loss: 0.1848 - acc: 0.9463 - val_loss: 3.2150 - val_acc: 0.6247\n",
      "Epoch 54/100\n",
      "2634/2634 [==============================] - ETA: 0s - loss: 0.1810 - acc: 0.9478\n",
      "Epoch 00054: val_acc did not improve from 0.63871\n",
      "2634/2634 [==============================] - 835s 317ms/step - loss: 0.1810 - acc: 0.9478 - val_loss: 3.1232 - val_acc: 0.6380\n",
      "Epoch 55/100\n",
      "2634/2634 [==============================] - ETA: 0s - loss: 0.1809 - acc: 0.9474\n",
      "Epoch 00055: val_acc did not improve from 0.63871\n",
      "2634/2634 [==============================] - 835s 317ms/step - loss: 0.1809 - acc: 0.9474 - val_loss: 3.3921 - val_acc: 0.6130\n",
      "Epoch 56/100\n",
      "2634/2634 [==============================] - ETA: 0s - loss: 0.1747 - acc: 0.9495\n",
      "Epoch 00056: val_acc did not improve from 0.63871\n",
      "2634/2634 [==============================] - 835s 317ms/step - loss: 0.1747 - acc: 0.9495 - val_loss: 3.1170 - val_acc: 0.6150\n",
      "Epoch 57/100\n",
      "2634/2634 [==============================] - ETA: 0s - loss: 0.1711 - acc: 0.9503\n",
      "Epoch 00057: val_acc did not improve from 0.63871\n",
      "2634/2634 [==============================] - 836s 317ms/step - loss: 0.1711 - acc: 0.9503 - val_loss: 3.6725 - val_acc: 0.5714\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/100\n",
      "2634/2634 [==============================] - ETA: 0s - loss: 0.1686 - acc: 0.9507\n",
      "Epoch 00058: val_acc improved from 0.63871 to 0.64199, saving model to checkpoints_group9/model-58-0.64.hdf5\n",
      "2634/2634 [==============================] - 836s 317ms/step - loss: 0.1686 - acc: 0.9507 - val_loss: 3.1740 - val_acc: 0.6420\n",
      "Epoch 59/100\n",
      "2634/2634 [==============================] - ETA: 0s - loss: 0.1671 - acc: 0.9515\n",
      "Epoch 00059: val_acc did not improve from 0.64199\n",
      "2634/2634 [==============================] - 835s 317ms/step - loss: 0.1671 - acc: 0.9515 - val_loss: 3.2564 - val_acc: 0.6156\n",
      "Epoch 60/100\n",
      "2634/2634 [==============================] - ETA: 0s - loss: 0.1633 - acc: 0.9525\n",
      "Epoch 00060: val_acc did not improve from 0.64199\n",
      "2634/2634 [==============================] - 835s 317ms/step - loss: 0.1633 - acc: 0.9525 - val_loss: 3.3788 - val_acc: 0.6230\n",
      "Epoch 61/100\n",
      "2634/2634 [==============================] - ETA: 0s - loss: 0.1619 - acc: 0.9533\n",
      "Epoch 00061: val_acc did not improve from 0.64199\n",
      "2634/2634 [==============================] - 836s 317ms/step - loss: 0.1619 - acc: 0.9533 - val_loss: 3.2443 - val_acc: 0.6198\n",
      "Epoch 62/100\n",
      "2634/2634 [==============================] - ETA: 0s - loss: 0.1550 - acc: 0.9555\n",
      "Epoch 00062: val_acc did not improve from 0.64199\n",
      "2634/2634 [==============================] - 835s 317ms/step - loss: 0.1550 - acc: 0.9555 - val_loss: 4.2130 - val_acc: 0.5596\n",
      "Epoch 63/100\n",
      "2634/2634 [==============================] - ETA: 0s - loss: 0.1536 - acc: 0.9551\n",
      "Epoch 00063: val_acc did not improve from 0.64199\n",
      "2634/2634 [==============================] - 836s 317ms/step - loss: 0.1536 - acc: 0.9551 - val_loss: 3.3781 - val_acc: 0.6282\n",
      "Epoch 64/100\n",
      "2634/2634 [==============================] - ETA: 0s - loss: 0.1530 - acc: 0.9552\n",
      "Epoch 00064: val_acc did not improve from 0.64199\n",
      "2634/2634 [==============================] - 836s 317ms/step - loss: 0.1530 - acc: 0.9552 - val_loss: 3.7061 - val_acc: 0.5946\n",
      "Epoch 65/100\n",
      "2634/2634 [==============================] - ETA: 0s - loss: 0.1487 - acc: 0.9570\n",
      "Epoch 00065: val_acc did not improve from 0.64199\n",
      "2634/2634 [==============================] - 842s 320ms/step - loss: 0.1487 - acc: 0.9570 - val_loss: 3.5880 - val_acc: 0.6162\n",
      "Epoch 66/100\n",
      "2634/2634 [==============================] - ETA: 0s - loss: 0.1425 - acc: 0.9585\n",
      "Epoch 00066: val_acc did not improve from 0.64199\n",
      "2634/2634 [==============================] - 842s 320ms/step - loss: 0.1425 - acc: 0.9585 - val_loss: 3.2108 - val_acc: 0.6405\n",
      "Epoch 67/100\n",
      "2634/2634 [==============================] - ETA: 0s - loss: 0.1438 - acc: 0.9585\n",
      "Epoch 00067: val_acc did not improve from 0.64199\n",
      "2634/2634 [==============================] - 839s 318ms/step - loss: 0.1438 - acc: 0.9585 - val_loss: 3.6308 - val_acc: 0.6116\n",
      "Epoch 68/100\n",
      "2634/2634 [==============================] - ETA: 0s - loss: 0.1416 - acc: 0.9590\n",
      "Epoch 00068: val_acc improved from 0.64199 to 0.65083, saving model to checkpoints_group9/model-68-0.65.hdf5\n",
      "2634/2634 [==============================] - 836s 317ms/step - loss: 0.1416 - acc: 0.9590 - val_loss: 3.0281 - val_acc: 0.6508\n",
      "Epoch 69/100\n",
      "2634/2634 [==============================] - ETA: 0s - loss: 0.1392 - acc: 0.9593\n",
      "Epoch 00069: val_acc did not improve from 0.65083\n",
      "2634/2634 [==============================] - 835s 317ms/step - loss: 0.1392 - acc: 0.9593 - val_loss: 3.7960 - val_acc: 0.5741\n",
      "Epoch 70/100\n",
      "2634/2634 [==============================] - ETA: 0s - loss: 0.1389 - acc: 0.9599\n",
      "Epoch 00070: val_acc did not improve from 0.65083\n",
      "2634/2634 [==============================] - 834s 317ms/step - loss: 0.1389 - acc: 0.9599 - val_loss: 3.5759 - val_acc: 0.6140\n",
      "Epoch 71/100\n",
      "2634/2634 [==============================] - ETA: 0s - loss: 0.1350 - acc: 0.9602\n",
      "Epoch 00071: val_acc did not improve from 0.65083\n",
      "2634/2634 [==============================] - 835s 317ms/step - loss: 0.1350 - acc: 0.9602 - val_loss: 3.4560 - val_acc: 0.6384\n",
      "Epoch 72/100\n",
      "2634/2634 [==============================] - ETA: 0s - loss: 0.1325 - acc: 0.9613\n",
      "Epoch 00072: val_acc did not improve from 0.65083\n",
      "2634/2634 [==============================] - 835s 317ms/step - loss: 0.1325 - acc: 0.9613 - val_loss: 3.3283 - val_acc: 0.6280\n",
      "Epoch 73/100\n",
      "2634/2634 [==============================] - ETA: 0s - loss: 0.1287 - acc: 0.9626\n",
      "Epoch 00073: val_acc did not improve from 0.65083\n",
      "2634/2634 [==============================] - 836s 317ms/step - loss: 0.1287 - acc: 0.9626 - val_loss: 3.2443 - val_acc: 0.6277\n",
      "Epoch 74/100\n",
      "2634/2634 [==============================] - ETA: 0s - loss: 0.1278 - acc: 0.9630\n",
      "Epoch 00074: val_acc did not improve from 0.65083\n",
      "2634/2634 [==============================] - 837s 318ms/step - loss: 0.1278 - acc: 0.9630 - val_loss: 3.3941 - val_acc: 0.6475\n",
      "Epoch 75/100\n",
      "2634/2634 [==============================] - ETA: 0s - loss: 0.1308 - acc: 0.9621\n",
      "Epoch 00075: val_acc did not improve from 0.65083\n",
      "2634/2634 [==============================] - 837s 318ms/step - loss: 0.1308 - acc: 0.9621 - val_loss: 3.5367 - val_acc: 0.6271\n",
      "Epoch 76/100\n",
      "2634/2634 [==============================] - ETA: 0s - loss: 0.1270 - acc: 0.9631\n",
      "Epoch 00076: val_acc did not improve from 0.65083\n",
      "2634/2634 [==============================] - 838s 318ms/step - loss: 0.1270 - acc: 0.9631 - val_loss: 3.1834 - val_acc: 0.6415\n",
      "Epoch 77/100\n",
      "2634/2634 [==============================] - ETA: 0s - loss: 0.1238 - acc: 0.9641\n",
      "Epoch 00077: val_acc did not improve from 0.65083\n",
      "2634/2634 [==============================] - 838s 318ms/step - loss: 0.1238 - acc: 0.9641 - val_loss: 3.8067 - val_acc: 0.5820\n",
      "Epoch 78/100\n",
      "2634/2634 [==============================] - ETA: 0s - loss: 0.1227 - acc: 0.9639\n",
      "Epoch 00078: val_acc did not improve from 0.65083\n",
      "2634/2634 [==============================] - 838s 318ms/step - loss: 0.1227 - acc: 0.9639 - val_loss: 3.7853 - val_acc: 0.6188\n",
      "Epoch 79/100\n",
      "2634/2634 [==============================] - ETA: 0s - loss: 0.1199 - acc: 0.9648\n",
      "Epoch 00079: val_acc did not improve from 0.65083\n",
      "2634/2634 [==============================] - 837s 318ms/step - loss: 0.1199 - acc: 0.9648 - val_loss: 3.4277 - val_acc: 0.6378\n",
      "Epoch 80/100\n",
      "2634/2634 [==============================] - ETA: 0s - loss: 0.1199 - acc: 0.9649\n",
      "Epoch 00080: val_acc did not improve from 0.65083\n",
      "2634/2634 [==============================] - 838s 318ms/step - loss: 0.1199 - acc: 0.9649 - val_loss: 3.2437 - val_acc: 0.6423\n",
      "Epoch 81/100\n",
      "2634/2634 [==============================] - ETA: 0s - loss: 0.1169 - acc: 0.9657\n",
      "Epoch 00081: val_acc did not improve from 0.65083\n",
      "2634/2634 [==============================] - 837s 318ms/step - loss: 0.1169 - acc: 0.9657 - val_loss: 3.4895 - val_acc: 0.6112\n",
      "Epoch 82/100\n",
      "2634/2634 [==============================] - ETA: 0s - loss: 0.1173 - acc: 0.9659\n",
      "Epoch 00082: val_acc did not improve from 0.65083\n",
      "2634/2634 [==============================] - 837s 318ms/step - loss: 0.1173 - acc: 0.9659 - val_loss: 3.2508 - val_acc: 0.6461\n",
      "Epoch 83/100\n",
      "2634/2634 [==============================] - ETA: 0s - loss: 0.1138 - acc: 0.9669\n",
      "Epoch 00083: val_acc did not improve from 0.65083\n",
      "2634/2634 [==============================] - 838s 318ms/step - loss: 0.1138 - acc: 0.9669 - val_loss: 3.5671 - val_acc: 0.6231\n",
      "Epoch 84/100\n",
      "2634/2634 [==============================] - ETA: 0s - loss: 0.1142 - acc: 0.9664\n",
      "Epoch 00084: val_acc did not improve from 0.65083\n",
      "2634/2634 [==============================] - 838s 318ms/step - loss: 0.1142 - acc: 0.9664 - val_loss: 3.3875 - val_acc: 0.6441\n",
      "Epoch 85/100\n",
      "2634/2634 [==============================] - ETA: 0s - loss: 0.1148 - acc: 0.9664\n",
      "Epoch 00085: val_acc did not improve from 0.65083\n",
      "2634/2634 [==============================] - 839s 318ms/step - loss: 0.1148 - acc: 0.9664 - val_loss: 3.5370 - val_acc: 0.6159\n",
      "Epoch 86/100\n",
      "2634/2634 [==============================] - ETA: 0s - loss: 0.1103 - acc: 0.9678\n",
      "Epoch 00086: val_acc did not improve from 0.65083\n",
      "2634/2634 [==============================] - 837s 318ms/step - loss: 0.1103 - acc: 0.9678 - val_loss: 3.5642 - val_acc: 0.6361\n",
      "Epoch 87/100\n",
      "2634/2634 [==============================] - ETA: 0s - loss: 0.1064 - acc: 0.9690\n",
      "Epoch 00087: val_acc did not improve from 0.65083\n",
      "2634/2634 [==============================] - 839s 319ms/step - loss: 0.1064 - acc: 0.9690 - val_loss: 3.6355 - val_acc: 0.6385\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 88/100\n",
      "2634/2634 [==============================] - ETA: 0s - loss: 0.1091 - acc: 0.9682\n",
      "Epoch 00088: val_acc did not improve from 0.65083\n",
      "2634/2634 [==============================] - 839s 318ms/step - loss: 0.1091 - acc: 0.9682 - val_loss: 3.8640 - val_acc: 0.6104\n",
      "Epoch 89/100\n",
      "2634/2634 [==============================] - ETA: 0s - loss: 0.1092 - acc: 0.9684\n",
      "Epoch 00089: val_acc did not improve from 0.65083\n",
      "2634/2634 [==============================] - 844s 321ms/step - loss: 0.1092 - acc: 0.9684 - val_loss: 3.5036 - val_acc: 0.6244\n",
      "Epoch 90/100\n",
      "2634/2634 [==============================] - ETA: 0s - loss: 0.1053 - acc: 0.9689\n",
      "Epoch 00090: val_acc did not improve from 0.65083\n",
      "2634/2634 [==============================] - 845s 321ms/step - loss: 0.1053 - acc: 0.9689 - val_loss: 3.7003 - val_acc: 0.6301\n",
      "Epoch 91/100\n",
      "2634/2634 [==============================] - ETA: 0s - loss: 0.1053 - acc: 0.9693\n",
      "Epoch 00091: val_acc did not improve from 0.65083\n",
      "2634/2634 [==============================] - 839s 319ms/step - loss: 0.1053 - acc: 0.9693 - val_loss: 4.0033 - val_acc: 0.5887\n",
      "Epoch 92/100\n",
      "2634/2634 [==============================] - ETA: 0s - loss: 0.1052 - acc: 0.9688\n",
      "Epoch 00092: val_acc did not improve from 0.65083\n",
      "2634/2634 [==============================] - 839s 318ms/step - loss: 0.1052 - acc: 0.9688 - val_loss: 3.7910 - val_acc: 0.5901\n",
      "Epoch 93/100\n",
      "2634/2634 [==============================] - ETA: 0s - loss: 0.1043 - acc: 0.9699\n",
      "Epoch 00093: val_acc did not improve from 0.65083\n",
      "2634/2634 [==============================] - 839s 318ms/step - loss: 0.1043 - acc: 0.9699 - val_loss: 4.2806 - val_acc: 0.5868\n",
      "Epoch 94/100\n",
      "2634/2634 [==============================] - ETA: 0s - loss: 0.1014 - acc: 0.9702\n",
      "Epoch 00094: val_acc did not improve from 0.65083\n",
      "2634/2634 [==============================] - 839s 318ms/step - loss: 0.1014 - acc: 0.9702 - val_loss: 3.6840 - val_acc: 0.6195\n",
      "Epoch 95/100\n",
      "2634/2634 [==============================] - ETA: 0s - loss: 0.1019 - acc: 0.9705\n",
      "Epoch 00095: val_acc did not improve from 0.65083\n",
      "2634/2634 [==============================] - 839s 318ms/step - loss: 0.1019 - acc: 0.9705 - val_loss: 4.0730 - val_acc: 0.5827\n",
      "Epoch 96/100\n",
      "2634/2634 [==============================] - ETA: 0s - loss: 0.0976 - acc: 0.9708\n",
      "Epoch 00096: val_acc did not improve from 0.65083\n",
      "2634/2634 [==============================] - 844s 320ms/step - loss: 0.0976 - acc: 0.9708 - val_loss: 3.5416 - val_acc: 0.6445\n",
      "Epoch 97/100\n",
      "2634/2634 [==============================] - ETA: 0s - loss: 0.0975 - acc: 0.9710\n",
      "Epoch 00097: val_acc did not improve from 0.65083\n",
      "2634/2634 [==============================] - 843s 320ms/step - loss: 0.0975 - acc: 0.9710 - val_loss: 3.7495 - val_acc: 0.6214\n",
      "Epoch 98/100\n",
      "2634/2634 [==============================] - ETA: 0s - loss: 0.0976 - acc: 0.9714\n",
      "Epoch 00098: val_acc did not improve from 0.65083\n",
      "2634/2634 [==============================] - 840s 319ms/step - loss: 0.0976 - acc: 0.9714 - val_loss: 3.5331 - val_acc: 0.6399\n",
      "Epoch 99/100\n",
      "2634/2634 [==============================] - ETA: 0s - loss: 0.0954 - acc: 0.9718\n",
      "Epoch 00099: val_acc did not improve from 0.65083\n",
      "2634/2634 [==============================] - 837s 318ms/step - loss: 0.0954 - acc: 0.9718 - val_loss: 3.3718 - val_acc: 0.6476\n",
      "Epoch 100/100\n",
      "2634/2634 [==============================] - ETA: 0s - loss: 0.0934 - acc: 0.9725\n",
      "Epoch 00100: val_acc did not improve from 0.65083\n",
      "2634/2634 [==============================] - 843s 320ms/step - loss: 0.0934 - acc: 0.9725 - val_loss: 3.8114 - val_acc: 0.6228\n"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(\n",
    "    generator = train_generator,\n",
    "    steps_per_epoch = train_generator.n // batch_size,\n",
    "    validation_data = valid_generator,\n",
    "    validation_steps = valid_generator.n // batch_size,\n",
    "    callbacks=[checkpoint_callback, tensorboard_callback],\n",
    "    epochs = 100,\n",
    "    workers = 8,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sfsdfsdsdfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.models.save_model(history.model, 'group11_set224_resnet50_07202020.hdf5', include_optimizer=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc)\n",
    "plt.plot(epochs, val_acc)\n",
    "plt.title('Training accuracy')\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss)\n",
    "plt.plot(epochs, val_loss)\n",
    "plt.title('Training Loss')\n",
    "plt.figure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gsedrfgdffg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ERROR: Timed out waiting for TensorBoard to start. It may still be running as pid 22708."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs/train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Labels in  Json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_to_class_labels_dict = {value : key for key, value in train_generator.class_indices.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1724\n",
      "{0: '100131', 1: '100474', 2: '10057', 3: '10071', 4: '100719', 5: '100820', 6: '100825', 7: '100847', 8: '100914', 9: '101049', 10: '10116', 11: '101236', 12: '101301', 13: '101462', 14: '101530', 15: '101615', 16: '101664', 17: '101923', 18: '102062', 19: '102241', 20: '102604', 21: '10269', 22: '102703', 23: '102743', 24: '102905', 25: '102959', 26: '102988', 27: '103039', 28: '10308', 29: '103292', 30: '103348', 31: '103365', 32: '103456', 33: '103590', 34: '10367', 35: '103704', 36: '103831', 37: '103923', 38: '104219', 39: '104239', 40: '104457', 41: '104497', 42: '104840', 43: '104882', 44: '10492', 45: '10503', 46: '105274', 47: '105479', 48: '1055', 49: '105597', 50: '105604', 51: '105763', 52: '105806', 53: '105878', 54: '105914', 55: '106128', 56: '106252', 57: '106258', 58: '106401', 59: '106438', 60: '106602', 61: '106653', 62: '106795', 63: '106805', 64: '10694', 65: '106950', 66: '106991', 67: '107233', 68: '107349', 69: '107386', 70: '107404', 71: '107545', 72: '10763', 73: '107717', 74: '10786', 75: '107941', 76: '108023', 77: '108050', 78: '108119', 79: '108269', 80: '108384', 81: '108535', 82: '108625', 83: '108886', 84: '108910', 85: '108924', 86: '108946', 87: '109326', 88: '10949', 89: '109503', 90: '109554', 91: '109821', 92: '109880', 93: '110081', 94: '110194', 95: '110240', 96: '110247', 97: '110313', 98: '110395', 99: '110434', 100: '110477', 101: '110594', 102: '110691', 103: '110718', 104: '110885', 105: '111122', 106: '111353', 107: '111663', 108: '111675', 109: '111779', 110: '111823', 111: '111840', 112: '111859', 113: '111876', 114: '1122', 115: '112445', 116: '1125', 117: '112516', 118: '112601', 119: '112612', 120: '113001', 121: '113107', 122: '11318', 123: '113458', 124: '113653', 125: '1137', 126: '11373', 127: '113926', 128: '113988', 129: '114515', 130: '114646', 131: '114663', 132: '114669', 133: '114723', 134: '114844', 135: '114940', 136: '115032', 137: '115124', 138: '115159', 139: '115164', 140: '115170', 141: '115350', 142: '115418', 143: '115445', 144: '115500', 145: '115502', 146: '115595', 147: '115884', 148: '115903', 149: '116027', 150: '116035', 151: '116037', 152: '116098', 153: '11614', 154: '116293', 155: '116393', 156: '116485', 157: '116596', 158: '116930', 159: '117004', 160: '117514', 161: '118054', 162: '118286', 163: '118331', 164: '118333', 165: '11854', 166: '118621', 167: '118749', 168: '11883', 169: '118895', 170: '119052', 171: '119068', 172: '119270', 173: '119290', 174: '119367', 175: '119371', 176: '11947', 177: '119495', 178: '119686', 179: '119768', 180: '119775', 181: '119800', 182: '119890', 183: '119913', 184: '119941', 185: '119969', 186: '120105', 187: '120110', 188: '120241', 189: '120246', 190: '120321', 191: '120428', 192: '12046', 193: '120521', 194: '120553', 195: '120556', 196: '120636', 197: '120649', 198: '120721', 199: '120749', 200: '120844', 201: '120871', 202: '121217', 203: '121455', 204: '12151', 205: '121517', 206: '121990', 207: '122129', 208: '122253', 209: '122358', 210: '122463', 211: '122614', 212: '122761', 213: '122875', 214: '123032', 215: '123095', 216: '123101', 217: '123162', 218: '123200', 219: '123281', 220: '123354', 221: '123400', 222: '123477', 223: '123481', 224: '123528', 225: '123633', 226: '123836', 227: '12386', 228: '124008', 229: '124153', 230: '12418', 231: '124275', 232: '124298', 233: '124349', 234: '124494', 235: '124726', 236: '124745', 237: '124769', 238: '124814', 239: '125176', 240: '125330', 241: '125434', 242: '125504', 243: '125520', 244: '125628', 245: '125931', 246: '126058', 247: '126131', 248: '126186', 249: '126194', 250: '126290', 251: '126366', 252: '126432', 253: '126437', 254: '126906', 255: '127101', 256: '127189', 257: '127320', 258: '127324', 259: '127346', 260: '127347', 261: '127357', 262: '127366', 263: '127434', 264: '127667', 265: '127766', 266: '128095', 267: '128131', 268: '128149', 269: '128200', 270: '128272', 271: '12833', 272: '128336', 273: '128443', 274: '128634', 275: '1287', 276: '128796', 277: '129044', 278: '129179', 279: '129182', 280: '129232', 281: '129272', 282: '129342', 283: '129518', 284: '129601', 285: '129682', 286: '129883', 287: '129902', 288: '129964', 289: '130129', 290: '130183', 291: '130205', 292: '130383', 293: '130386', 294: '130413', 295: '130674', 296: '130902', 297: '131016', 298: '131161', 299: '131209', 300: '131432', 301: '131465', 302: '13155', 303: '131593', 304: '131751', 305: '131896', 306: '132181', 307: '132555', 308: '132570', 309: '132640', 310: '132829', 311: '132915', 312: '132973', 313: '133011', 314: '133191', 315: '133448', 316: '133490', 317: '13352', 318: '133535', 319: '133738', 320: '133881', 321: '133960', 322: '134014', 323: '134736', 324: '134845', 325: '135106', 326: '135113', 327: '135356', 328: '135464', 329: '135571', 330: '135577', 331: '135690', 332: '135789', 333: '135959', 334: '135973', 335: '136069', 336: '136140', 337: '13628', 338: '136300', 339: '136359', 340: '136483', 341: '136577', 342: '136595', 343: '136728', 344: '136775', 345: '136827', 346: '136940', 347: '136970', 348: '137005', 349: '137164', 350: '137165', 351: '137385', 352: '13753', 353: '13754', 354: '137656', 355: '137738', 356: '137746', 357: '137981', 358: '138097', 359: '138139', 360: '13821', 361: '138248', 362: '138571', 363: '138636', 364: '138691', 365: '139046', 366: '139073', 367: '139114', 368: '139149', 369: '139334', 370: '139352', 371: '139589', 372: '139597', 373: '139696', 374: '13975', 375: '139787', 376: '139815', 377: '13983', 378: '139882', 379: '139956', 380: '139996', 381: '140011', 382: '14031', 383: '140386', 384: '140536', 385: '140548', 386: '14065', 387: '140734', 388: '141108', 389: '141116', 390: '141430', 391: '141458', 392: '141460', 393: '141487', 394: '141497', 395: '141715', 396: '141867', 397: '141874', 398: '141990', 399: '141991', 400: '142211', 401: '142444', 402: '142469', 403: '142470', 404: '142505', 405: '142760', 406: '142806', 407: '143048', 408: '143157', 409: '143267', 410: '143288', 411: '143595', 412: '14366', 413: '143711', 414: '143824', 415: '143919', 416: '143994', 417: '144215', 418: '144231', 419: '14436', 420: '144460', 421: '144483', 422: '145087', 423: '145120', 424: '145268', 425: '145412', 426: '145447', 427: '145557', 428: '145916', 429: '146167', 430: '146236', 431: '146244', 432: '146294', 433: '146331', 434: '146341', 435: '146388', 436: '146457', 437: '1468', 438: '146993', 439: '147013', 440: '147078', 441: '147591', 442: '147655', 443: '147716', 444: '147784', 445: '147844', 446: '14786', 447: '147873', 448: '147990', 449: '148222', 450: '148292', 451: '148755', 452: '148766', 453: '148799', 454: '148923', 455: '148970', 456: '149237', 457: '149419', 458: '149447', 459: '14968', 460: '149872', 461: '149906', 462: '149917', 463: '150054', 464: '150231', 465: '150385', 466: '150500', 467: '150618', 468: '15070', 469: '150790', 470: '150849', 471: '150863', 472: '150925', 473: '150998', 474: '151199', 475: '151227', 476: '151282', 477: '151487', 478: '151569', 479: '151876', 480: '15188', 481: '15194', 482: '151985', 483: '152071', 484: '152354', 485: '1524', 486: '152496', 487: '152526', 488: '152550', 489: '152697', 490: '152772', 491: '152912', 492: '152955', 493: '153033', 494: '153045', 495: '153123', 496: '153181', 497: '153194', 498: '153250', 499: '153407', 500: '153715', 501: '153746', 502: '153931', 503: '153959', 504: '154026', 505: '154158', 506: '154192', 507: '154257', 508: '1543', 509: '154670', 510: '15475', 511: '15481', 512: '154880', 513: '15497', 514: '155196', 515: '155280', 516: '155432', 517: '155532', 518: '155547', 519: '155641', 520: '155659', 521: '155748', 522: '156057', 523: '156172', 524: '156229', 525: '156403', 526: '156484', 527: '156693', 528: '15673', 529: '156756', 530: '156816', 531: '15688', 532: '156978', 533: '156993', 534: '1575', 535: '157661', 536: '157872', 537: '158054', 538: '158273', 539: '158318', 540: '158347', 541: '158369', 542: '15862', 543: '158638', 544: '15867', 545: '158671', 546: '158744', 547: '158928', 548: '158986', 549: '159007', 550: '159610', 551: '159838', 552: '160071', 553: '160110', 554: '160161', 555: '160200', 556: '160254', 557: '160283', 558: '160292', 559: '160404', 560: '160465', 561: '160530', 562: '160555', 563: '160559', 564: '160778', 565: '160798', 566: '161350', 567: '161376', 568: '161384', 569: '161478', 570: '161495', 571: '161514', 572: '16156', 573: '161803', 574: '16184', 575: '16188', 576: '161927', 577: '161998', 578: '162130', 579: '16247', 580: '162717', 581: '162794', 582: '162881', 583: '162918', 584: '163035', 585: '163280', 586: '163307', 587: '163677', 588: '163683', 589: '163897', 590: '163945', 591: '164000', 592: '164017', 593: '164137', 594: '164687', 595: '164886', 596: '16507', 597: '165097', 598: '165103', 599: '165285', 600: '165635', 601: '16580', 602: '165854', 603: '165917', 604: '166033', 605: '166144', 606: '166222', 607: '166395', 608: '166508', 609: '166548', 610: '166718', 611: '166926', 612: '167251', 613: '167290', 614: '167465', 615: '167485', 616: '167549', 617: '167571', 618: '167738', 619: '167807', 620: '167864', 621: '16801', 622: '168021', 623: '168227', 624: '168280', 625: '168466', 626: '168553', 627: '168578', 628: '168677', 629: '168769', 630: '168812', 631: '169043', 632: '169130', 633: '169231', 634: '169507', 635: '169514', 636: '169594', 637: '16967', 638: '16970', 639: '169732', 640: '169816', 641: '169872', 642: '16996', 643: '169985', 644: '170350', 645: '170373', 646: '170792', 647: '170832', 648: '171130', 649: '171355', 650: '171413', 651: '171457', 652: '171575', 653: '171718', 654: '172045', 655: '172104', 656: '172126', 657: '17222', 658: '172220', 659: '172233', 660: '172357', 661: '172432', 662: '17244', 663: '172593', 664: '172650', 665: '172669', 666: '172806', 667: '172904', 668: '173022', 669: '173403', 670: '173404', 671: '173666', 672: '173668', 673: '173700', 674: '173790', 675: '174070', 676: '174138', 677: '174158', 678: '174168', 679: '174349', 680: '175188', 681: '175254', 682: '175283', 683: '175416', 684: '175432', 685: '175499', 686: '17556', 687: '175574', 688: '175579', 689: '175753', 690: '175959', 691: '176036', 692: '17605', 693: '176111', 694: '176158', 695: '17631', 696: '176578', 697: '176650', 698: '177008', 699: '177051', 700: '177130', 701: '177258', 702: '177381', 703: '177471', 704: '177586', 705: '177634', 706: '177771', 707: '177772', 708: '177803', 709: '177892', 710: '177935', 711: '178007', 712: '17808', 713: '178297', 714: '178350', 715: '17860', 716: '178812', 717: '178830', 718: '178834', 719: '179333', 720: '179376', 721: '179581', 722: '179839', 723: '179857', 724: '179977', 725: '180051', 726: '180147', 727: '18035', 728: '180595', 729: '180689', 730: '180706', 731: '180825', 732: '180838', 733: '181317', 734: '181399', 735: '181401', 736: '181490', 737: '18164', 738: '181688', 739: '181959', 740: '181986', 741: '182056', 742: '182088', 743: '182168', 744: '182388', 745: '182789', 746: '182897', 747: '182989', 748: '183072', 749: '183077', 750: '18312', 751: '183328', 752: '183422', 753: '183535', 754: '183859', 755: '1839', 756: '183993', 757: '184018', 758: '184358', 759: '184435', 760: '184547', 761: '184566', 762: '184648', 763: '184658', 764: '184676', 765: '184746', 766: '184757', 767: '184811', 768: '185190', 769: '185197', 770: '185241', 771: '185271', 772: '185311', 773: '185532', 774: '185852', 775: '185860', 776: '186011', 777: '186160', 778: '186219', 779: '186389', 780: '1864', 781: '186453', 782: '186586', 783: '18678', 784: '186802', 785: '186813', 786: '186832', 787: '186921', 788: '186992', 789: '187060', 790: '187083', 791: '187223', 792: '187225', 793: '18738', 794: '187393', 795: '18750', 796: '18757', 797: '187579', 798: '187853', 799: '188407', 800: '188476', 801: '188626', 802: '188681', 803: '188698', 804: '188772', 805: '188812', 806: '189000', 807: '189171', 808: '189261', 809: '189359', 810: '189371', 811: '189553', 812: '18987', 813: '190023', 814: '190179', 815: '190190', 816: '190218', 817: '190441', 818: '190456', 819: '190602', 820: '190648', 821: '190665', 822: '190948', 823: '191015', 824: '191033', 825: '191052', 826: '191140', 827: '191183', 828: '191208', 829: '191243', 830: '191323', 831: '191370', 832: '191473', 833: '191723', 834: '191829', 835: '191876', 836: '19201', 837: '192035', 838: '192149', 839: '192186', 840: '19230', 841: '192423', 842: '192479', 843: '192746', 844: '192878', 845: '19297', 846: '193129', 847: '19323', 848: '193278', 849: '193296', 850: '193374', 851: '19362', 852: '193645', 853: '193701', 854: '193730', 855: '193739', 856: '194092', 857: '194109', 858: '194173', 859: '194263', 860: '194346', 861: '19439', 862: '194740', 863: '194886', 864: '195145', 865: '195189', 866: '195203', 867: '195265', 868: '195296', 869: '195465', 870: '195546', 871: '195555', 872: '195607', 873: '195760', 874: '195802', 875: '195823', 876: '195974', 877: '196059', 878: '196366', 879: '196478', 880: '196482', 881: '196902', 882: '196962', 883: '197002', 884: '197115', 885: '197232', 886: '197372', 887: '197413', 888: '197579', 889: '197631', 890: '198011', 891: '198052', 892: '198124', 893: '198152', 894: '198237', 895: '198370', 896: '198379', 897: '198451', 898: '198470', 899: '198560', 900: '198831', 901: '198849', 902: '198988', 903: '199181', 904: '1993', 905: '199527', 906: '199613', 907: '199802', 908: '19993', 909: '200004', 910: '20026', 911: '200267', 912: '200641', 913: '20079', 914: '200799', 915: '200806', 916: '200852', 917: '201015', 918: '201090', 919: '201195', 920: '201217', 921: '201590', 922: '201868', 923: '201919', 924: '201944', 925: '201945', 926: '202028', 927: '202446', 928: '202535', 929: '202625', 930: '20265', 931: '202879', 932: '202979', 933: '2037', 934: '20394', 935: '20516', 936: '20679', 937: '20712', 938: '21103', 939: '21389', 940: '21425', 941: '21493', 942: '21997', 943: '2202', 944: '22082', 945: '22111', 946: '22112', 947: '22170', 948: '22192', 949: '22225', 950: '22237', 951: '22289', 952: '22418', 953: '22580', 954: '22597', 955: '22650', 956: '22831', 957: '22856', 958: '22865', 959: '22895', 960: '22903', 961: '23173', 962: '23268', 963: '23383', 964: '23435', 965: '23445', 966: '23475', 967: '23481', 968: '23565', 969: '23642', 970: '23716', 971: '23896', 972: '23984', 973: '23996', 974: '23998', 975: '2421', 976: '24346', 977: '24353', 978: '24408', 979: '24492', 980: '24517', 981: '24760', 982: '24770', 983: '25107', 984: '25109', 985: '25370', 986: '25522', 987: '25578', 988: '25718', 989: '25747', 990: '25791', 991: '25801', 992: '25948', 993: '25986', 994: '26010', 995: '26015', 996: '26124', 997: '26159', 998: '26163', 999: '26164', 1000: '26230', 1001: '26294', 1002: '26364', 1003: '26566', 1004: '26687', 1005: '26781', 1006: '26825', 1007: '26952', 1008: '27004', 1009: '27039', 1010: '27192', 1011: '27273', 1012: '27278', 1013: '27470', 1014: '27486', 1015: '27497', 1016: '27733', 1017: '27941', 1018: '2797', 1019: '28068', 1020: '28116', 1021: '28154', 1022: '283', 1023: '28410', 1024: '2857', 1025: '28580', 1026: '2864', 1027: '28661', 1028: '2872', 1029: '2886', 1030: '28949', 1031: '28986', 1032: '29060', 1033: '29062', 1034: '29379', 1035: '29579', 1036: '29750', 1037: '29793', 1038: '29840', 1039: '29918', 1040: '29935', 1041: '30246', 1042: '30513', 1043: '30779', 1044: '309', 1045: '3103', 1046: '311', 1047: '31136', 1048: '31137', 1049: '31181', 1050: '31275', 1051: '3131', 1052: '31328', 1053: '31508', 1054: '31545', 1055: '31590', 1056: '31617', 1057: '31787', 1058: '31846', 1059: '31856', 1060: '31948', 1061: '32108', 1062: '32324', 1063: '32325', 1064: '32634', 1065: '32637', 1066: '32685', 1067: '33019', 1068: '33042', 1069: '33178', 1070: '33206', 1071: '33308', 1072: '33555', 1073: '33567', 1074: '33588', 1075: '33672', 1076: '33694', 1077: '33715', 1078: '33803', 1079: '3387', 1080: '33925', 1081: '341', 1082: '34190', 1083: '34456', 1084: '34603', 1085: '34896', 1086: '34930', 1087: '34946', 1088: '34964', 1089: '34971', 1090: '35044', 1091: '35068', 1092: '35143', 1093: '35178', 1094: '35288', 1095: '35348', 1096: '35446', 1097: '35535', 1098: '35546', 1099: '35580', 1100: '35782', 1101: '36011', 1102: '36012', 1103: '36121', 1104: '36353', 1105: '36412', 1106: '36414', 1107: '36557', 1108: '3657', 1109: '36586', 1110: '36664', 1111: '36835', 1112: '36978', 1113: '37028', 1114: '37077', 1115: '37104', 1116: '37113', 1117: '37131', 1118: '37172', 1119: '37227', 1120: '37382', 1121: '37386', 1122: '37599', 1123: '37930', 1124: '38087', 1125: '38277', 1126: '3834', 1127: '38343', 1128: '38504', 1129: '3856', 1130: '38671', 1131: '3887', 1132: '38884', 1133: '38998', 1134: '39012', 1135: '39029', 1136: '39067', 1137: '39211', 1138: '39439', 1139: '39452', 1140: '39502', 1141: '39526', 1142: '39542', 1143: '39624', 1144: '39848', 1145: '39850', 1146: '39869', 1147: '39922', 1148: '40052', 1149: '40217', 1150: '40276', 1151: '40407', 1152: '40498', 1153: '40611', 1154: '40637', 1155: '40644', 1156: '40823', 1157: '40842', 1158: '40847', 1159: '4103', 1160: '41072', 1161: '41250', 1162: '41566', 1163: '41587', 1164: '41647', 1165: '41991', 1166: '42142', 1167: '42193', 1168: '42217', 1169: '4239', 1170: '42641', 1171: '42653', 1172: '43031', 1173: '43283', 1174: '43370', 1175: '43425', 1176: '43695', 1177: '43847', 1178: '43959', 1179: '43985', 1180: '4406', 1181: '4412', 1182: '44180', 1183: '44232', 1184: '44236', 1185: '44293', 1186: '44471', 1187: '44483', 1188: '4465', 1189: '44660', 1190: '44712', 1191: '44776', 1192: '44916', 1193: '45037', 1194: '45221', 1195: '45264', 1196: '45325', 1197: '45395', 1198: '45514', 1199: '45562', 1200: '45646', 1201: '45689', 1202: '4572', 1203: '45870', 1204: '45894', 1205: '45952', 1206: '46001', 1207: '46191', 1208: '46338', 1209: '46411', 1210: '46487', 1211: '46609', 1212: '46690', 1213: '46814', 1214: '46975', 1215: '47002', 1216: '4706', 1217: '47078', 1218: '47080', 1219: '47157', 1220: '47226', 1221: '47552', 1222: '47580', 1223: '47643', 1224: '47645', 1225: '47685', 1226: '47884', 1227: '47892', 1228: '48004', 1229: '48184', 1230: '48319', 1231: '48440', 1232: '48484', 1233: '48524', 1234: '48721', 1235: '48962', 1236: '49093', 1237: '49200', 1238: '49323', 1239: '49333', 1240: '49409', 1241: '49644', 1242: '49766', 1243: '49917', 1244: '49944', 1245: '49952', 1246: '5012', 1247: '50384', 1248: '504', 1249: '50455', 1250: '50658', 1251: '50833', 1252: '50848', 1253: '51015', 1254: '5111', 1255: '51151', 1256: '51190', 1257: '51255', 1258: '51258', 1259: '5127', 1260: '51388', 1261: '51466', 1262: '51515', 1263: '51524', 1264: '51692', 1265: '51729', 1266: '52006', 1267: '52057', 1268: '52097', 1269: '52494', 1270: '52777', 1271: '53062', 1272: '53119', 1273: '53286', 1274: '53327', 1275: '53377', 1276: '53464', 1277: '53519', 1278: '53617', 1279: '53894', 1280: '5399', 1281: '54060', 1282: '54066', 1283: '54107', 1284: '54214', 1285: '54279', 1286: '5442', 1287: '54444', 1288: '54503', 1289: '54542', 1290: '54555', 1291: '54569', 1292: '54579', 1293: '54597', 1294: '54599', 1295: '54624', 1296: '5468', 1297: '54715', 1298: '54757', 1299: '55003', 1300: '55120', 1301: '55196', 1302: '5522', 1303: '55238', 1304: '5533', 1305: '55804', 1306: '55976', 1307: '5605', 1308: '56306', 1309: '56552', 1310: '56583', 1311: '56723', 1312: '56859', 1313: '5687', 1314: '56881', 1315: '56983', 1316: '57175', 1317: '57192', 1318: '5728', 1319: '57416', 1320: '57590', 1321: '57599', 1322: '578', 1323: '5785', 1324: '57915', 1325: '58018', 1326: '58387', 1327: '58389', 1328: '58610', 1329: '58639', 1330: '58832', 1331: '59047', 1332: '5937', 1333: '5942', 1334: '5950', 1335: '5951', 1336: '59516', 1337: '59612', 1338: '5976', 1339: '59770', 1340: '59864', 1341: '59922', 1342: '59965', 1343: '60049', 1344: '60366', 1345: '60405', 1346: '60430', 1347: '6045', 1348: '60870', 1349: '60889', 1350: '60944', 1351: '610', 1352: '61245', 1353: '61303', 1354: '61329', 1355: '61519', 1356: '61576', 1357: '61680', 1358: '6173', 1359: '6190', 1360: '62093', 1361: '62108', 1362: '62888', 1363: '63108', 1364: '63281', 1365: '63483', 1366: '63599', 1367: '63697', 1368: '64029', 1369: '64087', 1370: '64189', 1371: '6432', 1372: '64325', 1373: '64349', 1374: '64379', 1375: '64382', 1376: '64395', 1377: '64513', 1378: '64669', 1379: '64946', 1380: '65052', 1381: '65082', 1382: '65317', 1383: '65408', 1384: '65494', 1385: '65800', 1386: '65969', 1387: '65987', 1388: '66055', 1389: '66138', 1390: '66176', 1391: '66271', 1392: '66339', 1393: '6635', 1394: '66415', 1395: '66458', 1396: '66721', 1397: '66767', 1398: '66809', 1399: '66853', 1400: '66935', 1401: '66941', 1402: '66946', 1403: '66987', 1404: '67011', 1405: '67021', 1406: '6712', 1407: '67189', 1408: '6726', 1409: '67404', 1410: '67490', 1411: '67618', 1412: '67697', 1413: '67703', 1414: '67740', 1415: '67769', 1416: '67786', 1417: '67824', 1418: '67933', 1419: '68322', 1420: '68461', 1421: '68740', 1422: '6884', 1423: '6888', 1424: '689', 1425: '68900', 1426: '68913', 1427: '68953', 1428: '690', 1429: '69029', 1430: '6930', 1431: '6932', 1432: '69364', 1433: '69408', 1434: '69627', 1435: '69850', 1436: '69861', 1437: '69990', 1438: '70112', 1439: '70125', 1440: '70173', 1441: '70299', 1442: '70333', 1443: '70338', 1444: '70455', 1445: '70486', 1446: '70534', 1447: '70727', 1448: '70730', 1449: '70935', 1450: '71094', 1451: '71101', 1452: '71286', 1453: '7133', 1454: '71358', 1455: '71406', 1456: '71474', 1457: '71500', 1458: '71557', 1459: '71917', 1460: '72042', 1461: '72146', 1462: '72150', 1463: '72287', 1464: '72339', 1465: '7240', 1466: '72624', 1467: '72690', 1468: '72759', 1469: '73102', 1470: '7314', 1471: '73205', 1472: '73213', 1473: '73256', 1474: '7346', 1475: '73525', 1476: '73534', 1477: '73596', 1478: '73604', 1479: '73931', 1480: '73987', 1481: '74065', 1482: '74071', 1483: '74193', 1484: '7468', 1485: '74826', 1486: '7488', 1487: '75072', 1488: '75089', 1489: '75128', 1490: '75222', 1491: '75549', 1492: '75565', 1493: '75684', 1494: '75843', 1495: '75852', 1496: '75931', 1497: '76148', 1498: '76280', 1499: '76379', 1500: '76392', 1501: '76706', 1502: '77079', 1503: '77112', 1504: '77134', 1505: '77259', 1506: '77417', 1507: '77487', 1508: '7757', 1509: '77601', 1510: '77682', 1511: '77774', 1512: '77775', 1513: '77793', 1514: '77900', 1515: '78217', 1516: '78272', 1517: '78435', 1518: '78863', 1519: '7901', 1520: '79026', 1521: '79105', 1522: '79115', 1523: '79171', 1524: '79226', 1525: '79243', 1526: '79352', 1527: '79389', 1528: '79499', 1529: '79667', 1530: '7973', 1531: '79886', 1532: '7994', 1533: '8002', 1534: '80224', 1535: '80433', 1536: '80540', 1537: '8078', 1538: '80950', 1539: '81015', 1540: '81022', 1541: '81070', 1542: '81175', 1543: '813', 1544: '8131', 1545: '81432', 1546: '81543', 1547: '81728', 1548: '81731', 1549: '81789', 1550: '81856', 1551: '81941', 1552: '82008', 1553: '82070', 1554: '82145', 1555: '82259', 1556: '82290', 1557: '82563', 1558: '82589', 1559: '82729', 1560: '82804', 1561: '82853', 1562: '83139', 1563: '83160', 1564: '83172', 1565: '83189', 1566: '83552', 1567: '83700', 1568: '8379', 1569: '83819', 1570: '83885', 1571: '84147', 1572: '84208', 1573: '84329', 1574: '84415', 1575: '84461', 1576: '84795', 1577: '84796', 1578: '84853', 1579: '84960', 1580: '85114', 1581: '8527', 1582: '85326', 1583: '85333', 1584: '85377', 1585: '85543', 1586: '85806', 1587: '86106', 1588: '86108', 1589: '86179', 1590: '8622', 1591: '8627', 1592: '86359', 1593: '86473', 1594: '86504', 1595: '86529', 1596: '86536', 1597: '86738', 1598: '86828', 1599: '8694', 1600: '86947', 1601: '86980', 1602: '86982', 1603: '86984', 1604: '86992', 1605: '87002', 1606: '87029', 1607: '87049', 1608: '87237', 1609: '87367', 1610: '87404', 1611: '8745', 1612: '87514', 1613: '87612', 1614: '87793', 1615: '87937', 1616: '88090', 1617: '88199', 1618: '88211', 1619: '88408', 1620: '88438', 1621: '88729', 1622: '89122', 1623: '89220', 1624: '89458', 1625: '89480', 1626: '89505', 1627: '89525', 1628: '89788', 1629: '89975', 1630: '90071', 1631: '9052', 1632: '90665', 1633: '9067', 1634: '90770', 1635: '90823', 1636: '90991', 1637: '91012', 1638: '91061', 1639: '91180', 1640: '91284', 1641: '91414', 1642: '91484', 1643: '91505', 1644: '91563', 1645: '91707', 1646: '91895', 1647: '92208', 1648: '92371', 1649: '92377', 1650: '92508', 1651: '92607', 1652: '92721', 1653: '92893', 1654: '93097', 1655: '93241', 1656: '93321', 1657: '93392', 1658: '93683', 1659: '93701', 1660: '94168', 1661: '94179', 1662: '94320', 1663: '94332', 1664: '94342', 1665: '94608', 1666: '95068', 1667: '95101', 1668: '95187', 1669: '952', 1670: '9540', 1671: '95411', 1672: '95432', 1673: '95439', 1674: '95672', 1675: '95756', 1676: '96020', 1677: '96110', 1678: '96397', 1679: '96498', 1680: '96524', 1681: '96567', 1682: '96595', 1683: '96604', 1684: '9670', 1685: '96720', 1686: '96825', 1687: '969', 1688: '96931', 1689: '96982', 1690: '97033', 1691: '97268', 1692: '97306', 1693: '97324', 1694: '97342', 1695: '97345', 1696: '97548', 1697: '97654', 1698: '97715', 1699: '97783', 1700: '98001', 1701: '9819', 1702: '98355', 1703: '98403', 1704: '98459', 1705: '9847', 1706: '9848', 1707: '98496', 1708: '98773', 1709: '98852', 1710: '98870', 1711: '98884', 1712: '98896', 1713: '98900', 1714: '98917', 1715: '98974', 1716: '98997', 1717: '99059', 1718: '99060', 1719: '9915', 1720: '99515', 1721: '99543', 1722: '99681', 1723: '99806'}\n"
     ]
    }
   ],
   "source": [
    "print(len(indices_to_class_labels_dict))\n",
    "print(indices_to_class_labels_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"group9_indices_to_class_labels_dict.json\", \"wb\") as pickle_file:\n",
    "    pickle.dump(indices_to_class_labels_dict, pickle_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
