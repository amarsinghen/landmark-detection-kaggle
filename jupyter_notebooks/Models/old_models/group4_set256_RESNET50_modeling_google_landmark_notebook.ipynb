{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.image as mpimg\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'),\n",
       " PhysicalDevice(name='/physical_device:XLA_CPU:0', device_type='XLA_CPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'),\n",
       " PhysicalDevice(name='/physical_device:XLA_GPU:0', device_type='XLA_GPU')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ResNet50_MODEL=tf.keras.applications.ResNet50(input_shape=(224,224,3),\n",
    "                                               include_top=False,\n",
    "                                               weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "175"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ResNet50_MODEL.layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'conv2_block1_0_bn'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ResNet50_MODEL.layers[15].name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in ResNet50_MODEL.layers:\n",
    "    layer.trainable=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"resnet50\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 230, 230, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1_conv (Conv2D)             (None, 112, 112, 64) 9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1_bn (BatchNormalization)   (None, 112, 112, 64) 256         conv1_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1_relu (Activation)         (None, 112, 112, 64) 0           conv1_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 114, 114, 64) 0           conv1_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pool (MaxPooling2D)       (None, 56, 56, 64)   0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_conv (Conv2D)    (None, 56, 56, 64)   4160        pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_relu (Activation (None, 56, 56, 64)   0           conv2_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_relu (Activation (None, 56, 56, 64)   0           conv2_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_conv (Conv2D)    (None, 56, 56, 256)  16640       pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_add (Add)          (None, 56, 56, 256)  0           conv2_block1_0_bn[0][0]          \n",
      "                                                                 conv2_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_out (Activation)   (None, 56, 56, 256)  0           conv2_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_conv (Conv2D)    (None, 56, 56, 64)   16448       conv2_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_relu (Activation (None, 56, 56, 64)   0           conv2_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_relu (Activation (None, 56, 56, 64)   0           conv2_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_add (Add)          (None, 56, 56, 256)  0           conv2_block1_out[0][0]           \n",
      "                                                                 conv2_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_out (Activation)   (None, 56, 56, 256)  0           conv2_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_conv (Conv2D)    (None, 56, 56, 64)   16448       conv2_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_relu (Activation (None, 56, 56, 64)   0           conv2_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_relu (Activation (None, 56, 56, 64)   0           conv2_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_add (Add)          (None, 56, 56, 256)  0           conv2_block2_out[0][0]           \n",
      "                                                                 conv2_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_out (Activation)   (None, 56, 56, 256)  0           conv2_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_conv (Conv2D)    (None, 28, 28, 128)  32896       conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_relu (Activation (None, 28, 28, 128)  0           conv3_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_relu (Activation (None, 28, 28, 128)  0           conv3_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_conv (Conv2D)    (None, 28, 28, 512)  131584      conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_add (Add)          (None, 28, 28, 512)  0           conv3_block1_0_bn[0][0]          \n",
      "                                                                 conv3_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_out (Activation)   (None, 28, 28, 512)  0           conv3_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_relu (Activation (None, 28, 28, 128)  0           conv3_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_relu (Activation (None, 28, 28, 128)  0           conv3_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_add (Add)          (None, 28, 28, 512)  0           conv3_block1_out[0][0]           \n",
      "                                                                 conv3_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_out (Activation)   (None, 28, 28, 512)  0           conv3_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_relu (Activation (None, 28, 28, 128)  0           conv3_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_relu (Activation (None, 28, 28, 128)  0           conv3_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_add (Add)          (None, 28, 28, 512)  0           conv3_block2_out[0][0]           \n",
      "                                                                 conv3_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_out (Activation)   (None, 28, 28, 512)  0           conv3_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_relu (Activation (None, 28, 28, 128)  0           conv3_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_relu (Activation (None, 28, 28, 128)  0           conv3_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_add (Add)          (None, 28, 28, 512)  0           conv3_block3_out[0][0]           \n",
      "                                                                 conv3_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_out (Activation)   (None, 28, 28, 512)  0           conv3_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_conv (Conv2D)    (None, 14, 14, 256)  131328      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_relu (Activation (None, 14, 14, 256)  0           conv4_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_relu (Activation (None, 14, 14, 256)  0           conv4_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_conv (Conv2D)    (None, 14, 14, 1024) 525312      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_add (Add)          (None, 14, 14, 1024) 0           conv4_block1_0_bn[0][0]          \n",
      "                                                                 conv4_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_out (Activation)   (None, 14, 14, 1024) 0           conv4_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_relu (Activation (None, 14, 14, 256)  0           conv4_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_relu (Activation (None, 14, 14, 256)  0           conv4_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_add (Add)          (None, 14, 14, 1024) 0           conv4_block1_out[0][0]           \n",
      "                                                                 conv4_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_out (Activation)   (None, 14, 14, 1024) 0           conv4_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_relu (Activation (None, 14, 14, 256)  0           conv4_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_relu (Activation (None, 14, 14, 256)  0           conv4_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_add (Add)          (None, 14, 14, 1024) 0           conv4_block2_out[0][0]           \n",
      "                                                                 conv4_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_out (Activation)   (None, 14, 14, 1024) 0           conv4_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_relu (Activation (None, 14, 14, 256)  0           conv4_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_relu (Activation (None, 14, 14, 256)  0           conv4_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_add (Add)          (None, 14, 14, 1024) 0           conv4_block3_out[0][0]           \n",
      "                                                                 conv4_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_out (Activation)   (None, 14, 14, 1024) 0           conv4_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_relu (Activation (None, 14, 14, 256)  0           conv4_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_relu (Activation (None, 14, 14, 256)  0           conv4_block5_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block5_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block5_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_add (Add)          (None, 14, 14, 1024) 0           conv4_block4_out[0][0]           \n",
      "                                                                 conv4_block5_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_out (Activation)   (None, 14, 14, 1024) 0           conv4_block5_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block5_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_relu (Activation (None, 14, 14, 256)  0           conv4_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_relu (Activation (None, 14, 14, 256)  0           conv4_block6_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block6_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block6_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_add (Add)          (None, 14, 14, 1024) 0           conv4_block5_out[0][0]           \n",
      "                                                                 conv4_block6_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_out (Activation)   (None, 14, 14, 1024) 0           conv4_block6_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_conv (Conv2D)    (None, 7, 7, 512)    524800      conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_relu (Activation (None, 7, 7, 512)    0           conv5_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_relu (Activation (None, 7, 7, 512)    0           conv5_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_conv (Conv2D)    (None, 7, 7, 2048)   2099200     conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_add (Add)          (None, 7, 7, 2048)   0           conv5_block1_0_bn[0][0]          \n",
      "                                                                 conv5_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_out (Activation)   (None, 7, 7, 2048)   0           conv5_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_conv (Conv2D)    (None, 7, 7, 512)    1049088     conv5_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_relu (Activation (None, 7, 7, 512)    0           conv5_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_relu (Activation (None, 7, 7, 512)    0           conv5_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_add (Add)          (None, 7, 7, 2048)   0           conv5_block1_out[0][0]           \n",
      "                                                                 conv5_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_out (Activation)   (None, 7, 7, 2048)   0           conv5_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_conv (Conv2D)    (None, 7, 7, 512)    1049088     conv5_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_relu (Activation (None, 7, 7, 512)    0           conv5_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_relu (Activation (None, 7, 7, 512)    0           conv5_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_add (Add)          (None, 7, 7, 2048)   0           conv5_block2_out[0][0]           \n",
      "                                                                 conv5_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_out (Activation)   (None, 7, 7, 2048)   0           conv5_block3_add[0][0]           \n",
      "==================================================================================================\n",
      "Total params: 23,587,712\n",
      "Trainable params: 23,534,592\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "ResNet50_MODEL.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "l1_factor = 0.0001\n",
    "l2_factor = 0.0001\n",
    "dropout = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "resnet50 (Model)             (None, 7, 7, 2048)        23587712  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "Dropout_Regularization1 (Dro (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 5844)              11974356  \n",
      "=================================================================\n",
      "Total params: 35,562,068\n",
      "Trainable params: 35,508,948\n",
      "Non-trainable params: 53,120\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model=tf.keras.models.Sequential([\n",
    "                                  ResNet50_MODEL,\n",
    "                                  tf.keras.layers.GlobalAveragePooling2D(),\n",
    "                                  tf.keras.layers.Dropout(dropout, name='Dropout_Regularization1'),\n",
    "                                  tf.keras.layers.Dense(5844, activation='softmax')\n",
    "])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(lr=0.0001)\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['acc'])\n",
    "train_data_dir = '../datasets/group4_set_256/set_256/train/'\n",
    "valid_data_dir = '../datasets/group4_set_256/set_256/valid/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=45,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest')\n",
    "\n",
    "valid_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 297753 images belonging to 5844 classes.\n"
     ]
    }
   ],
   "source": [
    "#flow training images\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(256,256),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 70128 images belonging to 5844 classes.\n"
     ]
    }
   ],
   "source": [
    "valid_generator = valid_datagen.flow_from_directory(\n",
    "    valid_data_dir,\n",
    "    target_size=(256,256),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-14-4b8ac998ef6c>:8: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "Epoch 1/100\n",
      "4652/4652 [==============================] - 1796s 386ms/step - loss: 6.8055 - acc: 0.0649 - val_loss: 4.6291 - val_acc: 0.2285\n",
      "Epoch 2/100\n",
      "4652/4652 [==============================] - 1799s 387ms/step - loss: 4.0480 - acc: 0.2925 - val_loss: 3.6338 - val_acc: 0.3635\n",
      "Epoch 3/100\n",
      "4652/4652 [==============================] - 1807s 388ms/step - loss: 3.1302 - acc: 0.4169 - val_loss: 3.2762 - val_acc: 0.4223\n",
      "Epoch 4/100\n",
      "4652/4652 [==============================] - 1794s 386ms/step - loss: 2.6023 - acc: 0.4940 - val_loss: 3.0023 - val_acc: 0.4620\n",
      "Epoch 5/100\n",
      "4652/4652 [==============================] - 1808s 389ms/step - loss: 2.2325 - acc: 0.5512 - val_loss: 2.7810 - val_acc: 0.5028\n",
      "Epoch 6/100\n",
      "4652/4652 [==============================] - 1804s 388ms/step - loss: 1.9521 - acc: 0.5959 - val_loss: 2.9348 - val_acc: 0.4872\n",
      "Epoch 7/100\n",
      "4652/4652 [==============================] - 1805s 388ms/step - loss: 1.7233 - acc: 0.6345 - val_loss: 2.9540 - val_acc: 0.4780\n",
      "Epoch 8/100\n",
      "4652/4652 [==============================] - 1806s 388ms/step - loss: 1.5389 - acc: 0.6659 - val_loss: 2.5075 - val_acc: 0.5587\n",
      "Epoch 9/100\n",
      "4652/4652 [==============================] - 1800s 387ms/step - loss: 1.3800 - acc: 0.6937 - val_loss: 2.5218 - val_acc: 0.5537\n",
      "Epoch 10/100\n",
      "4652/4652 [==============================] - 1794s 386ms/step - loss: 1.2444 - acc: 0.7172 - val_loss: 3.0675 - val_acc: 0.4951\n",
      "Epoch 11/100\n",
      "4652/4652 [==============================] - 1807s 388ms/step - loss: 1.1292 - acc: 0.7381 - val_loss: 2.5899 - val_acc: 0.5607\n",
      "Epoch 12/100\n",
      "4652/4652 [==============================] - 1813s 390ms/step - loss: 1.0249 - acc: 0.7578 - val_loss: 2.5540 - val_acc: 0.5743\n",
      "Epoch 13/100\n",
      "4652/4652 [==============================] - 1813s 390ms/step - loss: 0.9371 - acc: 0.7753 - val_loss: 2.6705 - val_acc: 0.5519\n",
      "Epoch 14/100\n",
      "4652/4652 [==============================] - 1815s 390ms/step - loss: 0.8595 - acc: 0.7892 - val_loss: 2.7260 - val_acc: 0.5557\n",
      "Epoch 15/100\n",
      "4652/4652 [==============================] - 1802s 387ms/step - loss: 0.7849 - acc: 0.8047 - val_loss: 2.6088 - val_acc: 0.5789\n",
      "Epoch 16/100\n",
      "4652/4652 [==============================] - 1806s 388ms/step - loss: 0.7239 - acc: 0.8166 - val_loss: 2.6695 - val_acc: 0.5738\n",
      "Epoch 17/100\n",
      "4652/4652 [==============================] - 1800s 387ms/step - loss: 0.6716 - acc: 0.8278 - val_loss: 3.3994 - val_acc: 0.5038\n",
      "Epoch 18/100\n",
      "4652/4652 [==============================] - 1806s 388ms/step - loss: 0.6188 - acc: 0.8385 - val_loss: 2.8032 - val_acc: 0.5724\n",
      "Epoch 19/100\n",
      "4652/4652 [==============================] - 1803s 388ms/step - loss: 0.5772 - acc: 0.8479 - val_loss: 2.7336 - val_acc: 0.5812\n",
      "Epoch 20/100\n",
      "4652/4652 [==============================] - 1801s 387ms/step - loss: 0.5334 - acc: 0.8573 - val_loss: 2.9707 - val_acc: 0.5603\n",
      "Epoch 21/100\n",
      "4652/4652 [==============================] - 1792s 385ms/step - loss: 0.4976 - acc: 0.8660 - val_loss: 2.7128 - val_acc: 0.6000\n",
      "Epoch 22/100\n",
      "4652/4652 [==============================] - 1793s 385ms/step - loss: 0.4715 - acc: 0.8721 - val_loss: 2.8982 - val_acc: 0.5856\n",
      "Epoch 23/100\n",
      "4652/4652 [==============================] - 1793s 385ms/step - loss: 0.4372 - acc: 0.8801 - val_loss: 2.9010 - val_acc: 0.5903\n",
      "Epoch 24/100\n",
      "4652/4652 [==============================] - 1793s 385ms/step - loss: 0.4115 - acc: 0.8858 - val_loss: 3.2249 - val_acc: 0.5623\n",
      "Epoch 25/100\n",
      "4652/4652 [==============================] - 1793s 385ms/step - loss: 0.3864 - acc: 0.8921 - val_loss: 2.8430 - val_acc: 0.5997\n",
      "Epoch 26/100\n",
      "4652/4652 [==============================] - 1794s 386ms/step - loss: 0.3691 - acc: 0.8961 - val_loss: 3.3796 - val_acc: 0.5396\n",
      "Epoch 27/100\n",
      "4652/4652 [==============================] - 1795s 386ms/step - loss: 0.3470 - acc: 0.9026 - val_loss: 2.9803 - val_acc: 0.5844\n",
      "Epoch 28/100\n",
      "4652/4652 [==============================] - 1792s 385ms/step - loss: 0.3316 - acc: 0.9064 - val_loss: 3.0242 - val_acc: 0.5845\n",
      "Epoch 29/100\n",
      "4652/4652 [==============================] - 1794s 386ms/step - loss: 0.3137 - acc: 0.9106 - val_loss: 3.0191 - val_acc: 0.5843\n",
      "Epoch 30/100\n",
      "4652/4652 [==============================] - 1795s 386ms/step - loss: 0.3003 - acc: 0.9146 - val_loss: 2.9752 - val_acc: 0.6025\n",
      "Epoch 31/100\n",
      "4652/4652 [==============================] - 1792s 385ms/step - loss: 0.2867 - acc: 0.9185 - val_loss: 3.2057 - val_acc: 0.5766\n",
      "Epoch 32/100\n",
      "4652/4652 [==============================] - 1792s 385ms/step - loss: 0.2759 - acc: 0.9209 - val_loss: 3.1362 - val_acc: 0.5806\n",
      "Epoch 33/100\n",
      "4652/4652 [==============================] - 1795s 386ms/step - loss: 0.2654 - acc: 0.9239 - val_loss: 3.0975 - val_acc: 0.5946\n",
      "Epoch 34/100\n",
      "4652/4652 [==============================] - 1802s 387ms/step - loss: 0.2538 - acc: 0.9270 - val_loss: 3.3088 - val_acc: 0.5678\n",
      "Epoch 35/100\n",
      "4652/4652 [==============================] - 1802s 387ms/step - loss: 0.2433 - acc: 0.9299 - val_loss: 3.5818 - val_acc: 0.5441\n",
      "Epoch 36/100\n",
      "4652/4652 [==============================] - 1800s 387ms/step - loss: 0.2356 - acc: 0.9326 - val_loss: 3.1077 - val_acc: 0.6009\n",
      "Epoch 37/100\n",
      "4652/4652 [==============================] - 1804s 388ms/step - loss: 0.2264 - acc: 0.9346 - val_loss: 3.4007 - val_acc: 0.5624\n",
      "Epoch 38/100\n",
      "4652/4652 [==============================] - 1795s 386ms/step - loss: 0.2205 - acc: 0.9361 - val_loss: 3.0789 - val_acc: 0.6111\n",
      "Epoch 39/100\n",
      "4652/4652 [==============================] - 1794s 386ms/step - loss: 0.2128 - acc: 0.9380 - val_loss: 3.5060 - val_acc: 0.5706\n",
      "Epoch 40/100\n",
      "4652/4652 [==============================] - 1792s 385ms/step - loss: 0.2066 - acc: 0.9402 - val_loss: 3.2643 - val_acc: 0.5897\n",
      "Epoch 41/100\n",
      "4652/4652 [==============================] - 1797s 386ms/step - loss: 0.2004 - acc: 0.9420 - val_loss: 3.1942 - val_acc: 0.6112\n",
      "Epoch 42/100\n",
      "4652/4652 [==============================] - 1794s 386ms/step - loss: 0.1934 - acc: 0.9438 - val_loss: 3.0965 - val_acc: 0.6141\n",
      "Epoch 43/100\n",
      "4652/4652 [==============================] - 1793s 386ms/step - loss: 0.1882 - acc: 0.9449 - val_loss: 2.7853 - val_acc: 0.6419\n",
      "Epoch 44/100\n",
      "4652/4652 [==============================] - 1793s 385ms/step - loss: 0.1840 - acc: 0.9461 - val_loss: 3.5945 - val_acc: 0.5730\n",
      "Epoch 45/100\n",
      "4652/4652 [==============================] - 1793s 385ms/step - loss: 0.1785 - acc: 0.9479 - val_loss: 3.6100 - val_acc: 0.5621\n",
      "Epoch 46/100\n",
      "4652/4652 [==============================] - 1793s 385ms/step - loss: 0.1728 - acc: 0.9494 - val_loss: 3.4420 - val_acc: 0.5933\n",
      "Epoch 47/100\n",
      "4652/4652 [==============================] - 1793s 385ms/step - loss: 0.1709 - acc: 0.9497 - val_loss: 4.0696 - val_acc: 0.5168\n",
      "Epoch 48/100\n",
      "4652/4652 [==============================] - 1793s 385ms/step - loss: 0.1655 - acc: 0.9517 - val_loss: 3.3111 - val_acc: 0.6030\n",
      "Epoch 49/100\n",
      "4652/4652 [==============================] - 1799s 387ms/step - loss: 0.1607 - acc: 0.9530 - val_loss: 3.1268 - val_acc: 0.6180\n",
      "Epoch 50/100\n",
      "4652/4652 [==============================] - 1793s 385ms/step - loss: 0.1583 - acc: 0.9535 - val_loss: 3.2191 - val_acc: 0.6092\n",
      "Epoch 51/100\n",
      "4652/4652 [==============================] - 1793s 385ms/step - loss: 0.1558 - acc: 0.9544 - val_loss: 3.6686 - val_acc: 0.5742\n",
      "Epoch 52/100\n",
      "4652/4652 [==============================] - 1794s 386ms/step - loss: 0.1494 - acc: 0.9564 - val_loss: 3.0140 - val_acc: 0.6263\n",
      "Epoch 53/100\n",
      "4652/4652 [==============================] - 1793s 385ms/step - loss: 0.1471 - acc: 0.9569 - val_loss: 3.5178 - val_acc: 0.5863\n",
      "Epoch 54/100\n",
      "4652/4652 [==============================] - 1793s 386ms/step - loss: 0.1443 - acc: 0.9576 - val_loss: 3.4381 - val_acc: 0.5951\n",
      "Epoch 55/100\n",
      "4652/4652 [==============================] - 1792s 385ms/step - loss: 0.1409 - acc: 0.9588 - val_loss: 3.5195 - val_acc: 0.5973\n",
      "Epoch 56/100\n",
      "4652/4652 [==============================] - 1796s 386ms/step - loss: 0.1383 - acc: 0.9590 - val_loss: 3.0810 - val_acc: 0.6272\n",
      "Epoch 57/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4652/4652 [==============================] - 1802s 387ms/step - loss: 0.1347 - acc: 0.9605 - val_loss: 3.2496 - val_acc: 0.6178\n",
      "Epoch 58/100\n",
      "4652/4652 [==============================] - 1805s 388ms/step - loss: 0.1333 - acc: 0.9611 - val_loss: 4.3817 - val_acc: 0.5156\n",
      "Epoch 59/100\n",
      "4652/4652 [==============================] - 1800s 387ms/step - loss: 0.1293 - acc: 0.9619 - val_loss: 3.8238 - val_acc: 0.5661\n",
      "Epoch 60/100\n",
      "4652/4652 [==============================] - 1802s 387ms/step - loss: 0.1286 - acc: 0.9618 - val_loss: 4.2806 - val_acc: 0.5368\n",
      "Epoch 61/100\n",
      "4652/4652 [==============================] - 1792s 385ms/step - loss: 0.1247 - acc: 0.9634 - val_loss: 3.5474 - val_acc: 0.5907\n",
      "Epoch 62/100\n",
      "4652/4652 [==============================] - 1795s 386ms/step - loss: 0.1236 - acc: 0.9632 - val_loss: 3.6433 - val_acc: 0.5965\n",
      "Epoch 63/100\n",
      "4652/4652 [==============================] - 1791s 385ms/step - loss: 0.1209 - acc: 0.9642 - val_loss: 4.5028 - val_acc: 0.5192\n",
      "Epoch 64/100\n",
      "4652/4652 [==============================] - 1788s 384ms/step - loss: 0.1183 - acc: 0.9649 - val_loss: 3.3954 - val_acc: 0.6096\n",
      "Epoch 65/100\n",
      "4652/4652 [==============================] - 1791s 385ms/step - loss: 0.1165 - acc: 0.9656 - val_loss: 4.2467 - val_acc: 0.5462\n",
      "Epoch 66/100\n",
      "4652/4652 [==============================] - 1788s 384ms/step - loss: 0.1148 - acc: 0.9662 - val_loss: 3.2622 - val_acc: 0.6306\n",
      "Epoch 67/100\n",
      "4652/4652 [==============================] - 1787s 384ms/step - loss: 0.1124 - acc: 0.9666 - val_loss: 3.4956 - val_acc: 0.6012\n",
      "Epoch 68/100\n",
      "4652/4652 [==============================] - 1788s 384ms/step - loss: 0.1111 - acc: 0.9673 - val_loss: 3.5022 - val_acc: 0.6122\n",
      "Epoch 69/100\n",
      "4652/4652 [==============================] - 1787s 384ms/step - loss: 0.1102 - acc: 0.9675 - val_loss: 3.7062 - val_acc: 0.5971\n",
      "Epoch 70/100\n",
      "4652/4652 [==============================] - 1786s 384ms/step - loss: 0.1072 - acc: 0.9680 - val_loss: 3.8513 - val_acc: 0.5844\n",
      "Epoch 71/100\n",
      "4652/4652 [==============================] - 1787s 384ms/step - loss: 0.1063 - acc: 0.9686 - val_loss: 4.5849 - val_acc: 0.5300\n",
      "Epoch 72/100\n",
      "4652/4652 [==============================] - 1788s 384ms/step - loss: 0.1046 - acc: 0.9690 - val_loss: 3.7155 - val_acc: 0.5940\n",
      "Epoch 73/100\n",
      "4652/4652 [==============================] - 1789s 385ms/step - loss: 0.1033 - acc: 0.9693 - val_loss: 3.2494 - val_acc: 0.6284\n",
      "Epoch 74/100\n",
      "4652/4652 [==============================] - 1791s 385ms/step - loss: 0.1018 - acc: 0.9699 - val_loss: 3.4531 - val_acc: 0.6057\n",
      "Epoch 75/100\n",
      "4652/4652 [==============================] - 1793s 385ms/step - loss: 0.1004 - acc: 0.9705 - val_loss: 3.3854 - val_acc: 0.6213\n",
      "Epoch 76/100\n",
      "4652/4652 [==============================] - 1795s 386ms/step - loss: 0.0990 - acc: 0.9708 - val_loss: 4.3607 - val_acc: 0.5556\n",
      "Epoch 77/100\n",
      "4652/4652 [==============================] - 1796s 386ms/step - loss: 0.0975 - acc: 0.9711 - val_loss: 3.3776 - val_acc: 0.6262\n",
      "Epoch 78/100\n",
      "4652/4652 [==============================] - 1795s 386ms/step - loss: 0.0960 - acc: 0.9716 - val_loss: 4.0612 - val_acc: 0.5836\n",
      "Epoch 79/100\n",
      "4652/4652 [==============================] - 1796s 386ms/step - loss: 0.0955 - acc: 0.9714 - val_loss: 3.4231 - val_acc: 0.6298\n",
      "Epoch 80/100\n",
      "4652/4652 [==============================] - 1799s 387ms/step - loss: 0.0933 - acc: 0.9722 - val_loss: 4.0341 - val_acc: 0.5681\n",
      "Epoch 81/100\n",
      "4652/4652 [==============================] - 1801s 387ms/step - loss: 0.0929 - acc: 0.9725 - val_loss: 3.5138 - val_acc: 0.6218\n",
      "Epoch 82/100\n",
      "4652/4652 [==============================] - 1799s 387ms/step - loss: 0.0912 - acc: 0.9731 - val_loss: 3.5904 - val_acc: 0.6224\n",
      "Epoch 83/100\n",
      "4652/4652 [==============================] - 1816s 390ms/step - loss: 0.0898 - acc: 0.9734 - val_loss: 5.3657 - val_acc: 0.4803\n",
      "Epoch 84/100\n",
      "4652/4652 [==============================] - 1832s 394ms/step - loss: 0.0905 - acc: 0.9729 - val_loss: 3.6476 - val_acc: 0.6227\n",
      "Epoch 85/100\n",
      "4652/4652 [==============================] - 1847s 397ms/step - loss: 0.0877 - acc: 0.9739 - val_loss: 3.6999 - val_acc: 0.6063\n",
      "Epoch 86/100\n",
      "4652/4652 [==============================] - 1843s 396ms/step - loss: 0.0856 - acc: 0.9744 - val_loss: 4.1616 - val_acc: 0.5806\n",
      "Epoch 87/100\n",
      " 595/4652 [==>...........................] - ETA: 24:24 - loss: 0.0827 - acc: 0.9751"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-4b8ac998ef6c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mworkers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m )\n",
      "\u001b[1;32mC:\\Users\\adrsi\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\util\\deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    322\u001b[0m               \u001b[1;34m'in a future version'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'after %s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    323\u001b[0m               instructions)\n\u001b[1;32m--> 324\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    325\u001b[0m     return tf_decorator.make_decorator(\n\u001b[0;32m    326\u001b[0m         \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_func\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'deprecated'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\adrsi\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1477\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1478\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1479\u001b[1;33m         initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m   1480\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1481\u001b[0m   @deprecation.deprecated(\n",
      "\u001b[1;32mC:\\Users\\adrsi\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     64\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     67\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\adrsi\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m    846\u001b[0m                 batch_size=batch_size):\n\u001b[0;32m    847\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 848\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    849\u001b[0m               \u001b[1;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    850\u001b[0m               \u001b[1;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\adrsi\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    579\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 580\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    581\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    582\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\adrsi\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    609\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    610\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 611\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    612\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    613\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\adrsi\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2418\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2419\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2420\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2421\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2422\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\adrsi\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   1663\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[0;32m   1664\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[1;32m-> 1665\u001b[1;33m         self.captured_inputs)\n\u001b[0m\u001b[0;32m   1666\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1667\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\adrsi\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1744\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1746\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\adrsi\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 598\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    599\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32mC:\\Users\\adrsi\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 60\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(\n",
    "    generator = train_generator,\n",
    "    steps_per_epoch = train_generator.n // batch_size,\n",
    "    validation_data = valid_generator,\n",
    "    validation_steps = valid_generator.n // batch_size,\n",
    "    epochs = 100,\n",
    "    workers = 5,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history.model.save('group1_06302020')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.models.save_model(history.model, 'group4_set256_RESNET50_07032020.h5', include_optimizer=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc)\n",
    "plt.plot(epochs, val_acc)\n",
    "plt.title('Training accuracy')\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss)\n",
    "plt.plot(epochs, val_loss)\n",
    "plt.title('Training Loss')\n",
    "plt.figure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
