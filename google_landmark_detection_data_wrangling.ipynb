{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "google_landmark_detection_data_wrangling.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/amarsinghen/landmark-detection-kaggle/blob/master/google_landmark_detection_data_wrangling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hqpdjDKRxTvw",
        "colab_type": "text"
      },
      "source": [
        "Setting the tensorflow to version 2.0"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5sS4q7b3EDtN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6NZu_Uiog-J3",
        "colab_type": "code",
        "outputId": "6d9a8d6a-c63f-4eae-dbfd-5610a2cfa80a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n7An0k33xaku",
        "colab_type": "text"
      },
      "source": [
        "### Imports\n",
        "All the imports for the project"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AoRwAqH-EtTC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "import functools\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pathlib\n",
        "import tensorflow as tf\n",
        "from PIL import Image\n",
        "import imageio\n",
        "import logging as log\n",
        "import tarfile\n",
        "import os"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aBsYs-mKEPc6",
        "colab_type": "code",
        "outputId": "02b41982-13f7-4515-9927-660a7307efcf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "tf.__version__"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.1.0-rc1'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kBH3KURG0ul0",
        "colab_type": "text"
      },
      "source": [
        "Setting the log level"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5x6ZBt5o0hgd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "log.basicConfig(level=log.DEBUG)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mr7d4X4t2vgJ",
        "colab_type": "text"
      },
      "source": [
        "Downloading Training set Tar files to Mounted google drive. This is a one time task"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DmiDyT752XB2",
        "colab_type": "code",
        "outputId": "4a40cfd5-55f2-4556-c77d-620712df093d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        }
      },
      "source": [
        "# for i in range(0,1):\n",
        "#   if i<10:\n",
        "#     download_url = \"https://s3.amazonaws.com/google-landmark/train/images_00\"+str(i)+\".tar\"\n",
        "#     save_url = \"drive/My\\ Drive/datasets/landmark_detection/train/images_00\"+str(i)+\".tar\"\n",
        "#   elif (i<100 and i>9):\n",
        "#     download_url = \"https://s3.amazonaws.com/google-landmark/train/images_0\"+str(i)+\".tar\"\n",
        "#     save_url = \"drive/My\\ Drive/datasets/landmark_detection//train/images_0\"+str(i)+\".tar\"\n",
        "#   else:\n",
        "#     download_url = \"https://s3.amazonaws.com/google-landmark/train/images_\"+str(i)+\".tar\"\n",
        "#     save_url = \"drive/My\\ Drive/datasets/landmark_detection//train/images_\"+str(i)+\".tar\"\n",
        "#   print(download_url)\n",
        "#   !wget --no-check-certificate {download_url} -O {save_url}"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "https://s3.amazonaws.com/google-landmark/train/images_000.tar\n",
            "--2020-01-15 16:07:45--  https://s3.amazonaws.com/google-landmark/train/images_000.tar\n",
            "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.216.24.190\n",
            "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.216.24.190|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1067018752 (1018M) [application/x-tar]\n",
            "Saving to: ‘drive/My Drive/datasets/landmark_detection/train/images_000.tar’\n",
            "\n",
            "drive/My Drive/data 100%[===================>]   1018M  48.9MB/s    in 21s     \n",
            "\n",
            "2020-01-15 16:08:06 (48.8 MB/s) - ‘drive/My Drive/datasets/landmark_detection/train/images_000.tar’ saved [1067018752/1067018752]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VdQpN07s28It",
        "colab_type": "text"
      },
      "source": [
        "Downloading test set Tar files to Mounted google drive. This is a one time task"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a1w9Iq503ESZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# for i in range(0,20):\n",
        "#   if i<10:\n",
        "#     download_url = \"https://s3.amazonaws.com/google-landmark/test/images_00\"+str(i)+\".tar\"\n",
        "#     save_url = \"drive/My\\ Drive/datasets/landmark_detection/test/images_00\"+str(i)+\".tar\"\n",
        "#   else:\n",
        "#     download_url = \"https://s3.amazonaws.com/google-landmark/test/images_0\"+str(i)+\".tar\"\n",
        "#     save_url = \"drive/My\\ Drive/datasets/landmark_detection/test/images_0\"+str(i)+\".tar\"\n",
        "#   print(download_url)\n",
        "#   !wget --no-check-certificate {download_url} -O {save_url}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zpSM2L7eHnLk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tf.keras.backend.clear_session()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iKxE_tVdCXQQ",
        "colab_type": "code",
        "outputId": "89268210-1e6b-41f1-a2d9-54044d55b4c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# !ls -l \"drive/My Drive/datasets/landmark_detection/train\" | wc -l\n",
        "!find \"drive/My Drive/datasets/landmark_detection/train\" -type f | wc -l"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "36635\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CqGV8jcTC5XP",
        "colab_type": "text"
      },
      "source": [
        "Extracting the train images from all the 500 tar files to train folder. This is also a 1 time step."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wv7AU7KTDCdc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# train_extract_location = \"drive/My Drive/datasets/landmark_detection/train\"\n",
        "# for i in range(0,50):\n",
        "#   if i<10:\n",
        "#     train_tar_location = \"drive/My Drive/datasets/landmark_detection/train/images_00\"+str(i)+\".tar\"\n",
        "#   elif (i>9 and i<100):\n",
        "#     train_tar_location = \"drive/My Drive/datasets/landmark_detection/train/images_0\"+str(i)+\".tar\"\n",
        "#   else:\n",
        "#     train_tar_location = \"drive/My Drive/datasets/landmark_detection/train/images_\"+str(i)+\".tar\"\n",
        "#   print(train_tar_location)\n",
        "#   my_tar = tarfile.open(train_tar_location)\n",
        "#   my_tar.extractall(train_extract_location)\n",
        "#   my_tar.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sIfSx9QACuuu",
        "colab_type": "text"
      },
      "source": [
        "Extracting the test images from all the 20 tar files in test folder. This is also a 1 time step."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dvrd6uHK3V1Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# extract_location = \"drive/My Drive/datasets/landmark_detection/test\"\n",
        "# for i in range(0,20):\n",
        "#   if i<10:\n",
        "#     tar_location = \"drive/My Drive/datasets/landmark_detection/test/images_00\"+str(i)+\".tar\"\n",
        "#   else:\n",
        "#     tar_location = \"drive/My Drive/datasets/landmark_detection/test/images_0\"+str(i)+\".tar\"\n",
        "#   print(tar_location)\n",
        "#   my_tar = tarfile.open(tar_location)\n",
        "#   my_tar.extractall(extract_location)\n",
        "#   my_tar.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hc47fVRwBVr8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !rm -r \"drive/My Drive/datasets/landmark_detection/train/1\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uTKg-K9wxi_2",
        "colab_type": "text"
      },
      "source": [
        "### Data Download\n",
        "Assigning Training and Test Data file URLS to variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ebPccIH8OU3U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TRAIN_DATA_URL = \"https://s3.amazonaws.com/google-landmark/metadata/train.csv\"\n",
        "TRAIN_ATTRIBUTION_DATA_URL = \"https://s3.amazonaws.com/google-landmark/metadata/train_attribution.csv\"\n",
        "TRAIN_LABEL_TO_CATEGORY_DATA_URL = \"https://s3.amazonaws.com/google-landmark/metadata/train_label_to_category.csv\"\n",
        "TRAIN_IMAGES_DATA_TAR_URL = \"https://s3.amazonaws.com/google-landmark/train/images_001.tar\"\n",
        "\n",
        "TEST_DATA_CSV_URL = \"https://s3.amazonaws.com/google-landmark/metadata/test.csv\"\n",
        "TEST_DATA_RECOGNITION_SOLUTION_V2_URL = \"https://s3.amazonaws.com/google-landmark/ground_truth/recognition_solution_v2.1.csv\"\n",
        "TEST_DATA_RETRIEVAL_SOLUTION_V2_URL = \"https://s3.amazonaws.com/google-landmark/ground_truth/retrieval_solution_v2.1.csv\"\n",
        "TEST_IMAGES_DATA_TAR_URL = \"https://s3.amazonaws.com/google-landmark/test/images_000.tar\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O9dnZNNUxtL4",
        "colab_type": "text"
      },
      "source": [
        "Downloading the test and training data (csv) files. These csv files contain the urls and landmark classification information. The variables below are of type string that holds the file locations on local server. The overall image dataset is very large, ~4 million images for training and ~200k for test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ijR2OVInE05O",
        "colab_type": "code",
        "outputId": "f80f62fa-0dbf-48ad-9eed-8e9e8da00c51",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        }
      },
      "source": [
        "train_file_csv = tf.keras.utils.get_file(\"train.csv\", TRAIN_DATA_URL)\n",
        "train_attribution_csv= tf.keras.utils.get_file(\"train_attribution.csv\", TRAIN_ATTRIBUTION_DATA_URL)\n",
        "train_label_to_category_csv = tf.keras.utils.get_file(\"train_label_to_category.csv\",TRAIN_LABEL_TO_CATEGORY_DATA_URL)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/google-landmark/metadata/train.csv\n",
            "525836288/525832518 [==============================] - 9s 0us/step\n",
            "Downloading data from https://s3.amazonaws.com/google-landmark/metadata/train_attribution.csv\n",
            "1011458048/1011452758 [==============================] - 17s 0us/step\n",
            "Downloading data from https://s3.amazonaws.com/google-landmark/metadata/train_label_to_category.csv\n",
            "15155200/15153105 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dznzKZSpzE5r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "log.debug(\"The type of variables is : \" + str(type(train_file_csv)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "12Vgo8-MPFiY",
        "colab_type": "code",
        "outputId": "07539b39-b964-463d-f37f-57a564caa2a1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        }
      },
      "source": [
        "test_file_csv = tf.keras.utils.get_file(\"test.csv\", TEST_DATA_CSV_URL)\n",
        "test_image_recognition_solution_csv= tf.keras.utils.get_file(\"test_images_recognition_solution.csv\", TEST_DATA_RECOGNITION_SOLUTION_V2_URL)\n",
        "test_image_retrieval_solution_csv = tf.keras.utils.get_file(\"test_images_retrieval_solution.csv\",TEST_DATA_RETRIEVAL_SOLUTION_V2_URL)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/google-landmark/metadata/test.csv\n",
            "1998848/1998812 [==============================] - 0s 0us/step\n",
            "Downloading data from https://s3.amazonaws.com/google-landmark/ground_truth/recognition_solution_v2.1.csv\n",
            "3031040/3029774 [==============================] - 0s 0us/step\n",
            "Downloading data from https://s3.amazonaws.com/google-landmark/ground_truth/retrieval_solution_v2.1.csv\n",
            "3784704/3780702 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LUlY6NtaNf0u",
        "colab_type": "text"
      },
      "source": [
        "### Converting to pandas data frame\n",
        "Loading training and test data from csv files and converting to pandas dataframe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lHwXmehgEUQm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_file_csv_df = pd.read_csv(train_file_csv)\n",
        "train_attribution_csv_df = pd.read_csv(train_attribution_csv)\n",
        "train_label_to_category_csv_df = pd.read_csv(train_label_to_category_csv)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l3l3_fawSir5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_file_csv_df = pd.read_csv(test_file_csv)\n",
        "test_image_recognition_solution_csv_df = pd.read_csv(test_image_recognition_solution_csv)\n",
        "test_image_retrieval_solution_csv_csv_df = pd.read_csv(test_image_retrieval_solution_csv)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DYhcanMfB0b_",
        "colab_type": "text"
      },
      "source": [
        "Create a Dictionary of image ids to landmark_ids"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K-reHfLiByCl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7zrCpfBJaSk_",
        "colab_type": "text"
      },
      "source": [
        "- Checking for **null values**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ylvhgCwCTZsf",
        "colab_type": "code",
        "outputId": "edeaaed3-706d-4029-b8e5-a74b8b88175a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "source": [
        "train_file_csv_df[train_file_csv_df.id.isnull() | train_file_csv_df.url.isnull() | train_file_csv_df.landmark_id.isnull()].count()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "id             0\n",
              "url            0\n",
              "landmark_id    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xpQpwwOmg0XQ",
        "colab_type": "text"
      },
      "source": [
        "* The **top 20** landmarks with highest number of images in the training set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fHGRLMyWgv_D",
        "colab_type": "code",
        "outputId": "92692e58-6a43-4e63-da88-884947d5160e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 382
        }
      },
      "source": [
        "train_file_csv_df.landmark_id.value_counts()[:20]"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "138982    10247\n",
              "62798      4333\n",
              "177870     3327\n",
              "176528     3243\n",
              "192931     2627\n",
              "126637     2589\n",
              "83144      2351\n",
              "171772     2268\n",
              "20409      2248\n",
              "151942     1727\n",
              "84689      1721\n",
              "139894     1717\n",
              "62074      1637\n",
              "10618      1539\n",
              "45428      1513\n",
              "41808      1509\n",
              "139706     1509\n",
              "60532      1447\n",
              "161902     1424\n",
              "194914     1399\n",
              "Name: landmark_id, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XDosciVWHlaD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "landmarks_greater_than_5_df = train_file_csv_df.landmark_id.value_counts().reset_index(name=\"count\").query('count>5')\n",
        "log.debug(\"Sample of record in the train_file_csv_df dataframe : \\n\" + str(train_file_csv_df.head(1)))\n",
        "log.debug(\"Total number of images in the training set : \" + str(train_file_csv_df['url'].count()))\n",
        "log.debug(\"Total number of unique landmark_ids in the training dataset : \" + str(train_file_csv_df.landmark_id.value_counts()\n",
        "                                                                                 .reset_index(name=\"count\")[\"index\"].count()))\n",
        "log.debug(\"Total number of landmarks with greater than 5 images in the dataset : \" + str(landmarks_greater_than_5_df[\"index\"].count()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pIIg8pSqhPZy",
        "colab_type": "text"
      },
      "source": [
        "* Filtering training set to only inlcude images count of greater than 5 for landmarks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sV5ph0cGm9nd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "filtered_train_greater_than_5_df = train_file_csv_df[train_file_csv_df.landmark_id.isin(landmarks_greater_than_5_df['index'])]\n",
        "log.debug(\"Total number of images for landmarks with image count of greater than 5 in the training set after filtering  : \" + str(filtered_train_greater_than_5_df[\"id\"].count()))\n",
        "log.debug(filtered_train_greater_than_5_df.head(1))\n",
        "log.debug(filtered_train_greater_than_5_df.iloc[1]['url'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G6L7_CCRViNy",
        "colab_type": "text"
      },
      "source": [
        "Storing the filtered dataframe to a csv file for home computer use"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "khzny8oRVhkK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "filtered_df_file_name = \"drive/My Drive/datasets/landmark_detection/train/filtered_train_greater_than_5_df.csv\"\n",
        "filtered_train_greater_than_5_df.to_csv(filtered_df_file_name, encoding='utf-8', index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ucewCR0SWMRO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "00f66be8-93ad-4462-f98c-6e3838ea913e"
      },
      "source": [
        "print(filtered_train_greater_than_5_df[\"id\"].count())\n",
        "filtered_df_csv = pd.read_csv(filtered_df_file_name)\n",
        "print(filtered_df_csv[\"id\"].count())"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3920020\n",
            "3920020\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n6EYkIOetfC7",
        "colab_type": "text"
      },
      "source": [
        "Moving the files/images to appropriate train and test directories with labeled folders. Structure of the folders is : train->landmark_labeled_folder->actual_image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RIlB-lpDE9vB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "outputId": "04ab11b3-4fda-41e0-fd26-c07e5f4e195d"
      },
      "source": [
        "def getListOfFiles(dirName):\n",
        "    # create a list of file and sub directories \n",
        "    # names in the given directory \n",
        "    listOfFile = os.listdir(dirName)\n",
        "    allFiles = list()\n",
        "    # Iterate over all the entries\n",
        "    for entry in listOfFile:\n",
        "        # Create full path\n",
        "        fullPath = os.path.join(dirName, entry)\n",
        "        # If entry is a directory then get the list of files in this directory \n",
        "        if os.path.isdir(fullPath):\n",
        "            allFiles = allFiles + getListOfFiles(fullPath)\n",
        "        else:\n",
        "            allFiles.append(fullPath)             \n",
        "    return allFiles\n",
        "\n",
        "dirName = \"drive/My Drive/datasets/landmark_detection/train/0\"\n",
        "\n",
        "listOfImages = getListOfFiles(dirName)\n",
        "listOfImages[:10]"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['drive/My Drive/datasets/landmark_detection/train/0/0/0/0000059611c7d079.jpg',\n",
              " 'drive/My Drive/datasets/landmark_detection/train/0/0/0/0000070506c174cc.jpg',\n",
              " 'drive/My Drive/datasets/landmark_detection/train/0/0/0/000008ae30de967e.jpg',\n",
              " 'drive/My Drive/datasets/landmark_detection/train/0/0/0/000014b1f770f640.jpg',\n",
              " 'drive/My Drive/datasets/landmark_detection/train/0/0/0/000015f76534add3.jpg',\n",
              " 'drive/My Drive/datasets/landmark_detection/train/0/0/0/00001ae42cd00356.jpg',\n",
              " 'drive/My Drive/datasets/landmark_detection/train/0/0/0/00001b2ba2c69ac5.jpg',\n",
              " 'drive/My Drive/datasets/landmark_detection/train/0/0/0/00001d45edef6c9e.jpg',\n",
              " 'drive/My Drive/datasets/landmark_detection/train/0/0/0/000020dfc079c013.jpg',\n",
              " 'drive/My Drive/datasets/landmark_detection/train/0/0/0/000022ce0b9d8966.jpg']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GHsw7IrJH2EL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "outputId": "0fff330b-50c9-44f8-f67b-3b95552c7782"
      },
      "source": [
        "filtered_train_greater_than_5_df[:1]"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>url</th>\n",
              "      <th>landmark_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6e158a47eb2ca3f6</td>\n",
              "      <td>https://upload.wikimedia.org/wikipedia/commons...</td>\n",
              "      <td>142820</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 id  ... landmark_id\n",
              "0  6e158a47eb2ca3f6  ...      142820\n",
              "\n",
              "[1 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YJp8rFbdLUva",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "72c5f81f-cfd8-4bdf-bf52-d87054d243a7"
      },
      "source": [
        "train_file_csv_df[train_file_csv_df.id=='0000070506c174cc'].values"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([['0000070506c174cc',\n",
              "        'http://upload.wikimedia.org/wikipedia/commons/0/06/Grabst%C3%A4tte_Stra%C3%9Fe_des_17_Juni_%28Tierg%29_Sowjetisches_Ehrenmal.jpg',\n",
              "        149519]], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bnOKu5suBH0_",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P3RmVE1F-NDR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "9cc27a4f-3320-4be5-94e0-c7411f7f7493"
      },
      "source": [
        "import shutil\n",
        "\n",
        "for filepath in listOfImages[:1000]:\n",
        "  file_name = filepath.split(\"/\")[-1].split(\".\")[0]\n",
        "  landmark_id = filtered_train_greater_than_5_df[filtered_train_greater_than_5_df.id==file_name]\n",
        "  if (len(landmark_id)!=0):\n",
        "    landmark_id_folder_name = str(landmark_id['landmark_id'].values[0])\n",
        "    local_location = str(\"/tmp/train/\" + str(landmark_id_folder_name) + \"/\" + str(file_name) + \".jpg\")\n",
        "    if not os.path.isdir(local_location.split(str(file_name))[0]):\n",
        "        os.makedirs(local_location.split(str(file_name))[0])\n",
        "    # print(len(landmark_id))\n",
        "    # print(str(landmark_id['landmark_id'].values[0]))\n",
        "    # print(file_name)\n",
        "    shutil.copy2(filepath, local_location)\n",
        "    break"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\n",
            "149519\n",
            "0000070506c174cc\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gKvLfIVtkaq6",
        "colab_type": "code",
        "outputId": "16417746-18c3-4e21-e9b8-6f86941c0594",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!pwd"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z5oMxUTgKY69",
        "colab_type": "text"
      },
      "source": [
        "Download all the images via url. Most likely would not use this piece of code."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0rxqHNaagzYr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import urllib.request\n",
        "# from urllib.error import *\n",
        "# import os\n",
        "# # for row in filtered_train_between_50and100_df.iterrows():\n",
        "# for index, row in filtered_train_between_50and100_df.iterrows():\n",
        "#   # print(row['id'])\n",
        "#   # print(row['url'])\n",
        "#   # print(row['landmark_id'])\n",
        "#   local_location = str(\"/tmp/\" + str(row['landmark_id']) + \"/\" + str(row['id']) + \".jpg\")\n",
        "#   # print(local_location)\n",
        "#   if not os.path.isdir(local_location.split(row['id'])[0]):\n",
        "#         os.makedirs(local_location.split(row['id'])[0])\n",
        "#   try:\n",
        "#     urllib.request.urlretrieve(row['url'], local_location)\n",
        "#   except FileNotFoundError as err:\n",
        "#     print(err)   # something wrong with local path\n",
        "#   except HTTPError as err:\n",
        "#     print(err)  # something wrong with url\n",
        "#     print(row['url'])\n",
        "#   except ContentTooShortError as err:\n",
        "#     print(err)  # something wrong with url\n",
        "#     print(row['url'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ob_rvgo7mS4X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "log.debug(\"Sample of record in the test_file_csv_df dataframe : \\n\" + str(test_file_csv_df.head(3)))\n",
        "log.debug(\"Total number of images in the test set : \" + str(test_file_csv_df['id'].count()))\n",
        "log.debug(\"Total number of unique landmark_ids in the test dataset : \" + str(test_file_csv_df.id.value_counts()\n",
        "                                                                                 .reset_index(name=\"count\")[\"index\"].count()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1557JKc7V5-g",
        "colab_type": "text"
      },
      "source": [
        "View a few pictures. Configuring matplot parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dhn4jhctVp7Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m8_BCZ1dWHFS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "\n",
        "image_path = \"/tmp/100157/9cd60ce98c029534.jpg\"\n",
        "\n",
        "fig = plt.gcf()\n",
        "img = mpimg.imread(image_path)\n",
        "plt.imshow(img)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rloRwJ9FYCuo",
        "colab_type": "text"
      },
      "source": [
        "Build a tensorflow model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tpH73q5pYKjr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "model=tf.keras.models.Sequential([\n",
        "                                  tf.keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(400,400,3)),\n",
        "                                  tf.keras.layers.MaxPooling2D(2,2),\n",
        "                                  tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n",
        "                                  tf.keras.layers.MaxPooling2D(2,2),\n",
        "                                  tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "                                  tf.keras.layers.MaxPooling2D(2,2),\n",
        "                                  tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "                                  tf.keras.layers.MaxPooling2D(2,2),\n",
        "                                  tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "                                  tf.keras.layers.MaxPooling2D(2,2),\n",
        "                                  tf.keras.layers.Flatten(),\n",
        "                                  tf.keras.layers.Dense(512, activation='relu'),\n",
        "                                  tf.keras.layers.Dense(filtered_train_between_50and100_df[\"id\"].count(), activation='softmax')\n",
        "])\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X3Rce1dWaOos",
        "colab_type": "text"
      },
      "source": [
        "Compiling the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H4icM-fNaQII",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['acc'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YnJSSFqfazKS",
        "colab_type": "text"
      },
      "source": [
        "Data preprocessing with ImageDataGenerator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QZ87U2PPa32q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "train_datagen = ImageDataGenerator(rescale=1/255)\n",
        "#flow training images in batches of 128\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    '/tmp/',\n",
        "    target_size=(400,400),\n",
        "    batch_size=128,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "history = model.fit_generator(\n",
        "    train_generator,\n",
        "    steps_per_epoch=8,\n",
        "    epochs = 15,\n",
        "    verbose = 1\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "utxulcOZdYyi",
        "colab_type": "text"
      },
      "source": [
        "Evaluating Accuracy and Loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OGzrppXadf4b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "acc = history.history['acc']\n",
        "loss = history.history['loss']\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc)\n",
        "plt.title('Training accuracy')\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs, loss)\n",
        "plt.title('Training Loss')\n",
        "plt.figure()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}