{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "google_landmark_detection_data_wrangling.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/amarsinghen/landmark-detection-kaggle/blob/master/google_landmark_detection_data_wrangling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hqpdjDKRxTvw",
        "colab_type": "text"
      },
      "source": [
        "Setting the tensorflow to version 2.0"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5sS4q7b3EDtN",
        "colab_type": "code",
        "outputId": "0e25ee65-f39c-4c15-ad6b-baceed1e499a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n7An0k33xaku",
        "colab_type": "text"
      },
      "source": [
        "### Imports\n",
        "All the imports for the project"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AoRwAqH-EtTC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "import functools\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pathlib\n",
        "import tensorflow as tf\n",
        "from PIL import Image\n",
        "import imageio\n",
        "import logging as log"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aBsYs-mKEPc6",
        "colab_type": "code",
        "outputId": "ba2a32f2-f8a3-453a-b351-302318708057",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "tf.__version__"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.1.0-rc1'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kBH3KURG0ul0",
        "colab_type": "text"
      },
      "source": [
        "Setting the log level"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5x6ZBt5o0hgd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "log.basicConfig(level=log.DEBUG)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uTKg-K9wxi_2",
        "colab_type": "text"
      },
      "source": [
        "### Data Download\n",
        "Assigning Training and Test Data file URLS to variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ebPccIH8OU3U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TRAIN_DATA_URL = \"https://s3.amazonaws.com/google-landmark/metadata/train.csv\"\n",
        "TRAIN_ATTRIBUTION_DATA_URL = \"https://s3.amazonaws.com/google-landmark/metadata/train_attribution.csv\"\n",
        "TRAIN_LABEL_TO_CATEGORY_DATA_URL = \"https://s3.amazonaws.com/google-landmark/metadata/train_label_to_category.csv\"\n",
        "TRAIN_IMAGES_DATA_TAR_URL = \"https://s3.amazonaws.com/google-landmark/train/images_001.tar\"\n",
        "\n",
        "TEST_DATA_CSV_URL = \"https://s3.amazonaws.com/google-landmark/metadata/test.csv\"\n",
        "TEST_DATA_RECOGNITION_SOLUTION_V2_URL = \"https://s3.amazonaws.com/google-landmark/ground_truth/recognition_solution_v2.1.csv\"\n",
        "TEST_DATA_RETRIEVAL_SOLUTION_V2_URL = \"https://s3.amazonaws.com/google-landmark/ground_truth/retrieval_solution_v2.1.csv\"\n",
        "TEST_IMAGES_DATA_TAR_URL = \"https://s3.amazonaws.com/google-landmark/test/images_000.tar\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O9dnZNNUxtL4",
        "colab_type": "text"
      },
      "source": [
        "Downloading the test and training data (csv) files. These csv files contain the urls and landmark classification information. The variables below are of type string that holds the file locations on local server. The overall image dataset is very large, ~4 million images for training and ~200k for test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ijR2OVInE05O",
        "colab_type": "code",
        "outputId": "f7b9b5e4-6b79-4c83-ac95-3ab1c70f18be",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "train_file_csv = tf.keras.utils.get_file(\"train.csv\", TRAIN_DATA_URL)\n",
        "train_attribution_csv= tf.keras.utils.get_file(\"train_attribution.csv\", TRAIN_ATTRIBUTION_DATA_URL)\n",
        "train_label_to_category_csv = tf.keras.utils.get_file(\"train_label_to_category.csv\",TRAIN_LABEL_TO_CATEGORY_DATA_URL)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/google-landmark/metadata/train.csv\n",
            "525836288/525832518 [==============================] - 9s 0us/step\n",
            "Downloading data from https://s3.amazonaws.com/google-landmark/metadata/train_attribution.csv\n",
            "1011458048/1011452758 [==============================] - 18s 0us/step\n",
            "Downloading data from https://s3.amazonaws.com/google-landmark/metadata/train_label_to_category.csv\n",
            "15155200/15153105 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dznzKZSpzE5r",
        "colab_type": "code",
        "outputId": "4bd8fafd-43ce-43e9-a6db-03c4f8ef4b7a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "log.debug(\"The type of variables is : \" + str(type(train_file_csv)))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "DEBUG:root:The type of variables is : <class 'str'>\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "12Vgo8-MPFiY",
        "colab_type": "code",
        "outputId": "f6187b5b-510f-42d1-bc53-33bc64d939e4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "test_file_csv = tf.keras.utils.get_file(\"test.csv\", TEST_DATA_CSV_URL)\n",
        "test_image_recognition_solution_csv= tf.keras.utils.get_file(\"test_images_recognition_solution.csv\", TEST_DATA_RECOGNITION_SOLUTION_V2_URL)\n",
        "test_image_retrieval_solution_csv = tf.keras.utils.get_file(\"test_images_retrieval_solution.csv\",TEST_DATA_RETRIEVAL_SOLUTION_V2_URL)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/google-landmark/metadata/test.csv\n",
            "1998848/1998812 [==============================] - 0s 0us/step\n",
            "Downloading data from https://s3.amazonaws.com/google-landmark/ground_truth/recognition_solution_v2.1.csv\n",
            "3031040/3029774 [==============================] - 0s 0us/step\n",
            "Downloading data from https://s3.amazonaws.com/google-landmark/ground_truth/retrieval_solution_v2.1.csv\n",
            "3784704/3780702 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LUlY6NtaNf0u",
        "colab_type": "text"
      },
      "source": [
        "### Converting to pandas data frame\n",
        "Loading training and test data from csv files and converting to pandas dataframe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lHwXmehgEUQm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_file_csv_df = pd.read_csv(train_file_csv)\n",
        "train_attribution_csv_df = pd.read_csv(train_attribution_csv)\n",
        "train_label_to_category_csv_df = pd.read_csv(train_label_to_category_csv)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l3l3_fawSir5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_file_csv_df = pd.read_csv(test_file_csv)\n",
        "test_image_recognition_solution_csv_df = pd.read_csv(test_image_recognition_solution_csv)\n",
        "test_image_retrieval_solution_csv_csv_df = pd.read_csv(test_image_retrieval_solution_csv)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7zrCpfBJaSk_",
        "colab_type": "text"
      },
      "source": [
        "- Checking for **null values**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ylvhgCwCTZsf",
        "colab_type": "code",
        "outputId": "35528041-46ef-4918-bae6-482599966608",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "source": [
        "train_file_csv_df[train_file_csv_df.id.isnull() | train_file_csv_df.url.isnull() | train_file_csv_df.landmark_id.isnull()].count()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "id             0\n",
              "url            0\n",
              "landmark_id    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xpQpwwOmg0XQ",
        "colab_type": "text"
      },
      "source": [
        "* The **top 20** landmarks with highest number of images in the training set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fHGRLMyWgv_D",
        "colab_type": "code",
        "outputId": "d0eb62af-0ea7-4442-bda4-d9550a467878",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 382
        }
      },
      "source": [
        "train_file_csv_df.landmark_id.value_counts()[:20]"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "138982    10247\n",
              "62798      4333\n",
              "177870     3327\n",
              "176528     3243\n",
              "192931     2627\n",
              "126637     2589\n",
              "83144      2351\n",
              "171772     2268\n",
              "20409      2248\n",
              "151942     1727\n",
              "84689      1721\n",
              "139894     1717\n",
              "62074      1637\n",
              "10618      1539\n",
              "45428      1513\n",
              "41808      1509\n",
              "139706     1509\n",
              "60532      1447\n",
              "161902     1424\n",
              "194914     1399\n",
              "Name: landmark_id, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XDosciVWHlaD",
        "colab_type": "code",
        "outputId": "91d8aaab-b199-4380-877e-0ef5376e29cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "landmarks_between_50_and_100_df = train_file_csv_df.landmark_id.value_counts().reset_index(name=\"count\").query('count<55 and count>49')\n",
        "log.debug(\"Sample of record in the train_file_csv_df dataframe : \\n\" + str(train_file_csv_df.head(1)))\n",
        "log.debug(\"Total number of images in the training set : \" + str(train_file_csv_df['url'].count()))\n",
        "log.debug(\"Total number of unique landmark_ids in the training dataset : \" + str(train_file_csv_df.landmark_id.value_counts()\n",
        "                                                                                 .reset_index(name=\"count\")[\"index\"].count()))\n",
        "log.debug(\"Total number of landmarks with 50 and 100 images in the dataset : \" + str(landmarks_between_50_and_100_df[\"index\"].count()))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:numexpr.utils:NumExpr defaulting to 2 threads.\n",
            "DEBUG:root:Sample of record in the train_file_csv_df dataframe : \n",
            "                 id  ... landmark_id\n",
            "0  6e158a47eb2ca3f6  ...      142820\n",
            "\n",
            "[1 rows x 3 columns]\n",
            "DEBUG:root:Total number of images in the training set : 4132914\n",
            "DEBUG:root:Total number of unique landmark_ids in the training dataset : 203094\n",
            "DEBUG:root:Total number of landmarks with 50 and 100 images in the dataset : 2195\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pIIg8pSqhPZy",
        "colab_type": "text"
      },
      "source": [
        "* Filtering training set to nly inlcude images count between 50 and 100 for a landmark"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sV5ph0cGm9nd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "0abdad5b-0143-4a1b-d63f-9c2797f13347"
      },
      "source": [
        "filtered_train_between_50and100_df = train_file_csv_df[train_file_csv_df.landmark_id.isin(landmarks_between_50_and_100_df['index'])]\n",
        "log.debug(\"Total number of images between 50 and 100 count in the training set after filtering  : \" + str(filtered_train_between_50and100_df[\"id\"].count()))\n",
        "log.debug(filtered_train_between_50and100_df.head(1))\n",
        "log.debug(filtered_train_between_50and100_df.iloc[1]['url'])"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "DEBUG:root:Total number of images between 50 and 100 count in the training set after filtering  : 113948\n",
            "DEBUG:root:                 id  ... landmark_id\n",
            "3  e7f70e9c61e66af3  ...      102140\n",
            "\n",
            "[1 rows x 3 columns]\n",
            "DEBUG:root:https://upload.wikimedia.org/wikipedia/commons/e/e2/Mount_Vernon_Mansion_as_seen_from_the_Bowling_Green._-_panoramio.jpg\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gKvLfIVtkaq6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4445d26b-0bce-482e-febd-4cb8719375a0"
      },
      "source": [
        "!pwd"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0rxqHNaagzYr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        },
        "outputId": "7b13c1d6-ec3e-441c-a0c5-199a4d8ece74"
      },
      "source": [
        "import urllib.request\n",
        "from urllib.error import *\n",
        "import os\n",
        "# for row in filtered_train_between_50and100_df.iterrows():\n",
        "for index, row in filtered_train_between_50and100_df.iterrows():\n",
        "  # print(row['id'])\n",
        "  # print(row['url'])\n",
        "  # print(row['landmark_id'])\n",
        "  local_location = str(\"/tmp/\" + str(row['landmark_id']) + \"/\" + str(row['id']) + \".jpg\")\n",
        "  # print(local_location)\n",
        "  if not os.path.isdir(local_location.split(row['id'])[0]):\n",
        "        os.makedirs(local_location.split(row['id'])[0])\n",
        "  try:\n",
        "    urllib.request.urlretrieve(row['url'], local_location)\n",
        "  except FileNotFoundError as err:\n",
        "    print(err)   # something wrong with local path\n",
        "  except HTTPError as err:\n",
        "    print(err)  # something wrong with url\n",
        "    print(row['url'])\n",
        "  except ContentTooShortError as err:\n",
        "    print(err)  # something wrong with url\n",
        "    print(row['url'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "HTTP Error 404: Not Found\n",
            "https://upload.wikimedia.org/wikipedia/commons/a/af/Calrencedockpublicart.jpg\n",
            "HTTP Error 404: Not Found\n",
            "https://upload.wikimedia.org/wikipedia/commons/6/62/Interieur_doopvont_-_Voorburg_-_20533881_-_RCE.jpg\n",
            "HTTP Error 404: Not Found\n",
            "https://upload.wikimedia.org/wikipedia/commons/8/8f/Exterieur_ZUIDGEVEL_-_Voorburg_-_20275792_-_RCE.jpg\n",
            "HTTP Error 404: Not Found\n",
            "https://upload.wikimedia.org/wikipedia/commons/5/59/Namak_Lake_%282%29.jpg\n",
            "HTTP Error 404: Not Found\n",
            "https://upload.wikimedia.org/wikipedia/commons/b/bb/HK_CWB_Causeway_Bay_%E7%BE%85%E7%B4%A0%E8%A1%97_Russell_Street_Times_Square_red_heros_figure_August_2018_SSG_02.jpg\n",
            "HTTP Error 404: Not Found\n",
            "https://upload.wikimedia.org/wikipedia/commons/9/9c/Caverne_du_Pont_d%27Arc_Acc%C3%A8s_visiteurs.jpg\n",
            "HTTP Error 404: Not Found\n",
            "https://upload.wikimedia.org/wikipedia/commons/5/52/M%C3%BCnchen_2012_%2853%29.jpg\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jGQ8xeDcVmnp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ob_rvgo7mS4X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "log.debug(\"Sample of record in the test_file_csv_df dataframe : \\n\" + str(test_file_csv_df.head(3)))\n",
        "log.debug(\"Total number of images in the test set : \" + str(test_file_csv_df['id'].count()))\n",
        "log.debug(\"Total number of unique landmark_ids in the test dataset : \" + str(test_file_csv_df.id.value_counts()\n",
        "                                                                                 .reset_index(name=\"count\")[\"index\"].count()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1557JKc7V5-g",
        "colab_type": "text"
      },
      "source": [
        "View a few pictures. Configuring matplot parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dhn4jhctVp7Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m8_BCZ1dWHFS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "\n",
        "image_path = \"/tmp/100157/9cd60ce98c029534.jpg\"\n",
        "\n",
        "fig = plt.gcf()\n",
        "img = mpimg.imread(image_path)\n",
        "plt.imshow(img)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rloRwJ9FYCuo",
        "colab_type": "text"
      },
      "source": [
        "Build a tensorflow model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tpH73q5pYKjr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "model=tf.keras.models.Sequential([\n",
        "                                  tf.keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(400,400,3)),\n",
        "                                  tf.keras.layers.MaxPooling2D(2,2),\n",
        "                                  tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n",
        "                                  tf.keras.layers.MaxPooling2D(2,2),\n",
        "                                  tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "                                  tf.keras.layers.MaxPooling2D(2,2),\n",
        "                                  tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "                                  tf.keras.layers.MaxPooling2D(2,2),\n",
        "                                  tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "                                  tf.keras.layers.MaxPooling2D(2,2),\n",
        "                                  tf.keras.layers.Flatten(),\n",
        "                                  tf.keras.layers.Dense(512, activation='relu'),\n",
        "                                  tf.keras.layers.Dense(filtered_train_between_50and100_df[\"id\"].count(), activation='softmax')\n",
        "])\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X3Rce1dWaOos",
        "colab_type": "text"
      },
      "source": [
        "Compiling the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H4icM-fNaQII",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['acc'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YnJSSFqfazKS",
        "colab_type": "text"
      },
      "source": [
        "Data preprocessing with ImageDataGenerator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QZ87U2PPa32q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "train_datagen = ImageDataGenerator(rescale=1/255)\n",
        "#flow training images in batches of 128\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    '/tmp/',\n",
        "    target_size=(400,400),\n",
        "    batch_size=128,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "history = model.fit_generator(\n",
        "    train_generator,\n",
        "    steps_per_epoch=8,\n",
        "    epochs = 15,\n",
        "    verbose = 1\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "utxulcOZdYyi",
        "colab_type": "text"
      },
      "source": [
        "Evaluating Accuracy and Loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OGzrppXadf4b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "acc = history.history['acc']\n",
        "loss = history.history['loss']\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc)\n",
        "plt.title('Training accuracy')\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs, loss)\n",
        "plt.title('Training Loss')\n",
        "plt.figure()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}